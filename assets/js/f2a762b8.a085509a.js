"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[137],{4780(e,n,a){a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>_,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2-robotic-nervous-system/chapter-2/solutions","title":"Solutions: Bridging Python-based AI Agents to Robot Controllers","description":"Solution for Exercise 1: Basic AI Agent Implementation","source":"@site/docs/module-2-robotic-nervous-system/chapter-2/solutions.md","sourceDirName":"module-2-robotic-nervous-system/chapter-2","slug":"/module-2-robotic-nervous-system/chapter-2/solutions","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-2/solutions","draft":false,"unlisted":false,"editUrl":"https://github.com/shirazkk/Physicial_Ai_Book_Hackathon_1/edit/main/my-website/docs/module-2-robotic-nervous-system/chapter-2/solutions.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Exercises: Bridging Python-based AI Agents to Robot Controllers","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-2/exercises"},"next":{"title":"Understanding URDF for Humanoid Robot Description and Control","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-3/urdf-humanoid-description"}}');var s=a(4848),i=a(8453);const r={},l="Solutions: Bridging Python-based AI Agents to Robot Controllers",o={},c=[{value:"Solution for Exercise 1: Basic AI Agent Implementation",id:"solution-for-exercise-1-basic-ai-agent-implementation",level:2},{value:"Complete AI Agent Node Code",id:"complete-ai-agent-node-code",level:3},{value:"How to Run",id:"how-to-run",level:3},{value:"Solution for Exercise 2: Multi-Sensor Integration",id:"solution-for-exercise-2-multi-sensor-integration",level:2},{value:"Complete Multi-Sensor AI Agent Code",id:"complete-multi-sensor-ai-agent-code",level:3},{value:"Solution for Exercise 3: Behavior-Based Control",id:"solution-for-exercise-3-behavior-based-control",level:2},{value:"Complete Behavior-Based AI Agent Code",id:"complete-behavior-based-ai-agent-code",level:3},{value:"Solution for Exercise 4: Path Planning Integration",id:"solution-for-exercise-4-path-planning-integration",level:2},{value:"Complete Path Planning AI Agent Code",id:"complete-path-planning-ai-agent-code",level:3},{value:"Solution for Exercise 5: Safety and Validation System",id:"solution-for-exercise-5-safety-and-validation-system",level:2},{value:"Complete Safety Layer Code",id:"complete-safety-layer-code",level:3},{value:"Solution for Exercise 6: Learning-Based Behavior (Advanced)",id:"solution-for-exercise-6-learning-based-behavior-advanced",level:2},{value:"Complete Learning-Based AI Agent Code",id:"complete-learning-based-ai-agent-code",level:3},{value:"Implementation Guide",id:"implementation-guide",level:2},{value:"For Exercise 1 (Basic AI Agent):",id:"for-exercise-1-basic-ai-agent",level:3},{value:"For Exercise 2 (Multi-Sensor Integration):",id:"for-exercise-2-multi-sensor-integration",level:3},{value:"For Exercise 3 (Behavior-Based Control):",id:"for-exercise-3-behavior-based-control",level:3},{value:"For Exercise 4 (Path Planning Integration):",id:"for-exercise-4-path-planning-integration",level:3},{value:"For Exercise 5 (Safety and Validation):",id:"for-exercise-5-safety-and-validation",level:3},{value:"For Exercise 6 (Learning-Based Behavior):",id:"for-exercise-6-learning-based-behavior",level:3},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"solutions-bridging-python-based-ai-agents-to-robot-controllers",children:"Solutions: Bridging Python-based AI Agents to Robot Controllers"})}),"\n",(0,s.jsx)(n.h2,{id:"solution-for-exercise-1-basic-ai-agent-implementation",children:"Solution for Exercise 1: Basic AI Agent Implementation"}),"\n",(0,s.jsx)(n.h3,{id:"complete-ai-agent-node-code",children:"Complete AI Agent Node Code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist\nimport numpy as np\n\nclass AIAgentNode(Node):\n\n    def __init__(self):\n        super().__init__('ai_agent_node')\n\n        # Create subscriber for laser scan data\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10\n        )\n\n        # Create publisher for velocity commands\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            '/cmd_vel',\n            10\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)\n\n        # Internal state\n        self.laser_data = None\n        self.obstacle_threshold = 1.0  # meters\n\n        self.get_logger().info('AI Agent Node initialized')\n\n    def scan_callback(self, msg):\n        \"\"\"Process incoming laser scan data\"\"\"\n        # Convert to numpy array for easier processing\n        ranges = np.array(msg.ranges)\n        # Filter out invalid measurements (inf or nan)\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            self.laser_data = {\n                'ranges': valid_ranges,\n                'min_distance': np.min(valid_ranges),\n                'angle_min': msg.angle_min,\n                'angle_max': msg.angle_max,\n                'angle_increment': msg.angle_increment\n            }\n\n    def control_loop(self):\n        \"\"\"Main control loop for the AI agent\"\"\"\n        if self.laser_data is None:\n            return\n\n        # Get the minimum distance to any obstacle\n        min_distance = self.laser_data['min_distance']\n\n        # Create velocity command\n        cmd = Twist()\n\n        if min_distance < self.obstacle_threshold:\n            # Obstacle detected - implement avoidance behavior\n            # Find the angle of the closest obstacle\n            ranges = self.laser_data['ranges']\n            angles = np.linspace(\n                self.laser_data['angle_min'],\n                self.laser_data['angle_max'],\n                len(ranges)\n            )\n\n            closest_idx = np.argmin(ranges)\n            closest_angle = angles[closest_idx]\n\n            # Turn away from the obstacle\n            if closest_angle < 0:\n                # Obstacle on the left - turn right\n                cmd.linear.x = 0.2  # Slow forward motion\n                cmd.angular.z = -0.5  # Turn right\n            else:\n                # Obstacle on the right - turn left\n                cmd.linear.x = 0.2  # Slow forward motion\n                cmd.angular.z = 0.5  # Turn left\n        else:\n            # No immediate obstacles - move forward\n            cmd.linear.x = 0.5  # Move forward at medium speed\n            cmd.angular.z = 0.0  # No turning\n\n        # Publish the command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Log the command\n        self.get_logger().info(\n            f'Velocity: linear={cmd.linear.x:.2f}, angular={cmd.angular.z:.2f}, '\n            f'closest_obstacle={min_distance:.2f}m'\n        )\n\ndef main(args=None):\n    rclpy.init(args=args)\n    ai_agent_node = AIAgentNode()\n\n    try:\n        rclpy.spin(ai_agent_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        ai_agent_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h3,{id:"how-to-run",children:"How to Run"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Save the code as ",(0,s.jsx)(n.code,{children:"ai_agent_node.py"})]}),"\n",(0,s.jsx)(n.li,{children:"Make sure your ROS 2 environment is sourced"}),"\n",(0,s.jsxs)(n.li,{children:["Run the node: ",(0,s.jsx)(n.code,{children:"python3 ai_agent_node.py"})]}),"\n",(0,s.jsx)(n.li,{children:"Test with a simulated robot that publishes laser scan data and accepts velocity commands"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"solution-for-exercise-2-multi-sensor-integration",children:"Solution for Exercise 2: Multi-Sensor Integration"}),"\n",(0,s.jsx)(n.h3,{id:"complete-multi-sensor-ai-agent-code",children:"Complete Multi-Sensor AI Agent Code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Imu\nfrom nav_msgs.msg import Odometry\nfrom geometry_msgs.msg import Twist\nfrom tf2_ros import TransformException\nfrom tf2_ros.buffer import Buffer\nfrom tf2_ros.transform_listener import TransformListener\nimport numpy as np\nfrom collections import deque\nimport math\n\nclass MultiSensorAINode(Node):\n\n    def __init__(self):\n        super().__init__('multi_sensor_ai_node')\n\n        # TF2 buffer and listener for coordinate transforms\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Create subscribers for multiple sensors\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10\n        )\n\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            '/odom',\n            self.odom_callback,\n            10\n        )\n\n        self.imu_sub = self.create_subscription(\n            Imu,\n            '/imu',\n            self.imu_callback,\n            10\n        )\n\n        # Publisher for velocity commands\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            '/cmd_vel',\n            10\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)\n\n        # Data storage with timestamps for synchronization\n        self.scan_data = None\n        self.odom_data = None\n        self.imu_data = None\n\n        # Store recent sensor data for fusion\n        self.scan_history = deque(maxlen=10)\n        self.odom_history = deque(maxlen=10)\n        self.imu_history = deque(maxlen=10)\n\n        # Fused state\n        self.fused_state = {\n            'position': {'x': 0.0, 'y': 0.0, 'z': 0.0},\n            'orientation': {'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0},\n            'linear_velocity': {'x': 0.0, 'y': 0.0, 'z': 0.0},\n            'angular_velocity': {'x': 0.0, 'y': 0.0, 'z': 0.0},\n            'obstacle_distances': [],\n            'min_obstacle_distance': float('inf'),\n            'heading': 0.0  # Robot's heading in radians\n        }\n\n        self.get_logger().info('Multi-Sensor AI Node initialized')\n\n    def scan_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        timestamp = self.get_clock().now().nanoseconds\n        ranges = np.array(msg.ranges)\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            self.scan_data = {\n                'timestamp': timestamp,\n                'ranges': valid_ranges,\n                'min_distance': np.min(valid_ranges),\n                'angle_min': msg.angle_min,\n                'angle_max': msg.angle_max,\n                'angle_increment': msg.angle_increment\n            }\n            # Add to history\n            self.scan_history.append(self.scan_data)\n\n    def odom_callback(self, msg):\n        \"\"\"Process odometry data\"\"\"\n        timestamp = self.get_clock().now().nanoseconds\n        self.odom_data = {\n            'timestamp': timestamp,\n            'position': {\n                'x': msg.pose.pose.position.x,\n                'y': msg.pose.pose.position.y,\n                'z': msg.pose.pose.position.z\n            },\n            'orientation': {\n                'x': msg.pose.pose.orientation.x,\n                'y': msg.pose.pose.orientation.y,\n                'z': msg.pose.pose.orientation.z,\n                'w': msg.pose.pose.orientation.w\n            },\n            'linear_velocity': {\n                'x': msg.twist.twist.linear.x,\n                'y': msg.twist.twist.linear.y,\n                'z': msg.twist.twist.linear.z\n            },\n            'angular_velocity': {\n                'x': msg.twist.twist.angular.x,\n                'y': msg.twist.twist.angular.y,\n                'z': msg.twist.twist.angular.z\n            }\n        }\n        # Add to history\n        self.odom_history.append(self.odom_data)\n\n    def imu_callback(self, msg):\n        \"\"\"Process IMU data\"\"\"\n        timestamp = self.get_clock().now().nanoseconds\n        self.imu_data = {\n            'timestamp': timestamp,\n            'orientation': {\n                'x': msg.orientation.x,\n                'y': msg.orientation.y,\n                'z': msg.orientation.z,\n                'w': msg.orientation.w\n            },\n            'angular_velocity': {\n                'x': msg.angular_velocity.x,\n                'y': msg.angular_velocity.y,\n                'z': msg.angular_velocity.z\n            },\n            'linear_acceleration': {\n                'x': msg.linear_acceleration.x,\n                'y': msg.linear_acceleration.y,\n                'z': msg.linear_acceleration.z\n            }\n        }\n        # Add to history\n        self.imu_history.append(self.imu_data)\n\n    def quaternion_to_euler(self, x, y, z, w):\n        \"\"\"Convert quaternion to Euler angles\"\"\"\n        # Roll (x-axis rotation)\n        sinr_cosp = 2 * (w * x + y * z)\n        cosr_cosp = 1 - 2 * (x * x + y * y)\n        roll = math.atan2(sinr_cosp, cosr_cosp)\n\n        # Pitch (y-axis rotation)\n        sinp = 2 * (w * y - z * x)\n        pitch = math.asin(sinp)\n\n        # Yaw (z-axis rotation)\n        siny_cosp = 2 * (w * z + x * y)\n        cosy_cosp = 1 - 2 * (y * y + z * z)\n        yaw = math.atan2(siny_cosp, cosy_cosp)\n\n        return roll, pitch, yaw\n\n    def sensor_fusion(self):\n        \"\"\"Fuse data from multiple sensors to create comprehensive state\"\"\"\n        # Get the most recent data from each sensor\n        if not all([self.scan_data, self.odom_data, self.imu_data]):\n            return\n\n        # Use the most recent timestamp as reference\n        ref_timestamp = self.get_clock().now().nanoseconds\n\n        # Fuse position and orientation\n        # Prioritize odometry for position, IMU for orientation (more accurate)\n        fused_position = self.odom_data['position']\n\n        # Extract orientation from IMU (usually more accurate than odometry)\n        imu_orientation = self.imu_data['orientation']\n        roll, pitch, yaw = self.quaternion_to_euler(\n            imu_orientation['x'], imu_orientation['y'],\n            imu_orientation['z'], imu_orientation['w']\n        )\n\n        # Fuse velocity information\n        linear_vel = self.odom_data['linear_velocity']\n        angular_vel = self.imu_data['angular_velocity']  # IMU typically more accurate for angular rates\n\n        # Update fused state\n        self.fused_state.update({\n            'position': fused_position,\n            'orientation': {'roll': roll, 'pitch': pitch, 'yaw': yaw},\n            'linear_velocity': linear_vel,\n            'angular_velocity': angular_vel,\n            'heading': yaw,  # Current heading in radians\n            'min_obstacle_distance': self.scan_data['min_distance'],\n            'obstacle_distances': self.scan_data['ranges'].tolist()\n        })\n\n    def control_loop(self):\n        \"\"\"Main control loop with multi-sensor fusion\"\"\"\n        # Perform sensor fusion\n        self.sensor_fusion()\n\n        if self.fused_state['min_obstacle_distance'] == float('inf'):\n            return\n\n        # Create velocity command based on fused state\n        cmd = Twist()\n\n        min_distance = self.fused_state['min_obstacle_distance']\n        obstacle_threshold = 1.0  # meters\n\n        if min_distance < obstacle_threshold:\n            # Obstacle detected - implement avoidance behavior\n            # Use laser scan data to determine obstacle direction\n            if self.scan_data:\n                ranges = self.scan_data['ranges']\n                angles = np.linspace(\n                    self.scan_data['angle_min'],\n                    self.scan_data['angle_max'],\n                    len(ranges)\n                )\n\n                closest_idx = np.argmin(ranges)\n                closest_angle = angles[closest_idx]\n\n                # Adjust heading based on obstacle position\n                if closest_angle < 0:\n                    # Obstacle on the left - turn right\n                    cmd.linear.x = max(0.1, min_distance * 0.3)  # Slow forward motion, slower when closer to obstacles\n                    cmd.angular.z = -max(0.3, abs(closest_angle) * 0.5)  # Turn right more aggressively when closer to obstacles\n                else:\n                    # Obstacle on the right - turn left\n                    cmd.linear.x = max(0.1, min_distance * 0.3)  # Slow forward motion\n                    cmd.angular.z = max(0.3, abs(closest_angle) * 0.5)  # Turn left more aggressively when closer to obstacles\n        else:\n            # No immediate obstacles - move forward with heading correction\n            cmd.linear.x = 0.5  # Move forward at medium speed\n            cmd.angular.z = -self.fused_state['heading'] * 0.5  # Correct heading towards desired direction\n\n        # Publish the command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Log the command and fused state\n        self.get_logger().info(\n            f'Fused AI Agent - Vel: lin={cmd.linear.x:.2f}, ang={cmd.angular.z:.2f}, '\n            f'Pos:({self.fused_state[\"position\"][\"x\"]:.2f},{self.fused_state[\"position\"][\"y\"]:.2f}), '\n            f'Heading:{math.degrees(self.fused_state[\"heading\"]):.1f}\xb0, '\n            f'Obst:{self.fused_state[\"min_obstacle_distance\"]:.2f}m'\n        )\n\ndef main(args=None):\n    rclpy.init(args=args)\n    multi_sensor_node = MultiSensorAINode()\n\n    try:\n        rclpy.spin(multi_sensor_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        multi_sensor_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"solution-for-exercise-3-behavior-based-control",children:"Solution for Exercise 3: Behavior-Based Control"}),"\n",(0,s.jsx)(n.h3,{id:"complete-behavior-based-ai-agent-code",children:"Complete Behavior-Based AI Agent Code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist\nfrom enum import Enum\nimport numpy as np\nimport math\n\nclass BehaviorState(Enum):\n    WANDERING = 1\n    OBSTACLE_AVOIDANCE = 2\n    GOAL_SEEKING = 3\n\nclass BehaviorBasedAINode(Node):\n\n    def __init__(self):\n        super().__init__(\'behavior_based_ai_node\')\n\n        # Create subscriber for laser scan data\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.scan_callback,\n            10\n        )\n\n        # Publisher for velocity commands\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            \'/cmd_vel\',\n            10\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)\n\n        # Internal state\n        self.laser_data = None\n        self.current_behavior = BehaviorState.WANDERING\n        self.previous_behavior = BehaviorState.WANDERING\n\n        # Behavior-specific parameters\n        self.obstacle_threshold = 1.0  # meters\n        self.danger_threshold = 0.5    # meters (immediate danger)\n\n        # Goal-seeking parameters\n        self.goal_x = 5.0  # Target x-coordinate\n        self.goal_y = 5.0  # Target y-coordinate\n        self.current_x = 0.0  # Current position (would come from odometry in real implementation)\n        self.current_y = 0.0\n\n        # Behavior priorities (higher number = higher priority)\n        self.behavior_priorities = {\n            BehaviorState.OBSTACLE_AVOIDANCE: 3,\n            BehaviorState.GOAL_SEEKING: 2,\n            BehaviorState.WANDERING: 1\n        }\n\n        self.get_logger().info(\'Behavior-Based AI Node initialized\')\n\n    def scan_callback(self, msg):\n        """Process incoming laser scan data"""\n        ranges = np.array(msg.ranges)\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            self.laser_data = {\n                \'ranges\': valid_ranges,\n                \'min_distance\': np.min(valid_ranges),\n                \'angle_min\': msg.angle_min,\n                \'angle_max\': msg.angle_max,\n                \'angle_increment\': msg.angle_increment\n            }\n\n    def wandering_behavior(self):\n        """Wandering behavior - random exploration"""\n        cmd = Twist()\n\n        # Random wandering with some forward momentum\n        cmd.linear.x = 0.4 + np.random.uniform(-0.1, 0.1)  # Mostly forward with some variation\n        cmd.angular.z = np.random.uniform(-0.3, 0.3)       # Random turns\n\n        return cmd\n\n    def obstacle_avoidance_behavior(self):\n        """Obstacle avoidance behavior"""\n        if not self.laser_data:\n            return Twist()  # Return stop command if no data\n\n        cmd = Twist()\n\n        # Find the closest obstacle\n        ranges = self.laser_data[\'ranges\']\n        angles = np.linspace(\n            self.laser_data[\'angle_min\'],\n            self.laser_data[\'angle_max\'],\n            len(ranges)\n        )\n\n        closest_idx = np.argmin(ranges)\n        closest_distance = ranges[closest_idx]\n        closest_angle = angles[closest_idx]\n\n        # If in immediate danger, prioritize escape\n        if closest_distance < self.danger_threshold:\n            # Emergency maneuver\n            cmd.linear.x = -0.3  # Back up\n            cmd.angular.z = 0.8 if closest_angle < 0 else -0.8  # Sharp turn away\n        else:\n            # Standard avoidance\n            if closest_angle < 0:\n                # Obstacle on the left - turn right\n                cmd.linear.x = max(0.1, closest_distance * 0.2)\n                cmd.angular.z = -max(0.3, abs(closest_angle) * 0.5)\n            else:\n                # Obstacle on the right - turn left\n                cmd.linear.x = max(0.1, closest_distance * 0.2)\n                cmd.angular.z = max(0.3, abs(closest_angle) * 0.5)\n\n        return cmd\n\n    def goal_seeking_behavior(self):\n        """Goal seeking behavior"""\n        cmd = Twist()\n\n        # Calculate direction to goal\n        dx = self.goal_x - self.current_x\n        dy = self.goal_y - self.current_y\n        distance_to_goal = math.sqrt(dx*dx + dy*dy)\n        angle_to_goal = math.atan2(dy, dx)\n\n        # Normalize angle to [-pi, pi]\n        if angle_to_goal > math.pi:\n            angle_to_goal -= 2 * math.pi\n        elif angle_to_goal < -math.pi:\n            angle_to_goal += 2 * math.pi\n\n        # Set velocity based on distance to goal\n        cmd.linear.x = min(0.8, max(0.2, distance_to_goal * 0.2))\n        cmd.angular.z = angle_to_goal * 0.5\n\n        return cmd\n\n    def determine_active_behavior(self):\n        """Determine which behavior should be active based on conditions"""\n        if not self.laser_data:\n            return BehaviorState.WANDERING\n\n        min_distance = self.laser_data[\'min_distance\']\n\n        # Check for immediate danger (highest priority)\n        if min_distance < self.danger_threshold:\n            return BehaviorState.OBSTACLE_AVOIDANCE\n\n        # Check for obstacle in path (high priority)\n        if min_distance < self.obstacle_threshold:\n            return BehaviorState.OBSTACLE_AVOIDANCE\n\n        # Check if we have a goal and are trying to reach it\n        distance_to_goal = math.sqrt((self.goal_x - self.current_x)**2 + (self.goal_y - self.current_y)**2)\n        if distance_to_goal > 0.5:  # If we\'re not already at the goal\n            return BehaviorState.GOAL_SEEKING\n\n        # Default to wandering\n        return BehaviorState.WANDERING\n\n    def control_loop(self):\n        """Main control loop with behavior selection"""\n        # Determine which behavior should be active\n        self.current_behavior = self.determine_active_behavior()\n\n        # Execute the appropriate behavior\n        cmd = Twist()\n\n        if self.current_behavior == BehaviorState.WANDERING:\n            cmd = self.wandering_behavior()\n        elif self.current_behavior == BehaviorState.OBSTACLE_AVOIDANCE:\n            cmd = self.obstacle_avoidance_behavior()\n        elif self.current_behavior == BehaviorState.GOAL_SEEKING:\n            cmd = self.goal_seeking_behavior()\n\n        # Publish the command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Log behavior transitions\n        if self.current_behavior != self.previous_behavior:\n            self.get_logger().info(f\'Behavior transition: {self.previous_behavior.name} -> {self.current_behavior.name}\')\n\n        # Log the command and current behavior\n        self.get_logger().info(\n            f\'Behavior: {self.current_behavior.name}, \'\n            f\'Velocity: linear={cmd.linear.x:.2f}, angular={cmd.angular.z:.2f}\'\n        )\n\n        self.previous_behavior = self.current_behavior\n\ndef main(args=None):\n    rclpy.init(args=args)\n    behavior_node = BehaviorBasedAINode()\n\n    try:\n        rclpy.spin(behavior_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        behavior_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"solution-for-exercise-4-path-planning-integration",children:"Solution for Exercise 4: Path Planning Integration"}),"\n",(0,s.jsx)(n.h3,{id:"complete-path-planning-ai-agent-code",children:"Complete Path Planning AI Agent Code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom geometry_msgs.msg import Point\nfrom visualization_msgs.msg import Marker\nfrom std_msgs.msg import Header\nimport numpy as np\nimport math\nfrom enum import Enum\n\nclass NavigationState(Enum):\n    IDLE = 1\n    PLANNING = 2\n    FOLLOWING_PATH = 3\n    OBSTACLE_AVOIDANCE = 4\n    REPLANNING = 5\n\nclass PathPlanningAINode(Node):\n\n    def __init__(self):\n        super().__init__(\'path_planning_ai_node\')\n\n        # Create subscribers\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.scan_callback,\n            10\n        )\n\n        # Publisher for velocity commands\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            \'/cmd_vel\',\n            10\n        )\n\n        # Publisher for path visualization\n        self.path_marker_pub = self.create_publisher(\n            Marker,\n            \'/planned_path\',\n            10\n        )\n\n        # Publisher for current goal\n        self.current_goal_pub = self.create_publisher(\n            PoseStamped,\n            \'/current_goal\',\n            10\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)\n\n        # Internal state\n        self.laser_data = None\n        self.current_state = NavigationState.IDLE\n        self.current_x = 0.0\n        self.current_y = 0.0\n        self.current_yaw = 0.0\n\n        # Goal and path planning\n        self.goals = []  # List of (x, y) tuples\n        self.current_goal_index = 0\n        self.path = []   # List of waypoints\n        self.current_waypoint_index = 0\n\n        # Navigation parameters\n        self.waypoint_tolerance = 0.5  # meters\n        self.obstacle_threshold = 1.0  # meters\n        self.replan_threshold = 0.3    # meters (if obstacle is closer, replan)\n\n        # Path planning parameters\n        self.max_path_length = 10  # maximum number of waypoints in path\n\n        self.get_logger().info(\'Path Planning AI Node initialized\')\n\n    def scan_callback(self, msg):\n        """Process incoming laser scan data"""\n        ranges = np.array(msg.ranges)\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            self.laser_data = {\n                \'ranges\': valid_ranges,\n                \'min_distance\': np.min(valid_ranges),\n                \'angle_min\': msg.angle_min,\n                \'angle_max\': msg.angle_max,\n                \'angle_increment\': msg.angle_increment\n            }\n\n    def set_goals(self, goals_list):\n        """Set a list of goals to visit"""\n        self.goals = goals_list\n        self.current_goal_index = 0\n        self.current_state = NavigationState.PLANNING\n        self.get_logger().info(f\'Set {len(goals_list)} goals: {goals_list}\')\n\n    def plan_path(self, start_x, start_y, goal_x, goal_y):\n        """Simple straight-line path planner with intermediate waypoints"""\n        # Calculate distance and direction to goal\n        dx = goal_x - start_x\n        dy = goal_y - start_y\n        distance = math.sqrt(dx*dx + dy*dy)\n\n        if distance < 0.1:  # Already at goal\n            return []\n\n        # Create intermediate waypoints\n        num_waypoints = min(self.max_path_length, max(2, int(distance / 0.5)))\n        path = []\n\n        for i in range(num_waypoints + 1):\n            t = i / num_waypoints\n            wp_x = start_x + dx * t\n            wp_y = start_y + dy * t\n            path.append((wp_x, wp_y))\n\n        return path\n\n    def check_path_clear(self, path):\n        """Check if the path is clear of obstacles"""\n        if not self.laser_data or len(path) < 2:\n            return True\n\n        # For simplicity, check if any point on the path is too close to an obstacle\n        # In a real implementation, this would involve ray casting or occupancy grid checking\n        for i in range(len(path) - 1):\n            start_point = path[i]\n            end_point = path[i + 1]\n\n            # Check midpoint of segment\n            mid_x = (start_point[0] + end_point[0]) / 2\n            mid_y = (start_point[1] + end_point[1]) / 2\n\n            # Calculate distance from robot to this point\n            dist_to_point = math.sqrt((mid_x - self.current_x)**2 + (mid_y - self.current_y)**2)\n\n            # If the point is close to robot and we have laser data, check if it\'s blocked\n            if dist_to_point < 2.0:  # Only check nearby points\n                # This is a simplified check - in reality you\'d need to transform laser data\n                # to global coordinates and check for obstacles at these points\n                if self.laser_data[\'min_distance\'] < 0.5:\n                    return False\n\n        return True\n\n    def simple_path_planner(self):\n        """Execute path planning logic"""\n        if not self.goals or self.current_goal_index >= len(self.goals):\n            self.current_state = NavigationState.IDLE\n            return\n\n        # Get current goal\n        goal_x, goal_y = self.goals[self.current_goal_index]\n\n        # Plan path to current goal\n        self.path = self.plan_path(self.current_x, self.current_y, goal_x, goal_y)\n        self.current_waypoint_index = 0\n\n        if self.path:\n            self.current_state = NavigationState.FOLLOWING_PATH\n            self.get_logger().info(f\'Planned path to goal ({goal_x:.2f}, {goal_y:.2f}) with {len(self.path)} waypoints\')\n\n            # Visualize path\n            self.visualize_path()\n        else:\n            self.current_state = NavigationState.IDLE\n            self.get_logger().warn(\'Failed to plan path\')\n\n    def visualize_path(self):\n        """Publish visualization marker for the planned path"""\n        if not self.path:\n            return\n\n        marker = Marker()\n        marker.header = Header()\n        marker.header.frame_id = "map"\n        marker.header.stamp = self.get_clock().now().to_msg()\n        marker.ns = "planned_path"\n        marker.id = 0\n        marker.type = Marker.LINE_STRIP\n        marker.action = Marker.ADD\n\n        # Set the scale of the line\n        marker.scale.x = 0.05  # Line width\n\n        # Set the color (green)\n        marker.color.r = 0.0\n        marker.color.g = 1.0\n        marker.color.b = 0.0\n        marker.color.a = 1.0  # Alpha (opacity)\n\n        # Add points to the line strip\n        for x, y in self.path:\n            point = Point()\n            point.x = float(x)\n            point.y = float(y)\n            point.z = 0.0  # Assuming 2D navigation\n            marker.points.append(point)\n\n        self.path_marker_pub.publish(marker)\n\n    def navigate_to_waypoint(self):\n        """Generate commands to navigate to the current waypoint"""\n        if not self.path or self.current_waypoint_index >= len(self.path):\n            return Twist()\n\n        # Get current waypoint\n        target_x, target_y = self.path[self.current_waypoint_index]\n\n        # Calculate direction to waypoint\n        dx = target_x - self.current_x\n        dy = target_y - self.current_y\n        distance_to_waypoint = math.sqrt(dx*dx + dy*dy)\n\n        # Check if we\'ve reached the current waypoint\n        if distance_to_waypoint < self.waypoint_tolerance:\n            self.current_waypoint_index += 1\n\n            # Check if we\'ve reached the end of the path\n            if self.current_waypoint_index >= len(self.path):\n                # Check if we\'ve reached the final goal\n                goal_x, goal_y = self.goals[self.current_goal_index]\n                distance_to_goal = math.sqrt((goal_x - self.current_x)**2 + (goal_y - self.current_y)**2)\n\n                if distance_to_goal < self.waypoint_tolerance:\n                    # Reached current goal, move to next goal if available\n                    self.current_goal_index += 1\n                    if self.current_goal_index < len(self.goals):\n                        self.current_state = NavigationState.PLANNING\n                        self.get_logger().info(f\'Reached goal {self.current_goal_index}, moving to next goal\')\n                    else:\n                        self.current_state = NavigationState.IDLE\n                        self.get_logger().info(\'Reached all goals!\')\n                else:\n                    # We reached the end of the path but not the goal - replan\n                    self.current_state = NavigationState.REPLANNING\n            else:\n                # Move to next waypoint\n                target_x, target_y = self.path[self.current_waypoint_index]\n\n        # Recalculate direction to current waypoint\n        dx = target_x - self.current_x\n        dy = target_y - self.current_y\n        distance_to_waypoint = math.sqrt(dx*dx + dy*dy)\n        angle_to_waypoint = math.atan2(dy, dx)\n\n        # Normalize angle difference\n        angle_diff = angle_to_waypoint - self.current_yaw\n        while angle_diff > math.pi:\n            angle_diff -= 2 * math.pi\n        while angle_diff < -math.pi:\n            angle_diff += 2 * math.pi\n\n        # Create velocity command\n        cmd = Twist()\n        cmd.linear.x = min(0.8, max(0.1, distance_to_waypoint * 0.5))  # Speed based on distance\n        cmd.angular.z = max(-1.0, min(1.0, angle_diff * 1.5))  # Proportional control for heading\n\n        return cmd\n\n    def handle_obstacle_during_navigation(self):\n        """Handle obstacle detection during path following"""\n        if not self.laser_data:\n            return Twist()\n\n        # Simple obstacle avoidance while trying to maintain path following\n        cmd = Twist()\n\n        # Find the closest obstacle\n        ranges = self.laser_data[\'ranges\']\n        angles = np.linspace(\n            self.laser_data[\'angle_min\'],\n            self.laser_data[\'angle_max\'],\n            len(ranges)\n        )\n\n        closest_idx = np.argmin(ranges)\n        closest_distance = ranges[closest_idx]\n        closest_angle = angles[closest_idx]\n\n        # If obstacle is very close, prioritize avoidance\n        if closest_distance < self.replan_threshold:\n            # Emergency avoidance\n            cmd.linear.x = -0.2  # Slow reverse\n            cmd.angular.z = 0.8 if closest_angle < 0 else -0.8  # Turn away\n            self.current_state = NavigationState.REPLANNING\n        elif closest_distance < self.obstacle_threshold:\n            # Standard avoidance while maintaining heading toward waypoint\n            if closest_angle < 0:\n                # Obstacle on the left - turn right gently\n                cmd.linear.x = 0.3\n                cmd.angular.z = -0.5\n            else:\n                # Obstacle on the right - turn left gently\n                cmd.linear.x = 0.3\n                cmd.angular.z = 0.5\n        else:\n            # No immediate obstacles, continue with path following\n            cmd = self.navigate_to_waypoint()\n\n        return cmd\n\n    def control_loop(self):\n        """Main control loop with path planning integration"""\n        # Update robot position (in a real system, this would come from odometry)\n        # For simulation purposes, we\'ll just keep it at origin or update based on commands\n\n        # Execute state-specific behavior\n        cmd = Twist()\n\n        if self.current_state == NavigationState.IDLE:\n            # Wait for goals to be set\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n\n        elif self.current_state == NavigationState.PLANNING:\n            self.simple_path_planner()\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n\n        elif self.current_state == NavigationState.FOLLOWING_PATH:\n            if self.laser_data and self.laser_data[\'min_distance\'] < self.obstacle_threshold:\n                cmd = self.handle_obstacle_during_navigation()\n            else:\n                cmd = self.navigate_to_waypoint()\n\n        elif self.current_state == NavigationState.OBSTACLE_AVOIDANCE:\n            cmd = self.handle_obstacle_during_navigation()\n\n        elif self.current_state == NavigationState.REPLANNING:\n            # Stop temporarily while replanning\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n            # Trigger replanning in the next cycle\n            self.current_state = NavigationState.PLANNING\n\n        # Publish the command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Log current state and command\n        self.get_logger().info(\n            f\'State: {self.current_state.name}, \'\n            f\'Velocity: linear={cmd.linear.x:.2f}, angular={cmd.angular.z:.2f}, \'\n            f\'Goals: {self.current_goal_index}/{len(self.goals) if self.goals else 0}\'\n        )\n\ndef main(args=None):\n    rclpy.init(args=args)\n    path_planning_node = PathPlanningAINode()\n\n    # Example: Set some goals for the robot to visit\n    goals = [(2.0, 2.0), (4.0, 1.0), (5.0, 5.0), (1.0, 4.0)]\n    path_planning_node.set_goals(goals)\n\n    try:\n        rclpy.spin(path_planning_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        path_planning_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"solution-for-exercise-5-safety-and-validation-system",children:"Solution for Exercise 5: Safety and Validation System"}),"\n",(0,s.jsx)(n.h3,{id:"complete-safety-layer-code",children:"Complete Safety Layer Code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nfrom std_msgs.msg import Bool\nimport numpy as np\nimport math\n\nclass SafetySystemNode(Node):\n\n    def __init__(self):\n        super().__init__('safety_system_node')\n\n        # Subscriber for AI-generated commands\n        self.ai_cmd_sub = self.create_subscription(\n            Twist,\n            '/ai_cmd_vel',\n            self.ai_command_callback,\n            10\n        )\n\n        # Subscriber for sensor data\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10\n        )\n\n        # Publisher for validated/safe commands\n        self.safe_cmd_pub = self.create_publisher(\n            Twist,\n            '/safe_cmd_vel',\n            10\n        )\n\n        # Publisher for emergency stop\n        self.emergency_stop_pub = self.create_publisher(\n            Bool,\n            '/emergency_stop',\n            10\n        )\n\n        # Timer for safety monitoring\n        self.safety_timer = self.create_timer(0.05, self.safety_check)  # 20Hz safety check\n\n        # Internal state\n        self.ai_command = None\n        self.last_ai_command_time = None\n        self.laser_data = None\n\n        # Safety parameters\n        self.max_linear_velocity = 1.0      # m/s\n        self.max_angular_velocity = 1.5     # rad/s\n        self.max_linear_acceleration = 2.0  # m/s^2\n        self.max_angular_acceleration = 3.0 # rad/s^2\n        self.obstacle_distance_threshold = 0.5  # meters\n        self.collision_prediction_time = 1.0    # seconds\n        self.command_timeout = 0.5              # seconds\n\n        # Previous command for acceleration calculation\n        self.prev_command = Twist()\n        self.prev_command_time = None\n\n        # Emergency state\n        self.emergency_active = False\n        self.last_valid_command = Twist()\n\n        self.get_logger().info('Safety System Node initialized')\n\n    def ai_command_callback(self, msg):\n        \"\"\"Receive AI-generated commands\"\"\"\n        self.ai_command = msg\n        self.last_ai_command_time = self.get_clock().now()\n\n        if self.emergency_active:\n            self.get_logger().warn('AI command received during emergency stop - will not process until cleared')\n\n    def scan_callback(self, msg):\n        \"\"\"Process laser scan data for safety monitoring\"\"\"\n        ranges = np.array(msg.ranges)\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            self.laser_data = {\n                'ranges': valid_ranges,\n                'min_distance': np.min(valid_ranges),\n                'angle_min': msg.angle_min,\n                'angle_max': msg.angle_max,\n                'angle_increment': msg.angle_increment\n            }\n\n    def validate_velocity_limits(self, cmd):\n        \"\"\"Validate that velocities are within safe limits\"\"\"\n        validated_cmd = Twist()\n\n        # Linear velocity limits\n        validated_cmd.linear.x = max(-self.max_linear_velocity,\n                                   min(self.max_linear_velocity, cmd.linear.x))\n        validated_cmd.linear.y = max(-self.max_linear_velocity,\n                                   min(self.max_linear_velocity, cmd.linear.y))\n        validated_cmd.linear.z = max(-self.max_linear_velocity,\n                                   min(self.max_linear_velocity, cmd.linear.z))\n\n        # Angular velocity limits\n        validated_cmd.angular.x = max(-self.max_angular_velocity,\n                                    min(self.max_angular_velocity, cmd.angular.x))\n        validated_cmd.angular.y = max(-self.max_angular_velocity,\n                                    min(self.max_angular_velocity, cmd.angular.y))\n        validated_cmd.angular.z = max(-self.max_angular_velocity,\n                                    min(self.max_angular_velocity, cmd.angular.z))\n\n        return validated_cmd\n\n    def validate_acceleration_limits(self, cmd, prev_cmd, dt):\n        \"\"\"Validate that accelerations are within safe limits\"\"\"\n        if dt <= 0:\n            return cmd\n\n        validated_cmd = Twist()\n\n        # Calculate desired accelerations\n        linear_acc_x = (cmd.linear.x - prev_cmd.linear.x) / dt\n        linear_acc_y = (cmd.linear.y - prev_cmd.linear.y) / dt\n        linear_acc_z = (cmd.linear.z - prev_cmd.linear.z) / dt\n        angular_acc_x = (cmd.angular.x - prev_cmd.angular.x) / dt\n        angular_acc_y = (cmd.angular.y - prev_cmd.angular.y) / dt\n        angular_acc_z = (cmd.angular.z - prev_cmd.angular.z) / dt\n\n        # Limit accelerations\n        linear_acc_x = max(-self.max_linear_acceleration,\n                          min(self.max_linear_acceleration, linear_acc_x))\n        linear_acc_y = max(-self.max_linear_acceleration,\n                          min(self.max_linear_acceleration, linear_acc_y))\n        linear_acc_z = max(-self.max_linear_acceleration,\n                          min(self.max_linear_acceleration, linear_acc_z))\n        angular_acc_x = max(-self.max_angular_acceleration,\n                           min(self.max_angular_acceleration, angular_acc_x))\n        angular_acc_y = max(-self.max_angular_acceleration,\n                           min(self.max_angular_acceleration, angular_acc_y))\n        angular_acc_z = max(-self.max_angular_acceleration,\n                           min(self.max_angular_acceleration, angular_acc_z))\n\n        # Apply acceleration limits to get final velocities\n        validated_cmd.linear.x = prev_cmd.linear.x + linear_acc_x * dt\n        validated_cmd.linear.y = prev_cmd.linear.y + linear_acc_y * dt\n        validated_cmd.linear.z = prev_cmd.linear.z + linear_acc_z * dt\n        validated_cmd.angular.x = prev_cmd.angular.x + angular_acc_x * dt\n        validated_cmd.angular.y = prev_cmd.angular.y + angular_acc_y * dt\n        validated_cmd.angular.z = prev_cmd.angular.z + angular_acc_z * dt\n\n        # Also apply velocity limits after acceleration limiting\n        validated_cmd = self.validate_velocity_limits(validated_cmd)\n\n        return validated_cmd\n\n    def predict_collision(self, cmd):\n        \"\"\"Predict if the command will lead to a collision\"\"\"\n        if not self.laser_data:\n            return False\n\n        # Simple collision prediction: if the robot would move into space closer than threshold\n        # within the prediction time\n\n        # Calculate predicted position based on current command\n        predicted_forward_distance = cmd.linear.x * self.collision_prediction_time\n        predicted_turn_angle = cmd.angular.z * self.collision_prediction_time\n\n        # Check if moving forward would hit an obstacle\n        if predicted_forward_distance > 0 and self.laser_data['min_distance'] < predicted_forward_distance + 0.2:\n            return True\n\n        # For simplicity, we'll just check if there are obstacles directly ahead\n        # In a real system, this would involve more complex geometric calculations\n        ranges = self.laser_data['ranges']\n        angles = np.linspace(\n            self.laser_data['angle_min'],\n            self.laser_data['angle_max'],\n            len(ranges)\n        )\n\n        # Check the front sector (\xb130 degrees)\n        front_mask = (angles >= -math.pi/6) & (angles <= math.pi/6)\n        front_ranges = ranges[front_mask]\n\n        if len(front_ranges) > 0 and np.min(front_ranges) < self.obstacle_distance_threshold:\n            if cmd.linear.x > 0:  # Moving forward toward obstacles\n                return True\n\n        return False\n\n    def safety_check(self):\n        \"\"\"Main safety monitoring function\"\"\"\n        current_time = self.get_clock().now()\n\n        # Check for command timeout\n        if (self.last_ai_command_time and\n            (current_time - self.last_ai_command_time).nanoseconds / 1e9 > self.command_timeout):\n            self.get_logger().warn('AI command timeout - stopping robot')\n            self.emergency_stop()\n            return\n\n        # If emergency is active, only publish stop command\n        if self.emergency_active:\n            stop_cmd = Twist()\n            self.safe_cmd_pub.publish(stop_cmd)\n            return\n\n        # Process AI command if available\n        if self.ai_command:\n            # Get time delta for acceleration calculation\n            dt = 0.0\n            if self.prev_command_time:\n                dt = (current_time - self.prev_command_time).nanoseconds / 1e9\n\n            # Apply safety validations\n            safe_cmd = self.ai_command\n\n            # Validate velocity limits\n            safe_cmd = self.validate_velocity_limits(safe_cmd)\n\n            # Validate acceleration limits\n            if dt > 0:\n                safe_cmd = self.validate_acceleration_limits(safe_cmd, self.prev_command, dt)\n\n            # Predict and avoid collisions\n            if self.predict_collision(safe_cmd):\n                self.get_logger().warn('Collision predicted - reducing velocity/turning')\n                # Reduce linear velocity and increase turning to avoid obstacle\n                safe_cmd.linear.x *= 0.3  # Reduce forward speed significantly\n                # Maintain some angular control to turn away from obstacle\n                if safe_cmd.linear.x > 0:  # If moving forward\n                    # Add a turn component to avoid obstacle\n                    if self.laser_data and len(self.laser_data['ranges']) > 0:\n                        # Find the direction with most clearance\n                        ranges = self.laser_data['ranges']\n                        angles = np.linspace(\n                            self.laser_data['angle_min'],\n                            self.laser_data['angle_max'],\n                            len(ranges)\n                        )\n\n                        # Find the angle with maximum range (most clearance)\n                        max_range_idx = np.argmax(ranges)\n                        max_range_angle = angles[max_range_idx]\n\n                        # Adjust angular velocity to turn toward clearer direction\n                        safe_cmd.angular.z = max(-self.max_angular_velocity,\n                                               min(self.max_angular_velocity,\n                                                   max_range_angle * 0.5))\n\n            # Publish the validated command\n            self.safe_cmd_pub.publish(safe_cmd)\n\n            # Update previous command and time\n            self.prev_command = safe_cmd\n            self.prev_command_time = current_time\n            self.last_valid_command = safe_cmd\n\n            # Log safety check results\n            self.get_logger().info(\n                f'Safe Cmd: linear={safe_cmd.linear.x:.2f}, angular={safe_cmd.angular.z:.2f}, '\n                f'Min Obs: {self.laser_data[\"min_distance\"]:.2f}m' if self.laser_data else ''\n            )\n\n    def emergency_stop(self):\n        \"\"\"Trigger emergency stop\"\"\"\n        if not self.emergency_active:\n            self.emergency_active = True\n            self.get_logger().fatal('EMERGENCY STOP ACTIVATED')\n\n            # Publish emergency stop signal\n            emergency_msg = Bool()\n            emergency_msg.data = True\n            self.emergency_stop_pub.publish(emergency_msg)\n\n            # Publish stop command\n            stop_cmd = Twist()\n            self.safe_cmd_pub.publish(stop_cmd)\n\n    def emergency_clear(self):\n        \"\"\"Clear emergency stop\"\"\"\n        if self.emergency_active:\n            self.emergency_active = False\n            self.get_logger().info('Emergency stop cleared')\n\n            # Publish emergency clear signal\n            emergency_msg = Bool()\n            emergency_msg.data = False\n            self.emergency_stop_pub.publish(emergency_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    safety_node = SafetySystemNode()\n\n    try:\n        rclpy.spin(safety_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        safety_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"solution-for-exercise-6-learning-based-behavior-advanced",children:"Solution for Exercise 6: Learning-Based Behavior (Advanced)"}),"\n",(0,s.jsx)(n.h3,{id:"complete-learning-based-ai-agent-code",children:"Complete Learning-Based AI Agent Code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist, Odometry\nfrom nav_msgs.msg import OccupancyGrid\nimport numpy as np\nimport math\nimport json\nimport os\nfrom datetime import datetime\n\nclass LearningAINode(Node):\n\n    def __init__(self):\n        super().__init__('learning_ai_node')\n\n        # Create subscribers\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10\n        )\n\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            '/odom',\n            self.odom_callback,\n            10\n        )\n\n        # Publisher for velocity commands\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            '/cmd_vel',\n            10\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)\n\n        # Internal state\n        self.laser_data = None\n        self.current_x = 0.0\n        self.current_y = 0.0\n        self.current_yaw = 0.0\n        self.start_x = 0.0\n        self.start_y = 0.0\n        self.current_run_start_time = None\n\n        # Learning parameters\n        self.learning_enabled = True\n        self.experience_buffer = []  # Store experiences for learning\n        self.max_experience_buffer_size = 1000\n\n        # Navigation goal\n        self.goal_x = 5.0\n        self.goal_y = 5.0\n\n        # Learnable parameters\n        self.params = {\n            'obstacle_weight': 1.0,      # How much to avoid obstacles\n            'goal_weight': 1.0,          # How much to pursue goal\n            'speed_factor': 0.5,         # Base speed factor\n            'turn_sensitivity': 0.5,     # How sensitive turning is\n            'collision_penalty': 5.0,    # Penalty for getting too close to obstacles\n            'efficiency_bonus': 0.1      # Bonus for efficient navigation\n        }\n\n        # Performance metrics\n        self.run_count = 0\n        self.success_count = 0\n        self.total_time = 0.0\n        self.total_collisions = 0\n        self.performance_history = []\n\n        # Load saved parameters if available\n        self.load_parameters()\n\n        self.get_logger().info(f'Learning AI Node initialized with params: {self.params}')\n\n    def scan_callback(self, msg):\n        \"\"\"Process incoming laser scan data\"\"\"\n        ranges = np.array(msg.ranges)\n        valid_ranges = ranges[np.isfinite(ranges)]\n\n        if len(valid_ranges) > 0:\n            self.laser_data = {\n                'ranges': valid_ranges,\n                'min_distance': np.min(valid_ranges),\n                'angle_min': msg.angle_min,\n                'angle_max': msg.angle_max,\n                'angle_increment': msg.angle_increment\n            }\n\n    def odom_callback(self, msg):\n        \"\"\"Process odometry data\"\"\"\n        self.current_x = msg.pose.pose.position.x\n        self.current_y = msg.pose.pose.position.y\n\n        # Convert quaternion to yaw\n        quat = msg.pose.pose.orientation\n        siny_cosp = 2 * (quat.w * quat.z + quat.x * quat.y)\n        cosy_cosp = 1 - 2 * (quat.y * quat.y + quat.z * quat.z)\n        self.current_yaw = math.atan2(siny_cosp, cosy_cosp)\n\n    def calculate_reward(self):\n        \"\"\"Calculate reward based on current state and action\"\"\"\n        if not self.laser_data:\n            return 0.0\n\n        # Distance to goal\n        distance_to_goal = math.sqrt((self.goal_x - self.current_x)**2 + (self.goal_y - self.current_y)**2)\n\n        # Reward for getting closer to goal\n        goal_reward = -distance_to_goal  # Negative because closer is better\n\n        # Penalty for being too close to obstacles\n        min_distance = self.laser_data['min_distance']\n        obstacle_penalty = 0.0\n        if min_distance < 0.5:\n            obstacle_penalty = -self.params['collision_penalty'] / min_distance if min_distance > 0 else -float('inf')\n\n        # Small bonus for moving efficiently toward goal\n        efficiency_bonus = 0.0\n        if hasattr(self, '_prev_distance_to_goal'):\n            if distance_to_goal < self._prev_distance_to_goal:\n                efficiency_bonus = self.params['efficiency_bonus']\n\n        # Total reward\n        total_reward = goal_reward + obstacle_penalty + efficiency_bonus\n\n        # Store for next iteration\n        self._prev_distance_to_goal = distance_to_goal\n\n        return total_reward\n\n    def simple_navigation_policy(self):\n        \"\"\"Basic navigation policy that uses learnable parameters\"\"\"\n        if not self.laser_data:\n            return Twist()\n\n        cmd = Twist()\n\n        # Calculate direction to goal\n        dx = self.goal_x - self.current_x\n        dy = self.goal_y - self.current_y\n        distance_to_goal = math.sqrt(dx*dx + dy*dy)\n        angle_to_goal = math.atan2(dy, dx)\n\n        # Normalize angle difference\n        angle_diff = angle_to_goal - self.current_yaw\n        while angle_diff > math.pi:\n            angle_diff -= 2 * math.pi\n        while angle_diff < -math.pi:\n            angle_diff += 2 * math.pi\n\n        # Get obstacle information\n        min_distance = self.laser_data['min_distance']\n        ranges = self.laser_data['ranges']\n        angles = np.linspace(\n            self.laser_data['angle_min'],\n            self.laser_data['angle_max'],\n            len(ranges)\n        )\n\n        # Find direction of most clearance (away from obstacles)\n        max_range_idx = np.argmax(ranges)\n        max_range_angle = angles[max_range_idx]\n\n        # Combine goal-seeking and obstacle-avoidance behaviors using learned weights\n        if min_distance < 1.0:  # Significant obstacle detected\n            # Weighted combination of goal direction and obstacle avoidance\n            weighted_angle = (self.params['goal_weight'] * angle_diff +\n                            self.params['obstacle_weight'] * max_range_angle) / \\\n                           (self.params['goal_weight'] + self.params['obstacle_weight'])\n        else:\n            # Mainly follow goal direction\n            weighted_angle = angle_diff\n\n        # Set velocities based on learned parameters\n        cmd.linear.x = min(1.0, max(0.1, self.params['speed_factor'] * (distance_to_goal * 0.2)))\n        cmd.angular.z = max(-1.0, min(1.0, weighted_angle * self.params['turn_sensitivity']))\n\n        # Reduce speed when close to obstacles\n        if min_distance < 1.5:\n            cmd.linear.x *= (min_distance / 1.5)\n\n        return cmd\n\n    def simple_learning_algorithm(self):\n        \"\"\"Simple parameter learning algorithm\"\"\"\n        if not self.experience_buffer or len(self.experience_buffer) < 10:\n            return  # Not enough experience to learn\n\n        # Calculate average performance over recent experiences\n        recent_experiences = self.experience_buffer[-50:]  # Last 50 experiences\n        avg_reward = sum(exp['reward'] for exp in recent_experiences) / len(recent_experiences)\n\n        # Performance indicators\n        distance_traveled = math.sqrt((self.current_x - self.start_x)**2 + (self.current_y - self.start_y)**2)\n        time_elapsed = (self.get_clock().now() - self.current_run_start_time).nanoseconds / 1e9 if self.current_run_start_time else 0\n\n        # Adjust parameters based on performance\n        # This is a very simple learning approach - in practice, you'd use more sophisticated methods\n        learning_rate = 0.01\n\n        # If we're making good progress, slightly increase goal weight\n        if avg_reward > -2.0 and self.params['goal_weight'] < 2.0:\n            self.params['goal_weight'] += learning_rate\n        elif avg_reward < -5.0 and self.params['goal_weight'] > 0.5:\n            self.params['goal_weight'] -= learning_rate\n\n        # If we're hitting obstacles frequently, increase obstacle avoidance\n        if self.laser_data and self.laser_data['min_distance'] < 0.5:\n            self.params['obstacle_weight'] = min(3.0, self.params['obstacle_weight'] + learning_rate * 2)\n        else:\n            self.params['obstacle_weight'] = max(0.5, self.params['obstacle_weight'] - learning_rate)\n\n        # Adjust speed based on obstacle proximity history\n        avg_min_dist = np.mean([exp['state']['min_distance'] for exp in recent_experiences if 'min_distance' in exp['state']])\n        if avg_min_dist < 0.8:\n            self.params['speed_factor'] = max(0.2, self.params['speed_factor'] - learning_rate)\n        elif avg_min_dist > 1.2:\n            self.params['speed_factor'] = min(1.0, self.params['speed_factor'] + learning_rate)\n\n        self.get_logger().info(f'Learned params: {self.params}')\n\n    def save_experience(self, state, action, reward, next_state):\n        \"\"\"Store experience tuple for learning\"\"\"\n        experience = {\n            'timestamp': self.get_clock().now().nanoseconds,\n            'state': state.copy() if state else {},\n            'action': (action.linear.x, action.angular.z),\n            'reward': reward,\n            'next_state': next_state.copy() if next_state else {}\n        }\n\n        self.experience_buffer.append(experience)\n\n        # Keep buffer size manageable\n        if len(self.experience_buffer) > self.max_experience_buffer_size:\n            self.experience_buffer.pop(0)\n\n    def save_parameters(self):\n        \"\"\"Save learned parameters to file\"\"\"\n        params_file = 'learned_params.json'\n        params_data = {\n            'params': self.params,\n            'run_count': self.run_count,\n            'success_count': self.success_count,\n            'total_time': self.total_time,\n            'total_collisions': self.total_collisions,\n            'performance_history': self.performance_history[-100:],  # Keep last 100 runs\n            'saved_at': datetime.now().isoformat()\n        }\n\n        try:\n            with open(params_file, 'w') as f:\n                json.dump(params_data, f, indent=2)\n            self.get_logger().info(f'Parameters saved to {params_file}')\n        except Exception as e:\n            self.get_logger().error(f'Failed to save parameters: {e}')\n\n    def load_parameters(self):\n        \"\"\"Load learned parameters from file\"\"\"\n        params_file = 'learned_params.json'\n\n        if os.path.exists(params_file):\n            try:\n                with open(params_file, 'r') as f:\n                    params_data = json.load(f)\n\n                self.params.update(params_data.get('params', {}))\n                self.run_count = params_data.get('run_count', 0)\n                self.success_count = params_data.get('success_count', 0)\n                self.total_time = params_data.get('total_time', 0.0)\n                self.total_collisions = params_data.get('total_collisions', 0)\n                self.performance_history = params_data.get('performance_history', [])\n\n                self.get_logger().info(f'Parameters loaded from {params_file}: {self.params}')\n            except Exception as e:\n                self.get_logger().error(f'Failed to load parameters: {e}')\n        else:\n            self.get_logger().info('No saved parameters found, using defaults')\n\n    def evaluate_performance(self):\n        \"\"\"Evaluate current run performance\"\"\"\n        distance_to_goal = math.sqrt((self.goal_x - self.current_x)**2 + (self.goal_y - self.current_y)**2)\n\n        # Check if we reached the goal (within tolerance)\n        goal_reached = distance_to_goal < 0.5\n\n        # Calculate time taken\n        time_taken = 0.0\n        if self.current_run_start_time:\n            time_taken = (self.get_clock().now() - self.current_run_start_time).nanoseconds / 1e9\n\n        # Calculate collisions (when robot got too close to obstacles)\n        collision_count = 0\n        if self.laser_data and self.laser_data['min_distance'] < 0.3:\n            collision_count = 1  # Simplified collision detection\n\n        return {\n            'success': goal_reached,\n            'time_taken': time_taken,\n            'collisions': collision_count,\n            'distance_to_goal': distance_to_goal\n        }\n\n    def control_loop(self):\n        \"\"\"Main control loop with learning capability\"\"\"\n        # Initialize run if just starting\n        if self.current_run_start_time is None:\n            self.start_x = self.current_x\n            self.start_y = self.current_y\n            self.current_run_start_time = self.get_clock().now()\n\n        # Get current state\n        current_state = {\n            'x': self.current_x,\n            'y': self.current_y,\n            'yaw': self.current_yaw,\n            'min_distance': self.laser_data['min_distance'] if self.laser_data else float('inf')\n        }\n\n        # Generate command using current policy\n        cmd = self.simple_navigation_policy()\n\n        # Calculate reward for current state-action pair\n        reward = self.calculate_reward()\n\n        # Store experience for learning\n        self.save_experience(current_state, cmd, reward, {\n            'x': self.current_x,\n            'y': self.current_y,\n            'yaw': self.current_yaw,\n            'min_distance': self.laser_data['min_distance'] if self.laser_data else float('inf')\n        })\n\n        # Periodically perform learning update\n        if len(self.experience_buffer) % 20 == 0 and self.learning_enabled:\n            self.simple_learning_algorithm()\n\n        # Evaluate performance and check for run completion\n        perf = self.evaluate_performance()\n\n        if perf['success']:\n            # Run completed successfully\n            self.run_count += 1\n            self.success_count += 1\n            self.total_time += perf['time_taken']\n            self.total_collisions += perf['collisions']\n\n            avg_time = self.total_time / self.success_count if self.success_count > 0 else 0\n            success_rate = self.success_count / self.run_count if self.run_count > 0 else 0\n\n            self.performance_history.append({\n                'run': self.run_count,\n                'success': True,\n                'time': perf['time_taken'],\n                'collisions': perf['collisions'],\n                'avg_time': avg_time,\n                'success_rate': success_rate\n            })\n\n            self.get_logger().info(\n                f'GOAL REACHED! Run #{self.run_count}, '\n                f'Success Rate: {success_rate:.2%}, Avg Time: {avg_time:.2f}s'\n            )\n\n            # Save parameters after successful run\n            self.save_parameters()\n\n            # Reset for next run\n            self.current_run_start_time = None\n\n        elif perf['time_taken'] > 60:  # Timeout after 60 seconds\n            # Run timed out\n            self.run_count += 1\n            self.total_time += perf['time_taken']\n            self.total_collisions += perf['collisions']\n\n            self.performance_history.append({\n                'run': self.run_count,\n                'success': False,\n                'time': perf['time_taken'],\n                'collisions': perf['collisions'],\n                'avg_time': self.total_time / self.run_count if self.run_count > 0 else 0,\n                'success_rate': self.success_count / self.run_count if self.run_count > 0 else 0\n            })\n\n            self.get_logger().info(f'RUN TIMED OUT (60s). Success rate: {self.success_count}/{self.run_count}')\n\n            # Reset for next run\n            self.current_run_start_time = None\n\n        # Publish the command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Log current status periodically\n        if self.get_clock().now().nanoseconds % 1000000000 < 100000000:  # Every ~1 second\n            self.get_logger().info(\n                f'Learning AI - Pos:({self.current_x:.2f},{self.current_y:.2f}), '\n                f'Goal Dist:{perf[\"distance_to_goal\"]:.2f}m, '\n                f'Cmd:(lin={cmd.linear.x:.2f}, ang={cmd.angular.z:.2f}), '\n                f'Success Rate:{self.success_count}/{self.run_count}'\n            )\n\ndef main(args=None):\n    rclpy.init(args=args)\n    learning_node = LearningAINode()\n\n    try:\n        rclpy.spin(learning_node)\n    except KeyboardInterrupt:\n        # Save parameters before shutting down\n        learning_node.save_parameters()\n        pass\n    finally:\n        learning_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"implementation-guide",children:"Implementation Guide"}),"\n",(0,s.jsx)(n.h3,{id:"for-exercise-1-basic-ai-agent",children:"For Exercise 1 (Basic AI Agent):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create the AI agent node with laser scan subscription"}),"\n",(0,s.jsxs)(n.li,{children:["Implement obstacle detection logic using ",(0,s.jsx)(n.code,{children:"np.min()"})," on valid ranges"]}),"\n",(0,s.jsx)(n.li,{children:"Create simple navigation behaviors based on obstacle distances"}),"\n",(0,s.jsx)(n.li,{children:"Test in simulation with a robot that has laser range finder"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"for-exercise-2-multi-sensor-integration",children:"For Exercise 2 (Multi-Sensor Integration):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Set up multiple subscribers for different sensor types"}),"\n",(0,s.jsx)(n.li,{children:"Implement data synchronization using timestamps"}),"\n",(0,s.jsx)(n.li,{children:"Create a sensor fusion algorithm to combine sensor inputs"}),"\n",(0,s.jsx)(n.li,{children:"Use the fused state for improved navigation decisions"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"for-exercise-3-behavior-based-control",children:"For Exercise 3 (Behavior-Based Control):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Define behavior states using an Enum"}),"\n",(0,s.jsx)(n.li,{children:"Implement each behavior as a separate method"}),"\n",(0,s.jsx)(n.li,{children:"Create a state machine to manage transitions between behaviors"}),"\n",(0,s.jsx)(n.li,{children:"Use priority-based conflict resolution for competing behaviors"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"for-exercise-4-path-planning-integration",children:"For Exercise 4 (Path Planning Integration):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Implement a simple path planner (straight-line with intermediate waypoints)"}),"\n",(0,s.jsx)(n.li,{children:"Create a waypoint follower that navigates along the planned path"}),"\n",(0,s.jsx)(n.li,{children:"Integrate obstacle avoidance with path following"}),"\n",(0,s.jsx)(n.li,{children:"Implement replanning when obstacles block the path"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"for-exercise-5-safety-and-validation",children:"For Exercise 5 (Safety and Validation):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create a separate safety node that intercepts AI commands"}),"\n",(0,s.jsx)(n.li,{children:"Implement velocity and acceleration limits"}),"\n",(0,s.jsx)(n.li,{children:"Add collision prediction and avoidance"}),"\n",(0,s.jsx)(n.li,{children:"Include emergency stop functionality"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"for-exercise-6-learning-based-behavior",children:"For Exercise 6 (Learning-Based Behavior):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Implement a simple learning algorithm that adjusts parameters based on performance"}),"\n",(0,s.jsx)(n.li,{children:"Track performance metrics over multiple runs"}),"\n",(0,s.jsx)(n.li,{children:"Store learned parameters to persist across sessions"}),"\n",(0,s.jsx)(n.li,{children:"Use rewards to guide learning toward better navigation strategies"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Modular Design"}),": Keep each exercise implementation modular and reusable"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Error Handling"}),": Always check for null data and handle edge cases"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Logging"}),": Use appropriate logging to track robot behavior and debugging information"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter Tuning"}),": Use ROS parameters for easy tuning of behavior"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Safety First"}),": Always implement safety checks, especially when working with real robots"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simulation Testing"}),": Test extensively in simulation before deploying to real hardware"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance Monitoring"}),": Track performance metrics to measure improvement over time"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These solutions provide complete implementations for each exercise, demonstrating how to bridge AI agents with robot controllers using ROS 2. Each solution builds on the previous ones, showing progressive complexity from basic sensor processing to learning-based navigation."})]})}function _(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,a){a.d(n,{R:()=>r,x:()=>l});var t=a(6540);const s={},i=t.createContext(s);function r(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);