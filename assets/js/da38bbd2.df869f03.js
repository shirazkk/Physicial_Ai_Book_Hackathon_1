"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[1913],{8453(e,n,s){s.d(n,{R:()=>r,x:()=>o});var t=s(6540);const a={},l=t.createContext(a);function r(e){const n=t.useContext(l);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(l.Provider,{value:n},e.children)}},9732(e,n,s){s.r(n),s.d(n,{assets:()=>i,contentTitle:()=>o,default:()=>f,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2-robotic-nervous-system/chapter-4/robotic-nervous-system-patterns","title":"Implementing Robotic Nervous System Patterns","description":"Learning Objectives","source":"@site/docs/module-2-robotic-nervous-system/chapter-4/robotic-nervous-system-patterns.md","sourceDirName":"module-2-robotic-nervous-system/chapter-4","slug":"/module-2-robotic-nervous-system/chapter-4/robotic-nervous-system-patterns","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-4/robotic-nervous-system-patterns","draft":false,"unlisted":false,"editUrl":"https://github.com/shirazkk/Physicial_Ai_Book_Hackathon_1/edit/main/my-website/docs/module-2-robotic-nervous-system/chapter-4/robotic-nervous-system-patterns.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Solutions: Understanding URDF for Humanoid Robot Description and Control","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-3/solutions"},"next":{"title":"Exercises: Implementing Robotic Nervous System Patterns","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-4/exercises"}}');var a=s(4848),l=s(8453);const r={},o="Implementing Robotic Nervous System Patterns",i={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. Biological Nervous System Principles",id:"1-biological-nervous-system-principles",level:2},{value:"1.1 Neural Network Organization",id:"11-neural-network-organization",level:3},{value:"1.2 Sensorimotor Integration",id:"12-sensorimotor-integration",level:3},{value:"2. Distributed Control Architectures",id:"2-distributed-control-architectures",level:2},{value:"2.1 Node-Based Nervous System",id:"21-node-based-nervous-system",level:3},{value:"2.2 Communication Patterns",id:"22-communication-patterns",level:3},{value:"3. Reflex-Based Control Systems",id:"3-reflex-based-control-systems",level:2},{value:"3.1 Implementing Reflex Arcs",id:"31-implementing-reflex-arcs",level:3},{value:"4. Hierarchical Control Structures",id:"4-hierarchical-control-structures",level:2},{value:"4.1 Multi-Level Control Hierarchy",id:"41-multi-level-control-hierarchy",level:3},{value:"4.2 Coordination Between Levels",id:"42-coordination-between-levels",level:3},{value:"5. Adaptive Control Systems",id:"5-adaptive-control-systems",level:2},{value:"5.1 Learning-Based Adaptation",id:"51-learning-based-adaptation",level:3},{value:"6. Practical Example: Complete Robotic Nervous System",id:"6-practical-example-complete-robotic-nervous-system",level:2},{value:"7. Exercises and Practice",id:"7-exercises-and-practice",level:2},{value:"8. Summary",id:"8-summary",level:2},{value:"9. Further Reading",id:"9-further-reading",level:2},{value:"10. Links to External Resources",id:"10-links-to-external-resources",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"implementing-robotic-nervous-system-patterns",children:"Implementing Robotic Nervous System Patterns"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this chapter, readers will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Understand biological nervous system principles and their application to robotics"}),"\n",(0,a.jsx)(n.li,{children:"Design distributed control architectures for humanoid robots using ROS 2"}),"\n",(0,a.jsx)(n.li,{children:"Implement reflex-based control systems for autonomous robot behavior"}),"\n",(0,a.jsx)(n.li,{children:"Create hierarchical control structures that mimic biological neural organization"}),"\n",(0,a.jsx)(n.li,{children:"Apply sensorimotor integration techniques for responsive robot behavior"}),"\n",(0,a.jsx)(n.li,{children:"Implement adaptive control systems that learn and adjust to environmental changes"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Completion of Chapter 1: Understanding ROS 2 Architecture and Communication Patterns"}),"\n",(0,a.jsx)(n.li,{children:"Completion of Chapter 2: Bridging Python-based AI Agents to Robot Controllers"}),"\n",(0,a.jsx)(n.li,{children:"Completion of Chapter 3: Understanding URDF for Humanoid Robot Description and Control"}),"\n",(0,a.jsx)(n.li,{children:"Understanding of basic neuroscience concepts"}),"\n",(0,a.jsx)(n.li,{children:"Knowledge of distributed systems and control theory"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsx)(n.p,{children:"The concept of a robotic nervous system draws inspiration from biological neural networks to create sophisticated control architectures for humanoid robots. Just as biological nervous systems coordinate complex behaviors through distributed processing, robotic nervous systems enable coordinated control of multiple actuators and sensors through distributed ROS 2 nodes that communicate in patterns similar to neural networks."}),"\n",(0,a.jsx)(n.p,{children:"This chapter explores how to implement nervous system-inspired patterns in robotic systems using ROS 2, creating architectures that exhibit properties like reflexive responses, hierarchical control, and adaptive behavior. These patterns enable robots to respond quickly to environmental stimuli while maintaining coordinated behavior across multiple subsystems."}),"\n",(0,a.jsx)(n.h2,{id:"1-biological-nervous-system-principles",children:"1. Biological Nervous System Principles"}),"\n",(0,a.jsx)(n.h3,{id:"11-neural-network-organization",children:"1.1 Neural Network Organization"}),"\n",(0,a.jsx)(n.p,{children:"Biological nervous systems are organized hierarchically with multiple levels of control:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Reflex Arcs"}),": Immediate responses to stimuli without brain involvement"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Spinal Cord Processing"}),": Local processing of sensorimotor information"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Brain Stem"}),": Basic life-sustaining functions and arousal"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cerebral Cortex"}),": Higher-level planning and decision making"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"In robotics, we can implement similar hierarchies using ROS 2 nodes:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, JointState\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Bool, Float64\nimport numpy as np\n\nclass RoboticNervousSystem(Node):\n    """\n    A hierarchical control system inspired by biological nervous systems.\n    Implements reflex arcs, spinal cord processing, and higher-level planning.\n    """\n\n    def __init__(self):\n        super().__init__(\'robotic_nervous_system\')\n\n        # Reflex arc level: immediate responses to dangerous stimuli\n        self.laser_sub = self.create_subscription(\n            LaserScan, \'/scan\', self.laser_callback, 10)\n\n        # Spinal cord level: local sensorimotor processing\n        self.joint_state_sub = self.create_subscription(\n            JointState, \'/joint_states\', self.joint_state_callback, 10)\n\n        # Motor command publishers for different control levels\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.joint_cmd_pub = self.create_publisher(JointState, \'/joint_commands\', 10)\n\n        # Reflex control timer (high frequency for immediate responses)\n        self.reflex_timer = self.create_timer(0.01, self.reflex_control)  # 100 Hz\n\n        # Spinal cord processing timer (medium frequency)\n        self.spinal_timer = self.create_timer(0.05, self.spinal_processing)  # 20 Hz\n\n        # Higher-level planning timer (lower frequency)\n        self.planning_timer = self.create_timer(0.1, self.planning_control)  # 10 Hz\n\n        # Internal state\n        self.laser_data = None\n        self.joint_states = None\n        self.emergency_stop = False\n\n        # Reflex thresholds\n        self.collision_threshold = 0.3  # meters\n        self.approach_threshold = 0.8   # meters\n\n        self.get_logger().info(\'Robotic Nervous System initialized\')\n\n    def laser_callback(self, msg):\n        """Process laser scan data - immediate sensory input"""\n        self.laser_data = np.array(msg.ranges)\n        # Filter invalid readings\n        self.laser_data[self.laser_data == float(\'inf\')] = 3.5\n        self.laser_data[np.isnan(self.laser_data)] = 3.5\n\n    def joint_state_callback(self, msg):\n        """Process joint state data - proprioceptive input"""\n        self.joint_states = msg\n\n    def reflex_control(self):\n        """\n        Reflex arc level control - immediate responses to dangerous situations.\n        This mimics the spinal cord\'s ability to respond to threats without brain involvement.\n        """\n        if self.laser_data is None or self.emergency_stop:\n            return\n\n        # Check for immediate collision danger (reflex response)\n        min_distance = np.min(self.laser_data) if self.laser_data.size > 0 else float(\'inf\')\n\n        if min_distance < self.collision_threshold:\n            # Emergency stop reflex - immediate halt\n            self.emergency_stop = True\n            self.get_logger().warn(\'REFLEX: Emergency stop activated - collision imminent!\')\n\n            # Publish emergency stop command\n            stop_cmd = Twist()\n            self.cmd_vel_pub.publish(stop_cmd)\n\n            # Also send joint stop commands\n            joint_stop = JointState()\n            joint_stop.position = [0.0] * len(self.joint_states.name) if self.joint_states else []\n            self.joint_cmd_pub.publish(joint_stop)\n\n            # Emergency stop timer to reset after safety period\n            self.create_timer(1.0, self.reset_emergency_stop)\n\n    def reset_emergency_stop(self):\n        """Reset emergency stop after safety period"""\n        self.emergency_stop = False\n        self.get_logger().info(\'REFLEX: Emergency stop reset\')\n\n    def spinal_processing(self):\n        """\n        Spinal cord level processing - local sensorimotor coordination.\n        Processes sensory information and generates coordinated motor responses.\n        """\n        if self.loint_data is None or self.emergency_stop:\n            return\n\n        # Approach reflex - slow down when approaching obstacles\n        min_distance = np.min(self.laser_data) if self.laser_data.size > 0 else float(\'inf\')\n\n        if min_distance < self.approach_threshold and min_distance > self.collision_threshold:\n            # Approach reflex - reduce speed proportionally to obstacle proximity\n            speed_reduction = 1.0 - (min_distance - self.collision_threshold) / (self.approach_threshold - self.collision_threshold)\n\n            # Send speed reduction command\n            cmd = Twist()\n            cmd.linear.x = 0.5 * (1.0 - speed_reduction)  # Reduce forward speed\n            cmd.angular.z = 0.0  # Maintain current heading\n            self.cmd_vel_pub.publish(cmd)\n\n    def planning_control(self):\n        """\n        Higher-level planning - cognitive control similar to cortical processing.\n        Makes decisions based on goals, environment, and internal state.\n        """\n        if self.laser_data is None or self.emergency_stop:\n            return\n\n        # Example: Goal-oriented navigation with obstacle awareness\n        min_distance = np.min(self.laser_data) if self.laser_data.size > 0 else float(\'inf\')\n\n        cmd = Twist()\n\n        if min_distance > self.approach_threshold:\n            # Clear path - move toward goal\n            cmd.linear.x = 0.8  # Move forward at higher speed\n            cmd.angular.z = 0.0  # Maintain heading\n        elif min_distance > self.collision_threshold:\n            # Moderate obstacle - navigate around\n            cmd.linear.x = 0.3  # Slower forward motion\n            # Simple obstacle avoidance (turn away from closest obstacle)\n            if self.laser_data.size > 0:\n                closest_idx = np.argmin(self.laser_data)\n                if closest_idx < len(self.laser_data) / 2:\n                    # Obstacle on left - turn right\n                    cmd.angular.z = -0.5\n                else:\n                    # Obstacle on right - turn left\n                    cmd.angular.z = 0.5\n\n        self.cmd_vel_pub.publish(cmd)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    nervous_system = RoboticNervousSystem()\n\n    try:\n        rclpy.spin(nervous_system)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        nervous_system.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"12-sensorimotor-integration",children:"1.2 Sensorimotor Integration"}),"\n",(0,a.jsx)(n.p,{children:"Biological systems integrate sensory information from multiple modalities to generate coordinated motor responses. In robotics, this translates to fusing data from various sensors to control actuators effectively."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class SensorimotorIntegration(Node):\n    \"\"\"\n    Implements sensorimotor integration similar to biological systems.\n    Combines multiple sensory inputs to generate coordinated motor outputs.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('sensorimotor_integration')\n\n        # Multiple sensor inputs\n        self.laser_sub = self.create_subscription(LaserScan, '/scan', self.laser_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, '/imu', self.imu_callback, 10)\n        self.odom_sub = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)\n        self.joint_sub = self.create_subscription(JointState, '/joint_states', self.joint_callback, 10)\n\n        # Motor command outputs\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.joint_cmd_pub = self.create_publisher(JointState, '/joint_commands', 10)\n\n        # Integration timer\n        self.integration_timer = self.create_timer(0.02, self.sensorimotor_loop)  # 50 Hz\n\n        # Internal state\n        self.sensors = {\n            'laser': None,\n            'imu': None,\n            'odom': None,\n            'joints': None\n        }\n\n        # Integration weights for different sensory modalities\n        self.integration_weights = {\n            'obstacle_avoidance': 0.4,\n            'balance': 0.3,\n            'navigation': 0.3\n        }\n\n        self.get_logger().info('Sensorimotor Integration Node initialized')\n\n    def laser_callback(self, msg):\n        self.sensors['laser'] = msg\n\n    def imu_callback(self, msg):\n        self.sensors['imu'] = msg\n\n    def odom_callback(self, msg):\n        self.sensors['odom'] = msg\n\n    def joint_callback(self, msg):\n        self.sensors['joints'] = msg\n\n    def sensorimotor_loop(self):\n        \"\"\"Main sensorimotor integration loop\"\"\"\n        if not all(self.sensors.values()):\n            return\n\n        # Integrate different sensory modalities\n        obstacle_cmd = self.process_obstacle_avoidance()\n        balance_cmd = self.process_balance_control()\n        navigation_cmd = self.process_navigation()\n\n        # Weighted integration of commands\n        final_cmd = Twist()\n        final_cmd.linear.x = (\n            self.integration_weights['obstacle_avoidance'] * obstacle_cmd['linear_x'] +\n            self.integration_weights['balance'] * balance_cmd['linear_x'] +\n            self.integration_weights['navigation'] * navigation_cmd['linear_x']\n        )\n\n        final_cmd.angular.z = (\n            self.integration_weights['obstacle_avoidance'] * obstacle_cmd['angular_z'] +\n            self.integration_weights['balance'] * balance_cmd['angular_z'] +\n            self.integration_weights['navigation'] * navigation_cmd['angular_z']\n        )\n\n        # Apply command limits\n        final_cmd.linear.x = max(-1.0, min(1.0, final_cmd.linear.x))\n        final_cmd.angular.z = max(-1.0, min(1.0, final_cmd.angular.z))\n\n        self.cmd_vel_pub.publish(final_cmd)\n\n    def process_obstacle_avoidance(self):\n        \"\"\"Process laser data for obstacle avoidance\"\"\"\n        laser_data = np.array(self.sensors['laser'].ranges)\n        laser_data[laser_data == float('inf')] = 3.5\n        laser_data[np.isnan(laser_data)] = 3.5\n\n        min_distance = np.min(laser_data) if laser_data.size > 0 else float('inf')\n\n        cmd = {'linear_x': 0.0, 'angular_z': 0.0}\n\n        if min_distance < 0.5:\n            # Emergency avoidance\n            cmd['linear_x'] = -0.3  # Back up\n            # Turn away from closest obstacle\n            closest_idx = np.argmin(laser_data)\n            cmd['angular_z'] = 0.8 if closest_idx < len(laser_data) / 2 else -0.8\n        elif min_distance < 1.0:\n            # Normal avoidance\n            cmd['linear_x'] = 0.2  # Slow forward\n            # Gentle turn away\n            closest_idx = np.argmin(laser_data)\n            cmd['angular_z'] = 0.4 if closest_idx < len(laser_data) / 2 else -0.4\n        else:\n            # Clear path\n            cmd['linear_x'] = 0.6  # Normal forward speed\n            cmd['angular_z'] = 0.0  # No turn\n\n        return cmd\n\n    def process_balance_control(self):\n        \"\"\"Process IMU data for balance control\"\"\"\n        imu = self.sensors['imu']\n\n        # Extract roll and pitch from quaternion\n        import math\n        q = imu.orientation\n        sinr_cosp = 2 * (q.w * q.x + q.y * q.z)\n        cosr_cosp = 1 - 2 * (q.x * q.x + q.y * q.y)\n        roll = math.atan2(sinr_cosp, cosr_cosp)\n\n        siny_cosp = 2 * (q.w * q.z + q.x * q.y)\n        cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z)\n        pitch = math.atan2(siny_cosp, cosy_cosp)\n\n        cmd = {'linear_x': 0.0, 'angular_z': 0.0}\n\n        # Balance correction based on tilt\n        if abs(pitch) > 0.1:  # Tilted forward/backward\n            cmd['linear_x'] = -pitch * 2.0  # Correct by moving opposite to tilt\n        if abs(roll) > 0.1:   # Tilted side to side\n            cmd['angular_z'] = -roll * 2.0  # Correct by turning opposite to tilt\n\n        return cmd\n\n    def process_navigation(self):\n        \"\"\"Process odometry for navigation\"\"\"\n        odom = self.sensors['odom']\n\n        # Example: Simple goal-oriented navigation\n        # In a real system, this would involve path planning\n        cmd = {'linear_x': 0.5, 'angular_z': 0.0}  # Default forward motion\n\n        # This would be enhanced with goal-seeking behavior\n        return cmd\n"})}),"\n",(0,a.jsx)(n.h2,{id:"2-distributed-control-architectures",children:"2. Distributed Control Architectures"}),"\n",(0,a.jsx)(n.h3,{id:"21-node-based-nervous-system",children:"2.1 Node-Based Nervous System"}),"\n",(0,a.jsx)(n.p,{children:"In ROS 2, we can create a distributed nervous system using multiple interconnected nodes that communicate via topics, services, and actions:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Brain Node - Higher-level cognitive functions\nclass BrainNode(Node):\n    """\n    Higher-level cognitive control node.\n    Makes decisions based on integrated sensory information and goals.\n    """\n\n    def __init__(self):\n        super().__init__(\'brain_node\')\n\n        # Subscribe to integrated sensor data\n        self.sensory_sub = self.create_subscription(\n            String, \'/integrated_sensory_data\', self.sensory_callback, 10)\n\n        # Subscribe to goals\n        self.goal_sub = self.create_subscription(\n            PoseStamped, \'/goal\', self.goal_callback, 10)\n\n        # Publish high-level commands\n        self.high_level_cmd_pub = self.create_publisher(\n            String, \'/high_level_commands\', 10)\n\n        # Service for requesting planning\n        self.plan_service = self.create_service(\n            Trigger, \'/request_plan\', self.plan_callback)\n\n        self.sensory_data = {}\n        self.current_goal = None\n        self.current_state = "IDLE"\n\n        self.brain_timer = self.create_timer(0.1, self.cognitive_loop)\n\n        self.get_logger().info(\'Brain Node initialized\')\n\n    def sensory_callback(self, msg):\n        """Process integrated sensory information"""\n        try:\n            self.sensory_data = eval(msg.data)  # In practice, use json.loads\n        except:\n            self.get_logger().warn(\'Invalid sensory data format\')\n\n    def goal_callback(self, msg):\n        """Process new goal"""\n        self.current_goal = msg\n\n    def cognitive_loop(self):\n        """Main cognitive processing loop"""\n        if not self.sensory_data:\n            return\n\n        # Decision making based on sensory data and goals\n        decision = self.make_decision()\n\n        if decision:\n            cmd_msg = String()\n            cmd_msg.data = str(decision)\n            self.high_level_cmd_pub.publish(cmd_msg)\n\n    def make_decision(self):\n        """Make high-level decisions based on sensory data and goals"""\n        if not self.current_goal:\n            return {"action": "wait", "reason": "no_goal"}\n\n        # Example decision logic\n        if self.sensory_data.get(\'obstacle_distance\', float(\'inf\')) < 0.3:\n            return {"action": "avoid_obstacle", "reason": "immediate_danger"}\n        elif self.sensory_data.get(\'goal_distance\', float(\'inf\')) < 0.5:\n            return {"action": "goal_reached", "reason": "at_goal"}\n        else:\n            return {"action": "navigate", "reason": "toward_goal"}\n\n    def plan_callback(self, request, response):\n        """Plan a path to the current goal"""\n        if self.current_goal:\n            # In a real implementation, this would do actual path planning\n            response.success = True\n            response.message = "Path planned successfully"\n        else:\n            response.success = False\n            response.message = "No goal set"\n        return response\n\n# Spinal Cord Node - Local reflexes and coordination\nclass SpinalCordNode(Node):\n    """\n    Local processing node for reflexes and immediate responses.\n    Similar to spinal cord processing in biological systems.\n    """\n\n    def __init__(self):\n        super().__init__(\'spinal_cord_node\')\n\n        # Subscribe to immediate sensory data\n        self.immediate_sensory_sub = self.create_subscription(\n            LaserScan, \'/scan\', self.immediate_sensory_callback, 10)\n\n        # Subscribe to high-level commands\n        self.high_level_sub = self.create_subscription(\n            String, \'/high_level_commands\', self.high_level_callback, 10)\n\n        # Publish immediate motor commands\n        self.motor_cmd_pub = self.create_publisher(\n            Twist, \'/cmd_vel\', 10)\n\n        self.immediate_sensory_data = None\n        self.high_level_command = None\n\n        # High-frequency reflex processing\n        self.reflex_timer = self.create_timer(0.01, self.reflex_processing)\n\n        self.get_logger().info(\'Spinal Cord Node initialized\')\n\n    def immediate_sensory_callback(self, msg):\n        """Process immediate sensory data for reflexes"""\n        self.immediate_sensory_data = msg\n\n    def high_level_callback(self, msg):\n        """Process high-level commands"""\n        self.high_level_command = msg\n\n    def reflex_processing(self):\n        """Process immediate reflexes"""\n        if self.immediate_sensory_data is None:\n            return\n\n        # Immediate collision avoidance reflex\n        ranges = np.array(self.immediate_sensory_data.ranges)\n        ranges[ranges == float(\'inf\')] = 3.5\n        ranges[np.isnan(ranges)] = 3.5\n\n        min_distance = np.min(ranges) if ranges.size > 0 else float(\'inf\')\n\n        cmd = Twist()\n\n        if min_distance < 0.3:  # Immediate danger\n            # Emergency stop reflex\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n        elif min_distance < 0.8:  # Approaching obstacle\n            # Approach reflex - slow down\n            cmd.linear.x = max(0.1, min_distance * 0.5)\n            # Turn away from closest obstacle\n            closest_idx = np.argmin(ranges)\n            cmd.angular.z = 0.5 if closest_idx < len(ranges) / 2 else -0.5\n        else:\n            # No immediate threat - follow high-level command\n            if self.high_level_command:\n                # In a real system, interpret high-level commands\n                cmd.linear.x = 0.5\n                cmd.angular.z = 0.0\n            else:\n                # Default behavior\n                cmd.linear.x = 0.3\n                cmd.angular.z = 0.0\n\n        self.motor_cmd_pub.publish(cmd)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"22-communication-patterns",children:"2.2 Communication Patterns"}),"\n",(0,a.jsx)(n.p,{children:"The nervous system uses specific communication patterns that can be implemented with ROS 2:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Sensory Integration Hub\nclass SensoryIntegrationHub(Node):\n    \"\"\"\n    Hub for integrating multiple sensory inputs.\n    Similar to how sensory information is integrated in the brainstem/thalamus.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('sensory_integration_hub')\n\n        # Multiple sensor subscriptions\n        self.sensors = {}\n        self.sensors['laser'] = self.create_subscription(LaserScan, '/scan',\n                                                         lambda msg: self.sensor_callback('laser', msg), 10)\n        self.sensors['imu'] = self.create_subscription(Imu, '/imu',\n                                                       lambda msg: self.sensor_callback('imu', msg), 10)\n        self.sensors['odom'] = self.create_subscription(Odometry, '/odom',\n                                                        lambda msg: self.sensor_callback('odom', msg), 10)\n\n        # Integrated data publisher\n        self.integrated_pub = self.create_publisher(String, '/integrated_sensory_data', 10)\n\n        # Timestamped sensory data storage\n        self.sensory_buffer = {}\n        self.max_buffer_size = 10\n\n        # Integration timer\n        self.integration_timer = self.create_timer(0.05, self.integrate_sensory_data)\n\n        self.get_logger().info('Sensory Integration Hub initialized')\n\n    def sensor_callback(self, sensor_type, msg):\n        \"\"\"Receive and buffer sensory data\"\"\"\n        timestamp = self.get_clock().now().nanoseconds\n        self.sensory_buffer[sensor_type] = {\n            'timestamp': timestamp,\n            'data': msg\n        }\n\n        # Maintain buffer size\n        if len(self.sensory_buffer) > self.max_buffer_size:\n            # Remove oldest entries\n            oldest_key = min(self.sensory_buffer.keys(),\n                           key=lambda k: self.sensory_buffer[k]['timestamp'])\n            del self.sensory_buffer[oldest_key]\n\n    def integrate_sensory_data(self):\n        \"\"\"Integrate and publish sensory data\"\"\"\n        if not self.sensory_buffer:\n            return\n\n        # Create integrated sensory representation\n        integrated_data = {\n            'timestamp': self.get_clock().now().nanoseconds,\n            'sensors_present': list(self.sensory_buffer.keys())\n        }\n\n        # Extract and process key information from each sensor\n        if 'laser' in self.sensory_buffer:\n            laser_data = self.sensory_buffer['laser']['data']\n            ranges = np.array(laser_data.ranges)\n            ranges[ranges == float('inf')] = 3.5\n            ranges[np.isnan(ranges)] = 3.5\n            integrated_data['obstacle_distance'] = float(np.min(ranges)) if ranges.size > 0 else float('inf')\n            integrated_data['obstacle_direction'] = float(np.argmin(ranges)) if ranges.size > 0 else 0\n\n        if 'imu' in self.sensory_buffer:\n            imu_data = self.sensory_buffer['imu']['data']\n            # Process orientation and acceleration data\n            integrated_data['orientation'] = {\n                'x': imu_data.orientation.x,\n                'y': imu_data.orientation.y,\n                'z': imu_data.orientation.z,\n                'w': imu_data.orientation.w\n            }\n            integrated_data['linear_acceleration'] = {\n                'x': imu_data.linear_acceleration.x,\n                'y': imu_data.linear_acceleration.y,\n                'z': imu_data.linear_acceleration.z\n            }\n\n        if 'odom' in self.sensory_buffer:\n            odom_data = self.sensory_buffer['odom']['data']\n            integrated_data['position'] = {\n                'x': odom_data.pose.pose.position.x,\n                'y': odom_data.pose.pose.position.y,\n                'z': odom_data.pose.pose.position.z\n            }\n            integrated_data['velocity'] = {\n                'linear': {\n                    'x': odom_data.twist.twist.linear.x,\n                    'y': odom_data.twist.twist.linear.y,\n                    'z': odom_data.twist.twist.linear.z\n                },\n                'angular': {\n                    'x': odom_data.twist.twist.angular.x,\n                    'y': odom_data.twist.twist.angular.y,\n                    'z': odom_data.twist.twist.angular.z\n                }\n            }\n\n        # Publish integrated data\n        msg = String()\n        msg.data = str(integrated_data)\n        self.integrated_pub.publish(msg)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"3-reflex-based-control-systems",children:"3. Reflex-Based Control Systems"}),"\n",(0,a.jsx)(n.h3,{id:"31-implementing-reflex-arcs",children:"3.1 Implementing Reflex Arcs"}),"\n",(0,a.jsx)(n.p,{children:"Reflex arcs provide immediate responses to stimuli without higher-level processing:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class ReflexSystem(Node):\n    \"\"\"\n    Implementation of reflex arcs for immediate responses.\n    Mimics monosynaptic and polysynaptic reflexes in biological systems.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('reflex_system')\n\n        # Sensory inputs for different reflexes\n        self.laser_sub = self.create_subscription(LaserScan, '/scan', self.laser_callback, 10)\n        self.contact_sub = self.create_subscription(Bool, '/contact_sensor', self.contact_callback, 10)\n        self.force_sub = self.create_subscription(WrenchStamped, '/force_torque', self.force_callback, 10)\n\n        # Motor command outputs\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.joint_cmd_pub = self.create_publisher(JointState, '/joint_commands', 10)\n\n        # Reflex timers (very high frequency for immediate responses)\n        self.reflex_timer = self.create_timer(0.005, self.process_reflexes)  # 200 Hz\n\n        # Reflex state\n        self.sensory_inputs = {\n            'laser': None,\n            'contact': None,\n            'force': None\n        }\n\n        # Reflex thresholds and parameters\n        self.reflex_params = {\n            'collision_distance': 0.2,      # meters\n            'contact_threshold': True,      # contact detected\n            'force_threshold': 50.0         # Newtons\n        }\n\n        self.active_reflexes = set()\n\n        self.get_logger().info('Reflex System initialized')\n\n    def laser_callback(self, msg):\n        \"\"\"Process laser data for collision reflex\"\"\"\n        self.sensory_inputs['laser'] = msg\n\n    def contact_callback(self, msg):\n        \"\"\"Process contact sensor data\"\"\"\n        self.sensory_inputs['contact'] = msg\n\n    def force_callback(self, msg):\n        \"\"\"Process force/torque data\"\"\"\n        self.sensory_inputs['force'] = msg\n\n    def process_reflexes(self):\n        \"\"\"Process all active reflexes at high frequency\"\"\"\n        if not all(self.sensory_inputs.values()):\n            return\n\n        # Check and execute reflexes\n        if self.check_collision_reflex():\n            self.execute_collision_reflex()\n\n        if self.check_contact_reflex():\n            self.execute_contact_reflex()\n\n        if self.check_force_reflex():\n            self.execute_force_reflex()\n\n    def check_collision_reflex(self):\n        \"\"\"Check if collision reflex should be triggered\"\"\"\n        if self.sensory_inputs['laser'] is None:\n            return False\n\n        ranges = np.array(self.sensory_inputs['laser'].ranges)\n        ranges[ranges == float('inf')] = 3.5\n        ranges[np.isnan(ranges)] = 3.5\n\n        min_distance = np.min(ranges) if ranges.size > 0 else float('inf')\n\n        return min_distance < self.reflex_params['collision_distance']\n\n    def execute_collision_reflex(self):\n        \"\"\"Execute collision avoidance reflex\"\"\"\n        if 'collision' in self.active_reflexes:\n            return  # Already executing\n\n        self.active_reflexes.add('collision')\n        self.get_logger().warn('COLLISION REFLEX: Executing emergency avoidance')\n\n        # Immediate stop command\n        cmd = Twist()\n        cmd.linear.x = -0.3  # Move backward quickly\n        cmd.angular.z = 0.5  # Turn to avoid\n        self.cmd_vel_pub.publish(cmd)\n\n        # Schedule reflex reset\n        self.create_timer(0.5, lambda: self.reset_reflex('collision'))\n\n    def check_contact_reflex(self):\n        \"\"\"Check if contact reflex should be triggered\"\"\"\n        if self.sensory_inputs['contact'] is None:\n            return False\n\n        return self.sensory_inputs['contact'].data == self.reflex_params['contact_threshold']\n\n    def execute_contact_reflex(self):\n        \"\"\"Execute contact response reflex\"\"\"\n        if 'contact' in self.active_reflexes:\n            return\n\n        self.active_reflexes.add('contact')\n        self.get_logger().warn('CONTACT REFLEX: Withdrawing from contact')\n\n        # Withdraw from contact\n        cmd = Twist()\n        cmd.linear.x = -0.2  # Move away\n        cmd.angular.z = 0.0\n        self.cmd_vel_pub.publish(cmd)\n\n        self.create_timer(0.3, lambda: self.reset_reflex('contact'))\n\n    def check_force_reflex(self):\n        \"\"\"Check if force reflex should be triggered\"\"\"\n        if self.sensory_inputs['force'] is None:\n            return False\n\n        force_magnitude = (\n            self.sensory_inputs['force'].wrench.force.x**2 +\n            self.sensory_inputs['force'].wrench.force.y**2 +\n            self.sensory_inputs['force'].wrench.force.z**2\n        )**0.5\n\n        return force_magnitude > self.reflex_params['force_threshold']\n\n    def execute_force_reflex(self):\n        \"\"\"Execute force response reflex\"\"\"\n        if 'force' in self.active_reflexes:\n            return\n\n        self.active_reflexes.add('force')\n        self.get_logger().warn('FORCE REFLEX: Reducing applied force')\n\n        # Reduce joint efforts\n        joint_cmd = JointState()\n        # In a real system, this would command specific joint adjustments\n        self.joint_cmd_pub.publish(joint_cmd)\n\n        self.create_timer(0.2, lambda: self.reset_reflex('force'))\n\n    def reset_reflex(self, reflex_type):\n        \"\"\"Reset a specific reflex\"\"\"\n        if reflex_type in self.active_reflexes:\n            self.active_reflexes.remove(reflex_type)\n            self.get_logger().info(f'{reflex_type.upper()} REFLEX: Reset')\n\nclass AdaptiveReflexSystem(ReflexSystem):\n    \"\"\"\n    Extended reflex system with adaptive capabilities.\n    Reflux responses can adapt based on experience and context.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n        # Add adaptation timer\n        self.adaptation_timer = self.create_timer(1.0, self.adapt_reflexes)  # 1 Hz adaptation\n\n        # Reflex adaptation parameters\n        self.reflex_history = {\n            'collision': {'success_count': 0, 'failure_count': 0, 'avg_time': 0.0},\n            'contact': {'success_count': 0, 'failure_count': 0, 'avg_time': 0.0},\n            'force': {'success_count': 0, 'failure_count': 0, 'avg_time': 0.0}\n        }\n\n        self.adaptation_learning_rate = 0.1\n\n    def adapt_reflexes(self):\n        \"\"\"Adapt reflex parameters based on performance history\"\"\"\n        for reflex_type, history in self.reflex_history.items():\n            if history['success_count'] + history['failure_count'] > 0:\n                success_rate = history['success_count'] / (history['success_count'] + history['failure_count'])\n\n                # Adjust thresholds based on success rate\n                if success_rate < 0.7:  # Too many failures, make more conservative\n                    if reflex_type == 'collision':\n                        self.reflex_params['collision_distance'] *= 1.1  # Increase threshold\n                    elif reflex_type == 'force':\n                        self.reflex_params['force_threshold'] *= 0.9  # Decrease threshold\n                elif success_rate > 0.95:  # Very successful, could be more aggressive\n                    if reflex_type == 'collision':\n                        self.reflex_params['collision_distance'] *= 0.95  # Decrease threshold\n                    elif reflex_type == 'force':\n                        self.reflex_params['force_threshold'] *= 1.05  # Increase threshold\n\n                # Keep parameters within reasonable bounds\n                self.reflex_params['collision_distance'] = max(0.1, min(1.0, self.reflex_params['collision_distance']))\n                self.reflex_params['force_threshold'] = max(10.0, min(100.0, self.reflex_params['force_threshold']))\n"})}),"\n",(0,a.jsx)(n.h2,{id:"4-hierarchical-control-structures",children:"4. Hierarchical Control Structures"}),"\n",(0,a.jsx)(n.h3,{id:"41-multi-level-control-hierarchy",children:"4.1 Multi-Level Control Hierarchy"}),"\n",(0,a.jsx)(n.p,{children:"Implementing a control hierarchy similar to biological nervous systems:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class HierarchicalController(Node):\n    \"\"\"\n    Hierarchical control system with multiple levels of abstraction.\n    Mimics the organization from spinal cord to cerebral cortex.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('hierarchical_controller')\n\n        # Communication with different levels\n        self.high_level_sub = self.create_subscription(String, '/high_level_goals', self.high_level_callback, 10)\n        self.mid_level_sub = self.create_subscription(String, '/mid_level_tasks', self.mid_level_callback, 10)\n        self.low_level_sub = self.create_subscription(String, '/low_level_commands', self.low_level_callback, 10)\n\n        # Command publishers for different levels\n        self.high_level_pub = self.create_publisher(String, '/high_level_status', 10)\n        self.mid_level_pub = self.create_publisher(String, '/mid_level_status', 10)\n        self.low_level_pub = self.create_publisher(String, '/low_level_status', 10)\n\n        # Motor command publisher\n        self.motor_cmd_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Level-specific timers\n        self.high_level_timer = self.create_timer(0.5, self.high_level_processing)   # 2 Hz\n        self.mid_level_timer = self.create_timer(0.1, self.mid_level_processing)     # 10 Hz\n        self.low_level_timer = self.create_timer(0.02, self.low_level_processing)    # 50 Hz\n\n        # Internal state for each level\n        self.high_level_state = {\n            'current_goal': None,\n            'plan': [],\n            'execution_status': 'IDLE'\n        }\n\n        self.mid_level_state = {\n            'current_task': None,\n            'subtasks': [],\n            'progress': 0.0\n        }\n\n        self.low_level_state = {\n            'current_action': None,\n            'motor_commands': [],\n            'execution_time': 0.0\n        }\n\n        self.get_logger().info('Hierarchical Controller initialized')\n\n    def high_level_callback(self, msg):\n        \"\"\"Receive high-level goals and plans\"\"\"\n        try:\n            goal_data = eval(msg.data)  # In practice, use json.loads\n            self.high_level_state['current_goal'] = goal_data\n            self.high_level_state['execution_status'] = 'PLANNING'\n        except:\n            self.get_logger().warn('Invalid high-level command format')\n\n    def mid_level_callback(self, msg):\n        \"\"\"Receive mid-level tasks\"\"\"\n        try:\n            task_data = eval(msg.data)\n            self.mid_level_state['current_task'] = task_data\n        except:\n            self.get_logger().warn('Invalid mid-level command format')\n\n    def low_level_callback(self, msg):\n        \"\"\"Receive low-level commands\"\"\"\n        try:\n            cmd_data = eval(msg.data)\n            self.low_level_state['current_action'] = cmd_data\n        except:\n            self.get_logger().warn('Invalid low-level command format')\n\n    def high_level_processing(self):\n        \"\"\"High-level cognitive processing (goal planning and reasoning)\"\"\"\n        if self.high_level_state['execution_status'] == 'PLANNING':\n            if self.high_level_state['current_goal']:\n                # Generate plan for the goal\n                plan = self.generate_plan(self.high_level_state['current_goal'])\n                self.high_level_state['plan'] = plan\n                self.high_level_state['execution_status'] = 'EXECUTING'\n\n                # Send first task to mid-level\n                if plan:\n                    task_msg = String()\n                    task_msg.data = str(plan[0])\n                    self.mid_level_pub.publish(task_msg)\n\n        elif self.high_level_state['execution_status'] == 'EXECUTING':\n            # Monitor progress and adjust plan if needed\n            if not self.check_execution_progress():\n                # Plan adjustment needed\n                self.adjust_plan()\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = str({\n            'status': self.high_level_state['execution_status'],\n            'current_goal': self.high_level_state['current_goal'],\n            'plan_progress': len(self.high_level_state['plan']) - len([t for t in self.high_level_state['plan'] if t not in self.mid_level_state['subtasks']])\n        })\n        self.high_level_pub.publish(status_msg)\n\n    def mid_level_processing(self):\n        \"\"\"Mid-level task execution and coordination\"\"\"\n        if self.mid_level_state['current_task']:\n            task = self.mid_level_state['current_task']\n\n            # Execute task or delegate to low-level\n            if self.is_primitive_task(task):\n                # Send to low-level for execution\n                cmd_msg = String()\n                cmd_msg.data = str(task)\n                self.low_level_pub.publish(cmd_msg)\n            else:\n                # Break down complex task into subtasks\n                subtasks = self.decompose_task(task)\n                self.mid_level_state['subtasks'] = subtasks\n                self.execute_next_subtask()\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = str({\n            'current_task': self.mid_level_state['current_task'],\n            'subtasks_remaining': len(self.mid_level_state['subtasks']),\n            'progress': self.mid_level_state['progress']\n        })\n        self.mid_level_pub.publish(status_msg)\n\n    def low_level_processing(self):\n        \"\"\"Low-level motor control and execution\"\"\"\n        if self.low_level_state['current_action']:\n            action = self.low_level_state['current_action']\n\n            # Convert action to motor commands\n            motor_cmd = self.action_to_motor_command(action)\n            self.motor_cmd_pub.publish(motor_cmd)\n\n            # Update execution time\n            self.low_level_state['execution_time'] += 0.02  # Timer period\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = str({\n            'current_action': self.low_level_state['current_action'],\n            'execution_time': self.low_level_state['execution_time']\n        })\n        self.low_level_pub.publish(status_msg)\n\n    def generate_plan(self, goal):\n        \"\"\"Generate a plan to achieve the given goal\"\"\"\n        # In a real implementation, this would use path planning, task planning, etc.\n        # For example: navigate to goal, perform action, return\n        return [\n            {'type': 'navigate', 'target': goal.get('location', (0, 0))},\n            {'type': 'perform_action', 'action': goal.get('action', 'wait')},\n            {'type': 'return', 'target': goal.get('return_location', (0, 0))}\n        ]\n\n    def is_primitive_task(self, task):\n        \"\"\"Check if task is primitive (can be executed directly)\"\"\"\n        primitive_types = ['move', 'turn', 'stop', 'grip', 'release']\n        return task.get('type', '') in primitive_types\n\n    def decompose_task(self, task):\n        \"\"\"Decompose a complex task into primitive subtasks\"\"\"\n        task_type = task.get('type', '')\n\n        if task_type == 'navigate':\n            # Complex navigation breaks down into move and turn primitives\n            return [\n                {'type': 'turn', 'angle': task.get('heading', 0)},\n                {'type': 'move', 'distance': task.get('distance', 1.0)}\n            ]\n        elif task_type == 'grasp_object':\n            # Grasping breaks down into approach, align, grip\n            return [\n                {'type': 'navigate', 'target': task.get('approach_pose', (0, 0, 0))},\n                {'type': 'align_gripper', 'target': task.get('grasp_pose', (0, 0, 0))},\n                {'type': 'grip', 'force': task.get('grip_force', 10.0)}\n            ]\n\n        return [task]  # If no decomposition known, return as-is\n\n    def action_to_motor_command(self, action):\n        \"\"\"Convert an action to motor commands\"\"\"\n        cmd = Twist()\n\n        action_type = action.get('type', '')\n        if action_type == 'move':\n            cmd.linear.x = action.get('speed', 0.5)\n        elif action_type == 'turn':\n            cmd.angular.z = action.get('angular_speed', 0.5)\n        elif action_type == 'stop':\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n\n        return cmd\n\n    def check_execution_progress(self):\n        \"\"\"Check if high-level goal execution is progressing\"\"\"\n        # In a real implementation, this would check actual progress toward goal\n        # For now, return True to continue\n        return True\n\n    def adjust_plan(self):\n        \"\"\"Adjust the current plan based on execution feedback\"\"\"\n        self.get_logger().info('Adjusting plan based on execution feedback')\n        # Implementation would adjust plan based on actual vs expected progress\n"})}),"\n",(0,a.jsx)(n.h3,{id:"42-coordination-between-levels",children:"4.2 Coordination Between Levels"}),"\n",(0,a.jsx)(n.p,{children:"Ensuring proper coordination between different control levels:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class CoordinationManager(Node):\n    \"\"\"\n    Manages coordination between different levels of the control hierarchy.\n    Ensures that higher-level goals are properly decomposed and executed\n    while lower-level reflexes can override when necessary.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('coordination_manager')\n\n        # Subscriptions for status from all levels\n        self.high_status_sub = self.create_subscription(String, '/high_level_status', self.high_status_callback, 10)\n        self.mid_status_sub = self.create_subscription(String, '/mid_level_status', self.mid_status_callback, 10)\n        self.low_status_sub = self.create_subscription(String, '/low_level_status', self.low_status_callback, 10)\n\n        # Emergency override subscription\n        self.emergency_sub = self.create_subscription(Bool, '/emergency_override', self.emergency_callback, 10)\n\n        # Command publications to all levels\n        self.high_cmd_pub = self.create_publisher(String, '/high_level_commands', 10)\n        self.mid_cmd_pub = self.create_publisher(String, '/mid_level_commands', 10)\n        self.low_cmd_pub = self.create_publisher(String, '/low_level_commands', 10)\n\n        # Coordination timer\n        self.coordination_timer = self.create_timer(0.05, self.coordination_loop)\n\n        # Status tracking\n        self.level_status = {\n            'high': None,\n            'mid': None,\n            'low': None\n        }\n\n        self.emergency_override = False\n        self.emergency_priority = 10  # Highest priority\n\n        self.get_logger().info('Coordination Manager initialized')\n\n    def high_status_callback(self, msg):\n        try:\n            self.level_status['high'] = eval(msg.data)\n        except:\n            self.get_logger().warn('Invalid high-level status format')\n\n    def mid_status_callback(self, msg):\n        try:\n            self.level_status['mid'] = eval(msg.data)\n        except:\n            self.get_logger().warn('Invalid mid-level status format')\n\n    def low_status_callback(self, msg):\n        try:\n            self.level_status['low'] = eval(msg.data)\n        except:\n            self.get_logger().warn('Invalid low-level status format')\n\n    def emergency_callback(self, msg):\n        \"\"\"Handle emergency override commands\"\"\"\n        self.emergency_override = msg.data\n        if self.emergency_override:\n            self.get_logger().fatal('EMERGENCY OVERRIDE ACTIVATED')\n            # Send emergency stop to all levels\n            self.send_emergency_stop()\n\n    def coordination_loop(self):\n        \"\"\"Main coordination loop\"\"\"\n        if self.emergency_override:\n            return  # Emergency override has highest priority\n\n        # Check for conflicts between levels\n        conflicts = self.detect_conflicts()\n\n        if conflicts:\n            # Resolve conflicts based on priority and context\n            self.resolve_conflicts(conflicts)\n\n        # Monitor execution progress and adjust coordination as needed\n        self.monitor_progress()\n\n    def detect_conflicts(self):\n        \"\"\"Detect conflicts between different control levels\"\"\"\n        conflicts = []\n\n        # Example: Check if low-level is executing while high-level wants to replan\n        if (self.level_status['high'] and\n            self.level_status['high'].get('execution_status') == 'PLANNING' and\n            self.level_status['low'] and\n            self.level_status['low'].get('current_action')):\n            conflicts.append({\n                'type': 'execution_conflict',\n                'levels': ['high', 'low'],\n                'description': 'High-level planning while low-level executing'\n            })\n\n        # Add more conflict detection as needed\n        return conflicts\n\n    def resolve_conflicts(self, conflicts):\n        \"\"\"Resolve detected conflicts between control levels\"\"\"\n        for conflict in conflicts:\n            if conflict['type'] == 'execution_conflict':\n                # For execution conflicts, typically pause low-level execution during replanning\n                pause_cmd = String()\n                pause_cmd.data = str({'command': 'pause_execution'})\n                self.low_cmd_pub.publish(pause_cmd)\n\n    def monitor_progress(self):\n        \"\"\"Monitor execution progress across all levels\"\"\"\n        # Check if execution is proceeding as expected\n        # This might involve comparing expected vs actual progress\n        pass\n\n    def send_emergency_stop(self):\n        \"\"\"Send emergency stop command to all levels\"\"\"\n        stop_cmd = String()\n        stop_cmd.data = str({'command': 'emergency_stop'})\n\n        self.high_cmd_pub.publish(stop_cmd)\n        self.mid_cmd_pub.publish(stop_cmd)\n        self.low_cmd_pub.publish(stop_cmd)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"5-adaptive-control-systems",children:"5. Adaptive Control Systems"}),"\n",(0,a.jsx)(n.h3,{id:"51-learning-based-adaptation",children:"5.1 Learning-Based Adaptation"}),"\n",(0,a.jsx)(n.p,{children:"Implementing systems that can learn and adapt their behavior:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import pickle\nimport os\nfrom collections import deque\n\nclass AdaptiveController(Node):\n    \"\"\"\n    Adaptive controller that learns from experience and adjusts behavior.\n    Implements basic learning mechanisms similar to habituation and adaptation in biological systems.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('adaptive_controller')\n\n        # Sensor and command interfaces\n        self.laser_sub = self.create_subscription(LaserScan, '/scan', self.laser_callback, 10)\n        self.odom_sub = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, '/imu', self.imu_callback, 10)\n\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Learning timer\n        self.learning_timer = self.create_timer(0.1, self.learning_loop)\n\n        # Internal state\n        self.sensors = {\n            'laser': None,\n            'odom': None,\n            'imu': None\n        }\n\n        # Learning components\n        self.experience_buffer = deque(maxlen=1000)  # Store recent experiences\n        self.performance_history = deque(maxlen=100)  # Track performance over time\n        self.adaptation_params = {\n            'learning_rate': 0.01,\n            'exploration_rate': 0.1,\n            'adaptation_threshold': 0.8\n        }\n\n        # Learned behaviors\n        self.learnt_behaviors = {}  # Maps situations to behaviors\n        self.behavior_preferences = {}  # Tracks which behaviors work best\n\n        # Load any saved learning\n        self.load_learning()\n\n        self.get_logger().info('Adaptive Controller initialized')\n\n    def laser_callback(self, msg):\n        self.sensors['laser'] = msg\n\n    def odom_callback(self, msg):\n        self.sensors['odom'] = msg\n\n    def imu_callback(self, msg):\n        self.sensors['imu'] = msg\n\n    def learning_loop(self):\n        \"\"\"Main learning and adaptation loop\"\"\"\n        if not all(self.sensors.values()):\n            return\n\n        # Get current state\n        current_state = self.get_current_state()\n\n        # Select action based on current state and learned knowledge\n        action = self.select_action(current_state)\n\n        # Execute action\n        self.execute_action(action)\n\n        # Evaluate performance and store experience\n        performance = self.evaluate_performance()\n        experience = {\n            'state': current_state,\n            'action': action,\n            'performance': performance,\n            'timestamp': self.get_clock().now().nanoseconds\n        }\n\n        self.experience_buffer.append(experience)\n        self.performance_history.append(performance)\n\n        # Periodically update learned behaviors\n        if len(self.experience_buffer) % 10 == 0:  # Update every 10 experiences\n            self.update_learning()\n\n    def get_current_state(self):\n        \"\"\"Extract relevant features from sensor data to represent current state\"\"\"\n        state = {}\n\n        if self.sensors['laser']:\n            laser_data = np.array(self.sensors['laser'].ranges)\n            laser_data[laser_data == float('inf')] = 3.5\n            laser_data[np.isnan(laser_data)] = 3.5\n\n            # Extract key features\n            state['min_obstacle_distance'] = float(np.min(laser_data)) if laser_data.size > 0 else float('inf')\n            state['front_clear'] = float(np.min(laser_data[len(laser_data)//2-10:len(laser_data)//2+10])) if laser_data.size > 20 else float('inf')\n            state['left_clear'] = float(np.min(laser_data[:len(laser_data)//4])) if laser_data.size > 0 else float('inf')\n            state['right_clear'] = float(np.min(laser_data[3*len(laser_data)//4:])) if laser_data.size > 0 else float('inf')\n\n        if self.sensors['odom']:\n            odom = self.sensors['odom']\n            state['linear_velocity'] = odom.twist.twist.linear.x\n            state['angular_velocity'] = odom.twist.twist.angular.z\n\n        if self.sensors['imu']:\n            imu = self.sensors['imu']\n            # Extract orientation features\n            import math\n            q = imu.orientation\n            siny_cosp = 2 * (q.w * q.z + q.x * q.y)\n            cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z)\n            yaw = math.atan2(siny_cosp, cosy_cosp)\n            state['yaw'] = yaw\n\n        return state\n\n    def select_action(self, state):\n        \"\"\"Select action based on state and learned behaviors\"\"\"\n        # First, check if we have a learned behavior for this state\n        state_key = self.discretize_state(state)\n\n        if state_key in self.learnt_behaviors:\n            # Use learned behavior\n            return self.learnt_behaviors[state_key]\n        else:\n            # Use exploration with some random behavior\n            if np.random.random() < self.adaptation_params['exploration_rate']:\n                # Random exploration\n                return self.generate_random_action()\n            else:\n                # Default behavior\n                return self.default_behavior(state)\n\n    def generate_random_action(self):\n        \"\"\"Generate a random exploratory action\"\"\"\n        cmd = Twist()\n        cmd.linear.x = np.random.uniform(0.1, 0.8)  # Forward speed\n        cmd.angular.z = np.random.uniform(-0.5, 0.5)  # Turn rate\n        return cmd\n\n    def default_behavior(self, state):\n        \"\"\"Default behavior when no learned behavior exists\"\"\"\n        cmd = Twist()\n\n        # Simple obstacle avoidance by default\n        if state.get('min_obstacle_distance', float('inf')) < 0.5:\n            cmd.linear.x = 0.0  # Stop\n            if state.get('left_clear', 0) > state.get('right_clear', 0):\n                cmd.angular.z = 0.5  # Turn left\n            else:\n                cmd.angular.z = -0.5  # Turn right\n        else:\n            cmd.linear.x = 0.5  # Move forward\n            cmd.angular.z = 0.0  # No turn\n\n        return cmd\n\n    def execute_action(self, action):\n        \"\"\"Execute the selected action\"\"\"\n        self.cmd_vel_pub.publish(action)\n\n    def evaluate_performance(self):\n        \"\"\"Evaluate the performance of recent actions\"\"\"\n        # Calculate performance based on progress toward goals\n        # For simplicity, we'll use a basic metric based on movement and obstacle avoidance\n\n        if not self.sensors['laser'] or not self.sensors['odom']:\n            return 0.0\n\n        laser_data = np.array(self.sensors['laser'].ranges)\n        laser_data[laser_data == float('inf')] = 3.5\n        laser_data[np.isnan(laser_data)] = 3.5\n\n        min_distance = np.min(laser_data) if laser_data.size > 0 else float('inf')\n        linear_vel = self.sensors['odom'].twist.twist.linear.x\n\n        # Performance metric: combination of progress and safety\n        safety_factor = 1.0 if min_distance > 0.8 else min_distance / 0.8\n        progress_factor = abs(linear_vel) if linear_vel > 0 else 0  # Only reward forward movement\n\n        performance = 0.7 * progress_factor + 0.3 * safety_factor\n        return min(1.0, performance)  # Normalize to [0, 1]\n\n    def update_learning(self):\n        \"\"\"Update learned behaviors based on experience\"\"\"\n        if len(self.performance_history) < 10:\n            return\n\n        # Calculate average recent performance\n        recent_performance = np.mean(list(self.performance_history)[-10:])\n\n        if recent_performance > self.adaptation_params['adaptation_threshold']:\n            # Good performance - reinforce successful patterns\n            self.reinforce_successful_behaviors()\n        else:\n            # Poor performance - explore new behaviors\n            self.explore_new_behaviors()\n\n    def reinforce_successful_behaviors(self):\n        \"\"\"Reinforce behaviors that led to good performance\"\"\"\n        # Look at recent experiences with high performance\n        recent_experiences = list(self.experience_buffer)[-20:]\n\n        for exp in recent_experiences:\n            if exp['performance'] > 0.8:  # High performance threshold\n                state_key = self.discretize_state(exp['state'])\n                action = exp['action']\n\n                # Update behavior preference\n                if state_key not in self.behavior_preferences:\n                    self.behavior_preferences[state_key] = {}\n\n                action_key = self.action_to_key(action)\n                if action_key not in self.behavior_preferences[state_key]:\n                    self.behavior_preferences[state_key][action_key] = 0\n\n                # Increase preference for this action in this state\n                self.behavior_preferences[state_key][action_key] += self.adaptation_params['learning_rate']\n\n    def explore_new_behaviors(self):\n        \"\"\"Encourage exploration of new behaviors when performance is poor\"\"\"\n        # Increase exploration rate temporarily\n        self.adaptation_params['exploration_rate'] = min(0.5, self.adaptation_params['exploration_rate'] * 1.1)\n\n    def discretize_state(self, state):\n        \"\"\"Convert continuous state to discrete representation for learning\"\"\"\n        # Simplified discretization - in practice, this would be more sophisticated\n        if not state:\n            return \"unknown\"\n\n        min_dist = state.get('min_obstacle_distance', float('inf'))\n        front_clear = state.get('front_clear', float('inf'))\n\n        # Create discrete state representation\n        dist_category = \"close\" if min_dist < 0.5 else \"medium\" if min_dist < 1.0 else \"far\"\n        front_category = \"clear\" if front_clear > 1.0 else \"obstructed\"\n\n        return f\"{dist_category}_{front_category}\"\n\n    def action_to_key(self, action):\n        \"\"\"Convert action to a hashable key for learning\"\"\"\n        return (round(action.linear.x, 2), round(action.angular.z, 2))\n\n    def save_learning(self):\n        \"\"\"Save learned behaviors to file\"\"\"\n        learning_data = {\n            'learnt_behaviors': self.learnt_behaviors,\n            'behavior_preferences': self.behavior_preferences,\n            'adaptation_params': self.adaptation_params,\n            'experience_count': len(self.experience_buffer)\n        }\n\n        try:\n            with open('adaptive_controller_learning.pkl', 'wb') as f:\n                pickle.dump(learning_data, f)\n            self.get_logger().info('Learning data saved successfully')\n        except Exception as e:\n            self.get_logger().error(f'Failed to save learning data: {e}')\n\n    def load_learning(self):\n        \"\"\"Load learned behaviors from file\"\"\"\n        if os.path.exists('adaptive_controller_learning.pkl'):\n            try:\n                with open('adaptive_controller_learning.pkl', 'rb') as f:\n                    learning_data = pickle.load(f)\n\n                self.learnt_behaviors = learning_data.get('learnt_behaviors', {})\n                self.behavior_preferences = learning_data.get('behavior_preferences', {})\n                self.adaptation_params = learning_data.get('adaptation_params', self.adaptation_params)\n\n                self.get_logger().info(f'Learning data loaded: {learning_data.get(\"experience_count\", 0)} experiences')\n            except Exception as e:\n                self.get_logger().error(f'Failed to load learning data: {e}')\n\n    def destroy_node(self):\n        \"\"\"Save learning before shutdown\"\"\"\n        self.save_learning()\n        super().destroy_node()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"6-practical-example-complete-robotic-nervous-system",children:"6. Practical Example: Complete Robotic Nervous System"}),"\n",(0,a.jsx)(n.p,{children:"Here's a complete example that integrates all the concepts:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nComplete Robotic Nervous System Example\nThis example demonstrates a complete implementation of a robotic nervous system\nwith reflexes, hierarchical control, and adaptive behavior.\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Imu, Odometry, JointState\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom std_msgs.msg import String, Bool\nfrom builtin_interfaces.msg import Time\nimport numpy as np\nimport math\nfrom enum import Enum\nfrom collections import deque\n\nclass ControlLevel(Enum):\n    REFLEX = 1      # Immediate responses\n    SPINAL = 2      # Local coordination\n    MIDBRAIN = 3    # Basic behavioral patterns\n    CORTICAL = 4    # High-level planning\n\nclass RoboticNervousSystemCore(Node):\n    \"\"\"\n    Core nervous system that coordinates all levels of control.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('robotic_nervous_system_core')\n\n        # All sensor inputs\n        self.laser_sub = self.create_subscription(LaserScan, '/scan', self.laser_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, '/imu', self.imu_callback, 10)\n        self.odom_sub = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)\n        self.joint_sub = self.create_subscription(JointState, '/joint_states', self.joint_callback, 10)\n\n        # Motor outputs\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.joint_cmd_pub = self.create_publisher(JointState, '/joint_commands', 10)\n\n        # Control level timers with different frequencies\n        self.reflex_timer = self.create_timer(0.005, self.reflex_level_control)    # 200 Hz\n        self.spinal_timer = self.create_timer(0.02, self.spinal_level_control)     # 50 Hz\n        self.midbrain_timer = self.create_timer(0.1, self.midbrain_level_control)  # 10 Hz\n        self.cortical_timer = self.create_timer(0.5, self.cortical_level_control)  # 2 Hz\n\n        # Internal state\n        self.sensors = {\n            'laser': None,\n            'imu': None,\n            'odom': None,\n            'joints': None\n        }\n\n        # Control priorities and states\n        self.control_priority = {\n            ControlLevel.REFLEX: 100,\n            ControlLevel.SPINAL: 80,\n            ControlLevel.MIDBRAIN: 60,\n            ControlLevel.CORTICAL: 40\n        }\n\n        self.active_controls = {}  # Track which control level is active\n        self.control_commands = {}  # Store commands from each level\n\n        # Emergency state\n        self.emergency_active = False\n        self.emergency_reason = \"\"\n\n        # Learning and adaptation\n        self.adaptation_enabled = True\n        self.performance_history = deque(maxlen=50)\n\n        self.get_logger().info('Robotic Nervous System Core initialized')\n\n    def laser_callback(self, msg):\n        self.sensors['laser'] = msg\n\n    def imu_callback(self, msg):\n        self.sensors['imu'] = msg\n\n    def odom_callback(self, msg):\n        self.sensors['odom'] = msg\n\n    def joint_callback(self, msg):\n        self.sensors['joints'] = msg\n\n    def reflex_level_control(self):\n        \"\"\"Highest priority - immediate reflex responses\"\"\"\n        if not self.sensors['laser']:\n            return\n\n        # Collision avoidance reflex\n        laser_data = np.array(self.sensors['laser'].ranges)\n        laser_data[laser_data == float('inf')] = 3.5\n        laser_data[np.isnan(laser_data)] = 3.5\n\n        min_distance = np.min(laser_data) if laser_data.size > 0 else float('inf')\n\n        if min_distance < 0.2:  # Immediate collision danger\n            cmd = Twist()\n            cmd.linear.x = -0.4  # Rapid reverse\n            cmd.angular.z = 0.8 if np.argmin(laser_data) < len(laser_data) / 2 else -0.8\n            self.control_commands[ControlLevel.REFLEX] = cmd\n            self.active_controls[ControlLevel.REFLEX] = self.get_clock().now().nanoseconds\n            return\n\n        # Approach reflex\n        if min_distance < 0.5 and min_distance > 0.2:\n            cmd = Twist()\n            cmd.linear.x = max(0.1, min_distance - 0.3)  # Slow approach\n            # Gentle turn away from closest obstacle\n            closest_idx = np.argmin(laser_data)\n            cmd.angular.z = 0.3 if closest_idx < len(laser_data) / 2 else -0.3\n            self.control_commands[ControlLevel.REFLEX] = cmd\n            self.active_controls[ControlLevel.REFLEX] = self.get_clock().now().nanoseconds\n            return\n\n        # If no reflex action needed, clear reflex command\n        if ControlLevel.REFLEX in self.control_commands:\n            del self.control_commands[ControlLevel.REFLEX]\n\n    def spinal_level_control(self):\n        \"\"\"Local coordination and balance control\"\"\"\n        if not all([self.sensors['imu'], self.sensors['odom']]):\n            return\n\n        cmd = Twist()\n\n        # Balance control based on IMU\n        imu = self.sensors['imu']\n        q = imu.orientation\n        # Convert quaternion to roll/pitch\n        sinr_cosp = 2 * (q.w * q.x + q.y * q.z)\n        cosr_cosp = 1 - 2 * (q.x * q.x + q.y * q.y)\n        roll = math.atan2(sinr_cosp, cosr_cosp)\n\n        siny_cosp = 2 * (q.w * q.z + q.x * q.y)\n        cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z)\n        pitch = math.atan2(siny_cosp, cosy_cosp)\n\n        # Correct for tilt\n        cmd.angular.z = -pitch * 2.0  # Turn to correct pitch\n        # cmd.linear.x adjusted based on roll if needed for more complex balance\n\n        # If no high-priority reflex is active, use spinal control\n        if ControlLevel.REFLEX not in self.active_controls or \\\n           (self.get_clock().now().nanoseconds - self.active_controls.get(ControlLevel.REFLEX, 0)) > 100000000:  # 0.1 sec\n            self.control_commands[ControlLevel.SPINAL] = cmd\n            self.active_controls[ControlLevel.SPINAL] = self.get_clock().now().nanoseconds\n\n    def midbrain_level_control(self):\n        \"\"\"Basic behavioral patterns and responses\"\"\"\n        if not all([self.sensors['laser'], self.sensors['odom']]):\n            return\n\n        cmd = Twist()\n\n        # Simple wall following behavior\n        laser_data = np.array(self.sensors['laser'].ranges)\n        laser_data[laser_data == float('inf')] = 3.5\n        laser_data[np.isnan(laser_data)] = 3.5\n\n        # Check for walls on left/right\n        left_section = laser_data[:len(laser_data)//4]\n        right_section = laser_data[3*len(laser_data)//4:]\n\n        left_distance = np.min(left_section) if left_section.size > 0 else float('inf')\n        right_distance = np.min(right_section) if right_section.size > 0 else float('inf')\n\n        # Wall following: maintain distance from wall\n        target_distance = 0.8\n        kp = 1.0  # Proportional gain\n\n        if left_distance < target_distance * 1.5:  # Wall detected on left\n            # Turn right to maintain distance\n            cmd.angular.z = -kp * (target_distance - left_distance)\n            cmd.linear.x = 0.4  # Forward motion\n        elif right_distance < target_distance * 1.5:  # Wall on right\n            # Turn left to maintain distance\n            cmd.angular.z = kp * (target_distance - right_distance)\n            cmd.linear.x = 0.4  # Forward motion\n        else:\n            # No wall detected, continue straight\n            cmd.linear.x = 0.5\n            cmd.angular.z = 0.0\n\n        # Only activate if lower levels aren't handling critical situations\n        if not any(level in self.active_controls and\n                  self.get_clock().now().nanoseconds - self.active_controls[level] < 50000000  # 0.05 sec\n                  for level in [ControlLevel.REFLEX, ControlLevel.SPINAL]):\n            self.control_commands[ControlLevel.MIDBRAIN] = cmd\n            self.active_controls[ControlLevel.MIDBRAIN] = self.get_clock().now().nanoseconds\n\n    def cortical_level_control(self):\n        \"\"\"High-level goal-oriented behavior\"\"\"\n        # For this example, implement simple exploration behavior\n        # In a real system, this would handle complex tasks and planning\n\n        cmd = Twist()\n\n        # Random walk with bias toward open areas\n        if self.sensors['laser']:\n            laser_data = np.array(self.sensors['laser'].ranges)\n            laser_data[laser_data == float('inf')] = 3.5\n            laser_data[np.isnan(laser_data)] = 3.5\n\n            # Find the direction with maximum clearance\n            max_idx = np.argmax(laser_data)\n            angle_to_max = (max_idx / len(laser_data)) * 2 * math.pi - math.pi  # Convert to angle\n\n            # Move toward the clearest direction with some randomness\n            cmd.linear.x = 0.6  # Forward speed\n            cmd.angular.z = angle_to_max * 0.5 + np.random.uniform(-0.2, 0.2)  # Turn toward clear area\n\n        # Only activate if lower levels aren't handling critical situations\n        if not any(level in self.active_controls and\n                  self.get_clock().now().nanoseconds - self.active_controls[level] < 100000000  # 0.1 sec\n                  for level in [ControlLevel.REFLEX, ControlLevel.SPINAL, ControlLevel.MIDBRAIN]):\n            self.control_commands[ControlLevel.CORTICAL] = cmd\n            self.active_controls[ControlLevel.CORTICAL] = self.get_clock().now().nanoseconds\n\n    def execute_highest_priority_command(self):\n        \"\"\"Execute the command from the highest priority active control level\"\"\"\n        if not self.control_commands:\n            return\n\n        # Find the highest priority active control\n        active_levels = [level for level in ControlLevel\n                        if level in self.control_commands]\n\n        if not active_levels:\n            return\n\n        # Sort by priority (highest first)\n        active_levels.sort(key=lambda x: self.control_priority[x], reverse=True)\n\n        # Execute command from highest priority level\n        highest_level = active_levels[0]\n        cmd = self.control_commands[highest_level]\n\n        # Apply safety limits\n        cmd.linear.x = max(-1.0, min(1.0, cmd.linear.x))\n        cmd.angular.z = max(-1.0, min(1.0, cmd.angular.z))\n\n        self.cmd_vel_pub.publish(cmd)\n\n        # Log which level is currently controlling\n        self.get_logger().debug(f'Control level {highest_level.name} active')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    nervous_system = RoboticNervousSystemCore()\n\n    try:\n        # Run the main control loop\n        while rclpy.ok():\n            rclpy.spin_once(nervous_system, timeout_sec=0.001)\n            # Execute the highest priority command\n            nervous_system.execute_highest_priority_command()\n    except KeyboardInterrupt:\n        pass\n    finally:\n        nervous_system.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"7-exercises-and-practice",children:"7. Exercises and Practice"}),"\n",(0,a.jsx)(n.p,{children:"Complete the following exercises to reinforce your understanding of robotic nervous system patterns:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-4/exercises",children:"Chapter 4 Exercises"})," - Practice problems covering nervous system pattern implementation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-4/solutions",children:"Chapter 4 Solutions"})," - Complete implementations and solution guides"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"8-summary",children:"8. Summary"}),"\n",(0,a.jsx)(n.p,{children:"This chapter covered the implementation of robotic nervous system patterns inspired by biological neural networks:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Biological nervous system principles and their robotic applications"}),"\n",(0,a.jsx)(n.li,{children:"Distributed control architectures using ROS 2 nodes"}),"\n",(0,a.jsx)(n.li,{children:"Reflex-based control systems for immediate responses"}),"\n",(0,a.jsx)(n.li,{children:"Hierarchical control structures with proper coordination"}),"\n",(0,a.jsx)(n.li,{children:"Adaptive control systems that learn and adjust behavior"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The next chapter would typically cover advanced topics in humanoid robotics, building upon the nervous system patterns to create more sophisticated behaviors and capabilities."}),"\n",(0,a.jsx)(n.h2,{id:"9-further-reading",children:"9. Further Reading"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://www.sciencedirect.com/topics/engineering/biological-neural-network",children:"Biological Neural Networks and Robotics"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://control.ros.org/",children:"ROS 2 Control Framework"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://ieeexplore.ieee.org/document/9123456",children:"Bio-inspired Robotics"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://link.springer.com/book/10.1007/978-3-030-12442-9",children:"Distributed Control Systems"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"10-links-to-external-resources",children:"10. Links to External Resources"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.ros.org/en/humble/",children:"ROS 2 Humble Hawksbill Documentation"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://www.ieee-ras.org/",children:"Biologically-Inspired Robotics Research"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://www.scholarpedia.org/article/Neural_networks",children:"Neural Network Control Systems"})}),"\n"]})]})}function f(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);