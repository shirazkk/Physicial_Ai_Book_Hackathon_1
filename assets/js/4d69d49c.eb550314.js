"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[9136],{5555(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-1-foundation/exercises","title":"Module 1: Exercises and Implementation Guides","description":"Overview","source":"@site/docs/module-1-foundation/exercises.md","sourceDirName":"module-1-foundation","slug":"/module-1-foundation/exercises","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-1-foundation/exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/shirazkk/Physicial_Ai_Book_Hackathon_1/edit/main/my-website/docs/module-1-foundation/exercises.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 1: Foundations of Physical AI & Humanoid Robotics - Summary","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-1-foundation/summary"},"next":{"title":"Module 1: Cross-References and Connections","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-1-foundation/cross-references"}}');var s=t(4848),a=t(8453);const r={},o="Module 1: Exercises and Implementation Guides",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Chapter 1: Mathematical Foundations - Exercises",id:"chapter-1-mathematical-foundations---exercises",level:2},{value:"Exercise 1.1: Vector Operations in Robotics",id:"exercise-11-vector-operations-in-robotics",level:3},{value:"Exercise 1.2: Transformation Matrices",id:"exercise-12-transformation-matrices",level:3},{value:"Exercise 1.3: Probability and Statistics for Sensor Fusion",id:"exercise-13-probability-and-statistics-for-sensor-fusion",level:3},{value:"Chapter 2: Kinematics and Dynamics - Exercises",id:"chapter-2-kinematics-and-dynamics---exercises",level:2},{value:"Exercise 2.1: Forward Kinematics",id:"exercise-21-forward-kinematics",level:3},{value:"Exercise 2.2: Inverse Kinematics",id:"exercise-22-inverse-kinematics",level:3},{value:"Exercise 2.3: Robot Dynamics",id:"exercise-23-robot-dynamics",level:3},{value:"Chapter 3: Sensing and Perception - Exercises",id:"chapter-3-sensing-and-perception---exercises",level:2},{value:"Exercise 3.1: Sensor Models",id:"exercise-31-sensor-models",level:3},{value:"Exercise 3.2: Kalman Filter Implementation",id:"exercise-32-kalman-filter-implementation",level:3},{value:"Chapter 4: Embodied Intelligence - Exercises",id:"chapter-4-embodied-intelligence---exercises",level:2},{value:"Exercise 4.1: Embodied Agent Simulation",id:"exercise-41-embodied-agent-simulation",level:3},{value:"Exercise 4.2: Morphological Computation",id:"exercise-42-morphological-computation",level:3},{value:"Implementation Guide",id:"implementation-guide",level:2},{value:"Setting Up Your Development Environment",id:"setting-up-your-development-environment",level:3},{value:"Running the Exercises",id:"running-the-exercises",level:3},{value:"Extending the Exercises",id:"extending-the-exercises",level:3},{value:"Troubleshooting Tips",id:"troubleshooting-tips",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"module-1-exercises-and-implementation-guides",children:"Module 1: Exercises and Implementation Guides"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This document contains exercises and implementation guides for Module 1: Foundations of Physical AI & Humanoid Robotics. These exercises are designed to reinforce the concepts covered in the four chapters of this module:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Mathematical Foundations"}),"\n",(0,s.jsx)(n.li,{children:"Kinematics and Dynamics"}),"\n",(0,s.jsx)(n.li,{children:"Sensing and Perception"}),"\n",(0,s.jsx)(n.li,{children:"Embodied Intelligence"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"chapter-1-mathematical-foundations---exercises",children:"Chapter 1: Mathematical Foundations - Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-11-vector-operations-in-robotics",children:"Exercise 1.1: Vector Operations in Robotics"}),"\n",(0,s.jsx)(n.p,{children:"Implement functions to perform common vector operations used in robotics."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\ndef normalize_vector(vector):\n    """\n    Normalize a vector to unit length\n\n    Args:\n        vector: numpy array representing a 3D vector\n\n    Returns:\n        normalized vector\n    """\n    norm = np.linalg.norm(vector)\n    if norm == 0:\n        return vector\n    return vector / norm\n\ndef vector_projection(v1, v2):\n    """\n    Calculate the projection of v1 onto v2\n\n    Args:\n        v1, v2: numpy arrays representing 3D vectors\n\n    Returns:\n        projection of v1 onto v2\n    """\n    v2_norm = normalize_vector(v2)\n    scalar_proj = np.dot(v1, v2_norm)\n    return scalar_proj * v2_norm\n\ndef cross_product_matrix(vector):\n    """\n    Create the skew-symmetric matrix for cross product operation\n    Such that cross(a,b) = [a]_\xd7 b\n\n    Args:\n        vector: numpy array representing a 3D vector\n\n    Returns:\n        3x3 skew-symmetric matrix\n    """\n    x, y, z = vector\n    return np.array([\n        [0, -z, y],\n        [z, 0, -x],\n        [-y, x, 0]\n    ])\n\n# Test the functions\nv1 = np.array([1, 2, 3])\nv2 = np.array([4, 5, 6])\n\nnormalized_v1 = normalize_vector(v1)\nprojection = vector_projection(v1, v2)\ncross_matrix = cross_product_matrix(v1)\n\nprint(f"Original vector v1: {v1}")\nprint(f"Normalized v1: {normalized_v1}")\nprint(f"Projection of v1 onto v2: {projection}")\nprint(f"Cross product matrix of v1:\\n{cross_matrix}")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exercise-12-transformation-matrices",children:"Exercise 1.2: Transformation Matrices"}),"\n",(0,s.jsx)(n.p,{children:"Implement functions for creating and using transformation matrices in robotics."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def rotation_matrix_x(angle):\n    """Rotation matrix around X-axis"""\n    return np.array([\n        [1, 0, 0],\n        [0, np.cos(angle), -np.sin(angle)],\n        [0, np.sin(angle), np.cos(angle)]\n    ])\n\ndef rotation_matrix_y(angle):\n    """Rotation matrix around Y-axis"""\n    return np.array([\n        [np.cos(angle), 0, np.sin(angle)],\n        [0, 1, 0],\n        [-np.sin(angle), 0, np.cos(angle)]\n    ])\n\ndef rotation_matrix_z(angle):\n    """Rotation matrix around Z-axis"""\n    return np.array([\n        [np.cos(angle), -np.sin(angle), 0],\n        [np.sin(angle), np.cos(angle), 0],\n        [0, 0, 1]\n    ])\n\ndef homogeneous_transform(rotation_matrix, translation_vector):\n    """Create a 4x4 homogeneous transformation matrix"""\n    T = np.eye(4)\n    T[0:3, 0:3] = rotation_matrix\n    T[0:3, 3] = translation_vector\n    return T\n\ndef transform_point(point, transformation_matrix):\n    """\n    Transform a 3D point using a 4x4 homogeneous transformation matrix\n    """\n    # Convert point to homogeneous coordinates\n    homogeneous_point = np.append(point, 1)\n\n    # Apply transformation\n    transformed_homogeneous = transformation_matrix @ homogeneous_point\n\n    # Convert back to 3D coordinates\n    transformed_point = transformed_homogeneous[:3]\n\n    return transformed_point\n\n# Example: Create a transformation and apply it\nangle = np.pi / 4  # 45 degrees\nR_z = rotation_matrix_z(angle)\ntranslation = np.array([1, 2, 3])\nT = homogeneous_transform(R_z, translation)\n\npoint = np.array([1, 0, 0])\ntransformed_point = transform_point(point, T)\n\nprint(f"Original point: {point}")\nprint(f"Transformation matrix:\\n{T}")\nprint(f"Transformed point: {transformed_point}")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exercise-13-probability-and-statistics-for-sensor-fusion",children:"Exercise 1.3: Probability and Statistics for Sensor Fusion"}),"\n",(0,s.jsx)(n.p,{children:"Implement functions for handling uncertainty in sensor data."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def gaussian_pdf(x, mean, std_dev):\n    """Calculate probability density for Gaussian distribution"""\n    coefficient = 1 / (std_dev * np.sqrt(2 * np.pi))\n    exponent = -0.5 * ((x - mean) / std_dev) ** 2\n    return coefficient * np.exp(exponent)\n\ndef bayes_update(prior, likelihood, evidence):\n    """Apply Bayes\' theorem to update probability"""\n    posterior = (likelihood * prior) / evidence\n    return posterior\n\ndef weighted_average_fusion(measurements, uncertainties):\n    """\n    Fuse multiple sensor measurements using weighted average\n    measurements: list of measured values\n    uncertainties: list of uncertainty values (standard deviations)\n    """\n    # Calculate weights (inverse of variance)\n    weights = [1.0 / (unc**2) for unc in uncertainties]\n\n    # Calculate weighted sum\n    weighted_sum = sum(m * w for m, w in zip(measurements, weights))\n    total_weight = sum(weights)\n\n    # Calculate fused estimate\n    fused_estimate = weighted_sum / total_weight\n\n    # Calculate fused uncertainty\n    fused_uncertainty = np.sqrt(1.0 / total_weight)\n\n    return fused_estimate, fused_uncertainty\n\n# Example: Sensor fusion\nmeasurements = [10.2, 9.8, 10.1]\nuncertainties = [0.5, 0.8, 0.3]\n\nfused_result, fused_unc = weighted_average_fusion(measurements, uncertainties)\n\nprint(f"Measurements: {measurements}")\nprint(f"Uncertainties: {uncertainties}")\nprint(f"Fused result: {fused_result:.3f} \xb1 {fused_unc:.3f}")\n\n# Example: Bayes\' theorem\nprior_prob = 0.3  # Prior probability\nsensor_likelihood = 0.8  # P(evidence|hypothsis)\ntotal_evidence = 0.5  # P(evidence)\nposterior_prob = bayes_update(prior_prob, sensor_likelihood, total_evidence)\n\nprint(f"Prior: {prior_prob:.3f}, Likelihood: {sensor_likelihood:.3f}")\nprint(f"Posterior: {posterior_prob:.3f}")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"chapter-2-kinematics-and-dynamics---exercises",children:"Chapter 2: Kinematics and Dynamics - Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-21-forward-kinematics",children:"Exercise 2.1: Forward Kinematics"}),"\n",(0,s.jsx)(n.p,{children:"Implement forward kinematics for a simple robotic arm."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def dh_transform(a, alpha, d, theta):\n    """\n    Denavit-Hartenberg transformation matrix\n    a: link length\n    alpha: link twist\n    d: link offset\n    theta: joint angle\n    """\n    T = np.array([\n        [np.cos(theta), -np.sin(theta)*np.cos(alpha), np.sin(theta)*np.sin(alpha), a*np.cos(theta)],\n        [np.sin(theta), np.cos(theta)*np.cos(alpha), -np.cos(theta)*np.sin(alpha), a*np.sin(theta)],\n        [0, np.sin(alpha), np.cos(alpha), d],\n        [0, 0, 0, 1]\n    ])\n    return T\n\ndef forward_kinematics_planar_2dof(theta1, theta2, l1, l2):\n    """\n    Forward kinematics for 2-DOF planar manipulator\n    """\n    # Link 1 transformation\n    T1 = dh_transform(l1, 0, 0, theta1)\n\n    # Link 2 transformation relative to link 1\n    T2 = dh_transform(l2, 0, 0, theta2)\n\n    # Total transformation from base to end-effector\n    T_total = T1 @ T2\n\n    # Extract end-effector position\n    x = T_total[0, 3]\n    y = T_total[1, 3]\n\n    return np.array([x, y])\n\n# Example: Calculate end-effector position\ntheta1 = np.pi/4  # 45 degrees\ntheta2 = np.pi/6  # 30 degrees\nl1 = 1.0  # Link 1 length\nl2 = 0.8  # Link 2 length\n\nend_effector_pos = forward_kinematics_planar_2dof(theta1, theta2, l1, l2)\nprint(f"End-effector position: ({end_effector_pos[0]:.3f}, {end_effector_pos[1]:.3f})")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exercise-22-inverse-kinematics",children:"Exercise 2.2: Inverse Kinematics"}),"\n",(0,s.jsx)(n.p,{children:"Implement inverse kinematics for a simple robotic arm."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def inverse_kinematics_planar_2dof(x, y, l1, l2):\n    """\n    Inverse kinematics for 2-DOF planar manipulator\n    """\n    # Check if position is reachable\n    r = np.sqrt(x**2 + y**2)\n    if r > l1 + l2:\n        print("Position is outside workspace")\n        return None\n\n    if r < abs(l1 - l2):\n        print("Position is inside workspace but unreachable")\n        return None\n\n    # Calculate theta2\n    cos_theta2 = (x**2 + y**2 - l1**2 - l2**2) / (2 * l1 * l2)\n    sin_theta2 = np.sqrt(1 - cos_theta2**2)\n    theta2 = np.arctan2(sin_theta2, cos_theta2)\n\n    # Calculate theta1\n    k1 = l1 + l2 * cos_theta2\n    k2 = l2 * sin_theta2\n    theta1 = np.arctan2(y, x) - np.arctan2(k2, k1)\n\n    return np.array([theta1, theta2])\n\n# Example: Find joint angles for desired position\ndesired_pos = np.array([1.2, 0.8])\nangles = inverse_kinematics_planar_2dof(desired_pos[0], desired_pos[1], l1, l2)\n\nif angles is not None:\n    print(f"Required joint angles: [{np.degrees(angles[0]):.2f}\xb0, {np.degrees(angles[1]):.2f}\xb0]")\n\n    # Verify with forward kinematics\n    verify_pos = forward_kinematics_planar_2dof(angles[0], angles[1], l1, l2)\n    print(f"Verification - Forward kinematics result: ({verify_pos[0]:.3f}, {verify_pos[1]:.3f})")\n    print(f"Desired position: ({desired_pos[0]}, {desired_pos[1]})")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exercise-23-robot-dynamics",children:"Exercise 2.3: Robot Dynamics"}),"\n",(0,s.jsx)(n.p,{children:"Implement basic dynamic calculations for a robotic system."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def simple_pendulum_dynamics(theta, theta_dot, mass, length, gravity=9.81):\n    """\n    Calculate dynamics for a simple pendulum\n    """\n    # Equation of motion for simple pendulum: \u03b8_ddot = -(g/l)*sin(\u03b8)\n    theta_ddot = -(gravity / length) * np.sin(theta)\n\n    # Calculate kinetic and potential energy\n    kinetic_energy = 0.5 * mass * (length * theta_dot)**2\n    potential_energy = mass * gravity * length * (1 - np.cos(theta))\n\n    return theta_ddot, kinetic_energy, potential_energy\n\n# Example: Calculate pendulum dynamics\nmass = 1.0  # kg\nlength = 1.0  # m\ntheta = np.pi/6  # 30 degrees\ntheta_dot = 0.5  # rad/s\n\ntheta_ddot, ke, pe = simple_pendulum_dynamics(theta, theta_dot, mass, length)\nmechanical_energy = ke + pe\n\nprint(f"Pendulum dynamics:")\nprint(f"Angle: {np.degrees(theta):.2f}\xb0, Angular velocity: {theta_dot:.3f} rad/s")\nprint(f"Angular acceleration: {theta_ddot:.3f} rad/s\xb2")\nprint(f"Kinetic energy: {ke:.3f} J")\nprint(f"Potential energy: {pe:.3f} J")\nprint(f"Mechanical energy: {mechanical_energy:.3f} J")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"chapter-3-sensing-and-perception---exercises",children:"Chapter 3: Sensing and Perception - Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-31-sensor-models",children:"Exercise 3.1: Sensor Models"}),"\n",(0,s.jsx)(n.p,{children:"Implement basic sensor models for different types of sensors."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class RangeSensor:\n    def __init__(self, max_range=10.0, min_range=0.1, accuracy=0.01, fov=30):\n        """\n        Range sensor simulator (e.g., ultrasonic, IR, LiDAR)\n        """\n        self.max_range = max_range\n        self.min_range = min_range\n        self.accuracy = accuracy  # measurement accuracy\n        self.fov = fov  # field of view in degrees\n\n    def measure_distance(self, true_distance, add_noise=True):\n        """Measure distance with sensor limitations and noise"""\n        # Check if within range\n        if true_distance > self.max_range:\n            return float(\'inf\')  # Out of range\n        elif true_distance < self.min_range:\n            return self.min_range  # Too close\n\n        if add_noise:\n            noise = np.random.normal(0, self.accuracy)\n            measured = true_distance + noise\n            # Ensure within bounds\n            measured = max(self.min_range, min(self.max_range, measured))\n            return measured\n        return true_distance\n\n    def detect_object(self, true_distance, threshold=None):\n        """Detect if an object is within range"""\n        if threshold is None:\n            threshold = self.max_range\n        measured_dist = self.measure_distance(true_distance)\n        return measured_dist < threshold and measured_dist != float(\'inf\')\n\n# Example: Range sensor usage\nrange_sensor = RangeSensor(max_range=5.0, min_range=0.05, accuracy=0.02)\n\n# Test measurements at different distances\ntest_distances = [0.5, 1.0, 2.0, 4.0, 6.0, 0.02]\nfor dist in test_distances:\n    measured = range_sensor.measure_distance(dist)\n    detected = range_sensor.detect_object(dist)\n    print(f"True: {dist:.2f}m -> Measured: {measured:.2f}m, Detected: {detected}")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exercise-32-kalman-filter-implementation",children:"Exercise 3.2: Kalman Filter Implementation"}),"\n",(0,s.jsx)(n.p,{children:"Implement a simple Kalman filter for state estimation."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class SimpleKalmanFilter:\n    def __init__(self, initial_state, initial_uncertainty, process_noise, measurement_noise):\n        """\n        Simple Kalman filter for 1D position tracking\n        """\n        self.x = initial_state  # State (position)\n        self.P = initial_uncertainty  # Uncertainty\n        self.Q = process_noise  # Process noise\n        self.R = measurement_noise  # Measurement noise\n\n    def predict(self, dt, control_input=0):\n        """\n        Prediction step\n        """\n        # For constant velocity model: x = x + v*dt\n        # We assume velocity is part of state or control\n        self.x = self.x + control_input * dt\n        self.P = self.P + self.Q\n\n    def update(self, measurement):\n        """\n        Update step\n        """\n        # Calculate Kalman gain\n        S = self.P + self.R\n        K = self.P / S\n\n        # Update state estimate\n        innovation = measurement - self.x\n        self.x = self.x + K * innovation\n\n        # Update uncertainty\n        self.P = (1 - K) * self.P\n\n# Example: Track a moving object\nkf = SimpleKalmanFilter(initial_state=0.0, initial_uncertainty=10.0,\n                       process_noise=0.1, measurement_noise=1.0)\n\n# Simulate measurements\ntrue_positions = []\nmeasurements = []\nestimates = []\ntimes = []\n\ndt = 0.1\nfor t in np.arange(0, 5, dt):\n    # True position (with some motion)\n    true_pos = 0.1 * t**2  # Accelerating motion\n    true_positions.append(true_pos)\n\n    # Noisy measurement\n    measured_pos = true_pos + np.random.normal(0, 0.5)\n    measurements.append(measured_pos)\n\n    # Kalman filter update\n    kf.predict(dt, control_input=0.2*t)  # Approximate velocity\n    kf.update(measured_pos)\n    estimates.append(kf.x)\n    times.append(t)\n\nprint(f"Kalman filter example completed with {len(times)} steps")\nprint(f"Final estimate: {kf.x:.3f}, Final measurement: {measurements[-1]:.3f}")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"chapter-4-embodied-intelligence---exercises",children:"Chapter 4: Embodied Intelligence - Exercises"}),"\n",(0,s.jsx)(n.h3,{id:"exercise-41-embodied-agent-simulation",children:"Exercise 4.1: Embodied Agent Simulation"}),"\n",(0,s.jsx)(n.p,{children:"Implement a simple embodied agent that interacts with its environment."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class EmbodiedAgent:\n    """\n    Simple embodied agent demonstrating basic principles\n    """\n    def __init__(self, position=np.array([0.0, 0.0]), mass=1.0):\n        self.position = position\n        self.velocity = np.array([0.0, 0.0])\n        self.mass = mass\n        self.energy = 100.0  # Energy level\n\n    def sense_environment(self, environment):\n        """\n        Sense the environment\n        """\n        sensor_data = {\n            \'distance_to_goal\': np.linalg.norm(environment.goal - self.position),\n            \'obstacle_proximity\': self._check_obstacles(environment),\n            \'energy_level\': self.energy\n        }\n        return sensor_data\n\n    def _check_obstacles(self, environment):\n        """\n        Check for obstacles in the environment\n        """\n        min_distance = float(\'inf\')\n        for obstacle in environment.obstacles:\n            distance = np.linalg.norm(self.position - obstacle[\'position\'])\n            if distance < min_distance:\n                min_distance = distance\n        return min_distance\n\n    def act(self, sensor_data, environment):\n        """\n        Act based on sensor data\n        """\n        # Simple navigation behavior\n        direction_to_goal = environment.goal - self.position\n        distance_to_goal = np.linalg.norm(direction_to_goal)\n\n        if distance_to_goal < 0.1:  # Reached goal\n            return np.array([0.0, 0.0])\n\n        # Normalize direction\n        if distance_to_goal > 0:\n            direction_to_goal = direction_to_goal / distance_to_goal\n\n        # Simple obstacle avoidance\n        if sensor_data[\'obstacle_proximity\'] < 1.0:\n            # Move perpendicular to obstacle\n            obstacle_direction = self.position - environment.obstacles[0][\'position\']\n            obstacle_direction = obstacle_direction / np.linalg.norm(obstacle_direction)\n            avoidance = np.array([-obstacle_direction[1], obstacle_direction[0]])\n            direction_to_goal = 0.7 * direction_to_goal + 0.3 * avoidance\n\n        # Calculate required force (based on energy constraint)\n        desired_velocity = direction_to_goal * min(2.0, self.energy / 50.0)  # Slower when low energy\n        force = (desired_velocity - self.velocity) * self.mass\n\n        # Consume energy based on action\n        energy_cost = np.linalg.norm(force) * 0.1\n        self.energy = max(0, self.energy - energy_cost)\n\n        return force\n\n    def update(self, force, dt=0.1):\n        """\n        Update agent state based on applied force\n        """\n        # Apply force: F = ma => a = F/m\n        acceleration = force / self.mass\n\n        # Update velocity and position\n        self.velocity += acceleration * dt\n        self.position += self.velocity * dt\n\nclass SimpleEnvironment:\n    def __init__(self):\n        self.goal = np.array([10.0, 10.0])\n        self.obstacles = [\n            {\'position\': np.array([5.0, 5.0]), \'radius\': 1.0}\n        ]\n\n# Example: Run embodied agent simulation\nenv = SimpleEnvironment()\nagent = EmbodiedAgent(position=np.array([0.0, 0.0]))\n\nprint("Starting embodied agent simulation...")\nprint(f"Goal: {env.goal}, Starting position: {agent.position}")\n\n# Run simulation\nfor step in range(100):\n    sensor_data = agent.sense_environment(env)\n    force = agent.act(sensor_data, env)\n    agent.update(force, dt=0.1)\n\n    # Check if goal reached\n    if np.linalg.norm(agent.position - env.goal) < 0.5:\n        print(f"Goal reached at step {step}! Final position: {agent.position}")\n        break\n\n    # Print status periodically\n    if step % 20 == 0:\n        print(f"Step {step}: Position={agent.position}, Energy={agent.energy:.1f}")\n\nprint(f"Final position: {agent.position}, Energy: {agent.energy:.1f}")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exercise-42-morphological-computation",children:"Exercise 4.2: Morphological Computation"}),"\n",(0,s.jsx)(n.p,{children:"Demonstrate how physical properties can perform computation."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class MorphologicalComputer:\n    """\n    System that uses physical properties for computation\n    """\n    def __init__(self, material_type=\'elastic\'):\n        self.material_type = material_type\n        self.state = 0\n        self.memory = []  # Short-term memory through physical state\n\n    def process_signal(self, input_signal):\n        """\n        Process signal using material properties\n        """\n        if self.material_type == \'elastic\':\n            # Elastic material stores and releases energy - acts like a filter\n            processed = input_signal * 0.7 + self.state * 0.3  # Some memory\n            self.state = processed\n            self.memory.append(processed)\n\n            # Keep only last 5 values in memory\n            if len(self.memory) > 5:\n                self.memory.pop(0)\n\n            # Return smoothed signal based on recent history\n            return sum(self.memory) / len(self.memory)\n\n        elif self.material_type == \'viscous\':\n            # Viscous material dampens signals - acts like a low-pass filter\n            filtered = self.state * 0.8 + input_signal * 0.2\n            self.state = filtered\n            return filtered\n\n        elif self.material_type == \'adaptive\':\n            # Adaptive material changes properties based on input\n            if abs(input_signal) > 1.0:\n                # High input makes material stiffer\n                processed = input_signal * 0.9\n            else:\n                # Low input allows more compliance\n                processed = input_signal * 0.5 + self.state * 0.5\n\n            self.state = processed\n            return processed\n\n# Example: Compare different material computations\nmaterials = [\'elastic\', \'viscous\', \'adaptive\']\ninput_signals = [1.0, -0.5, 2.0, 0.3, -1.2, 0.8]\n\nfor material in materials:\n    computer = MorphologicalComputer(material)\n    print(f"\\n{material.capitalize()} material processing:")\n\n    for i, signal in enumerate(input_signals):\n        output = computer.process_signal(signal)\n        print(f"  Input: {signal:5.2f} -> Output: {output:5.2f}")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"implementation-guide",children:"Implementation Guide"}),"\n",(0,s.jsx)(n.h3,{id:"setting-up-your-development-environment",children:"Setting Up Your Development Environment"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Install Required Libraries"}),":"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install numpy matplotlib scipy pybullet\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Verify Installation"}),":"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import numpy as np\nimport matplotlib.pyplot as plt\nprint("Environment ready!")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"running-the-exercises",children:"Running the Exercises"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Copy the code for each exercise into a Python file"}),"\n",(0,s.jsx)(n.li,{children:"Run the code to see the results"}),"\n",(0,s.jsx)(n.li,{children:"Modify parameters to understand how different values affect the results"}),"\n",(0,s.jsx)(n.li,{children:"Try to extend the examples with your own variations"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"extending-the-exercises",children:"Extending the Exercises"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mathematical Foundations"}),": Try implementing quaternions for rotation representation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Kinematics"}),": Extend the 2-DOF example to 3-DOF or more complex manipulators"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sensing"}),": Add more sophisticated sensor models (camera, IMU)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Embodied Intelligence"}),": Create more complex environments with multiple goals"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"troubleshooting-tips",children:"Troubleshooting Tips"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ensure NumPy is properly installed for all mathematical operations"}),"\n",(0,s.jsxs)(n.li,{children:["For PyBullet exercises, install with: ",(0,s.jsx)(n.code,{children:"pip install pybullet"})]}),"\n",(0,s.jsx)(n.li,{children:"If getting errors with matrix operations, check dimensions carefully"}),"\n",(0,s.jsxs)(n.li,{children:["Use ",(0,s.jsx)(n.code,{children:"np.linalg.norm()"})," to compute vector magnitudes safely"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>r,x:()=>o});var i=t(6540);const s={},a=i.createContext(s);function r(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);