"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[5996],{5177(n,e,a){a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-3-digital-twin/chapter-3-sensor-simulation/solutions","title":"Physics Simulation and Sensor Simulation - Solutions","description":"Solution 3.1: Physics Parameter Tuning","source":"@site/docs/module-3-digital-twin/chapter-3-sensor-simulation/solutions.md","sourceDirName":"module-3-digital-twin/chapter-3-sensor-simulation","slug":"/module-3-digital-twin/chapter-3-sensor-simulation/solutions","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-3-digital-twin/chapter-3-sensor-simulation/solutions","draft":false,"unlisted":false,"editUrl":"https://github.com/shirazkk/Physicial_Ai_Book_Hackathon_1/edit/main/my-website/docs/module-3-digital-twin/chapter-3-sensor-simulation/solutions.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Physics Simulation and Sensor Simulation - Exercises","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-3-digital-twin/chapter-3-sensor-simulation/exercises"},"next":{"title":"Unity Visualization and Interaction","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-3-digital-twin/chapter-4-unity-integration/content"}}');var s=a(4848),t=a(8453);const r={},o="Physics Simulation and Sensor Simulation - Solutions",l={},d=[{value:"Solution 3.1: Physics Parameter Tuning",id:"solution-31-physics-parameter-tuning",level:2},{value:"Solution 3.2: LiDAR Sensor Implementation",id:"solution-32-lidar-sensor-implementation",level:2},{value:"Solution 3.3: Depth Camera Simulation",id:"solution-33-depth-camera-simulation",level:2},{value:"Solution 3.4: IMU Sensor Calibration and Noise Modeling",id:"solution-34-imu-sensor-calibration-and-noise-modeling",level:2},{value:"Solution 3.5: Sensor Fusion Algorithm Implementation",id:"solution-35-sensor-fusion-algorithm-implementation",level:2},{value:"Solution 3.6: Sensor Validation and Testing",id:"solution-36-sensor-validation-and-testing",level:2},{value:"Solution 3.7: Performance Optimization",id:"solution-37-performance-optimization",level:2},{value:"Solution 3.8: Environmental Effects on Sensors",id:"solution-38-environmental-effects-on-sensors",level:2},{value:"Back to Chapter Contents",id:"back-to-chapter-contents",level:2}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"physics-simulation-and-sensor-simulation---solutions",children:"Physics Simulation and Sensor Simulation - Solutions"})}),"\n",(0,s.jsx)(e.h2,{id:"solution-31-physics-parameter-tuning",children:"Solution 3.1: Physics Parameter Tuning"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Physics configuration for stable humanoid simulation:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:"<physics type='ode'>\n  <max_step_size>0.001</max_step_size>  \x3c!-- Small step for stability --\x3e\n  <real_time_factor>1.0</real_time_factor>\n  <real_time_update_rate>1000.0</real_time_update_rate>\n  <gravity>0 0 -9.8</gravity>\n  <ode>\n    <solver>\n      <type>quick</type>\n      <iters>100</iters>  \x3c!-- More iterations for stability --\x3e\n      <sor>1.3</sor>\n    </solver>\n    <constraints>\n      <cfm>1e-5</cfm>  \x3c!-- Small CFM for tight constraints --\x3e\n      <erp>0.8</erp>   \x3c!-- High ERP for good contact resolution --\x3e\n      <contact_max_correcting_vel>100.0</contact_max_correcting_vel>\n      <contact_surface_layer>0.001</contact_surface_layer>\n    </constraints>\n  </ode>\n</physics>\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Humanoid model with stable feet:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<link name="foot_link">\n  <visual>\n    <geometry>\n      <box size="0.15 0.08 0.05"/>\n    </geometry>\n  </visual>\n  <collision>\n    <geometry>\n      <box size="0.15 0.08 0.05"/>\n    </geometry>\n  </collision>\n  <inertial>\n    <mass value="0.5"/>\n    <inertia ixx="0.001" ixy="0.0" ixz="0.0" iyy="0.002" iyz="0.0" izz="0.002"/>\n  </inertial>\n  <surface>\n    <friction>\n      <ode>\n        <mu>0.8</mu>    \x3c!-- High friction for stability --\x3e\n        <mu2>0.8</mu2>\n      </ode>\n    </friction>\n    <contact>\n      <ode>\n        <soft_cfm>0.0</soft_cfm>\n        <soft_erp>0.2</soft_erp>\n        <kp>1e+6</kp>   \x3c!-- Stiff contact --\x3e\n        <kd>1e+3</kd>\n      </ode>\n    </contact>\n  </surface>\n</link>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Trade-offs:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stability vs. Performance: More iterations = more stable but slower"}),"\n",(0,s.jsx)(e.li,{children:"Accuracy vs. Speed: Smaller time steps = more accurate but computationally expensive"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"solution-32-lidar-sensor-implementation",children:"Solution 3.2: LiDAR Sensor Implementation"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Complete LiDAR configuration:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="front_lidar" type="ray">\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>360</samples>\n        <resolution>1</resolution>\n        <min_angle>-3.14159</min_angle>\n        <max_angle>3.14159</max_angle>\n      </horizontal>\n    </scan>\n    <range>\n      <min>0.1</min>\n      <max>10.0</max>\n      <resolution>0.01</resolution>\n    </range>\n    <noise>\n      <type>gaussian</type>\n      <mean>0.0</mean>\n      <stddev>0.02</stddev>  \x3c!-- 2cm noise --\x3e\n    </noise>\n  </ray>\n  <always_on>true</always_on>\n  <update_rate>10</update_rate>\n  <visualize>false</visualize>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Testing different surface materials:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Smooth surfaces (metal, glass): Clean reflections"}),"\n",(0,s.jsx)(e.li,{children:"Rough surfaces (grass, gravel): More scattering"}),"\n",(0,s.jsx)(e.li,{children:"Absorptive materials (carpet): Reduced range returns"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"solution-33-depth-camera-simulation",children:"Solution 3.3: Depth Camera Simulation"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Realistic depth camera configuration:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="rgb_depth_camera" type="depth">\n  <camera>\n    <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <clip>\n      <near>0.1</near>\n      <far>5.0</far>\n    </clip>\n    <noise>\n      <type>gaussian</type>\n      <mean>0.0</mean>\n      <stddev>0.005</stddev>  \x3c!-- 5mm at 1m --\x3e\n    </noise>\n  </camera>\n  <always_on>true</always_on>\n  <update_rate>30</update_rate>\n  <visualize>true</visualize>\n  <point_cloud>\n    <output>sensor</output>\n    <point_cloud_min_dist>0.1</point_cloud_min_dist>\n    <point_cloud_max_dist>5.0</point_cloud_max_dist>\n  </point_cloud>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Distance-dependent noise function:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def distance_dependent_noise(distance, base_noise=0.005):\n    """Model noise that increases with distance"""\n    return base_noise * (1 + distance * 0.1)  # Noise increases with distance\n'})}),"\n",(0,s.jsx)(e.h2,{id:"solution-34-imu-sensor-calibration-and-noise-modeling",children:"Solution 3.4: IMU Sensor Calibration and Noise Modeling"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Advanced IMU configuration:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\n  <always_on>true</always_on>\n  <update_rate>200</update_rate>\n  <imu>\n    <angular_velocity>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>1.2e-3</stddev>  \x3c!-- 1.2 mrad/s --\x3e\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>5.0e-4</bias_stddev>\n          <dynamic_bias_correlation_time>300</dynamic_bias_correlation_time>\n          <dynamic_bias_stddev>1.0e-5</dynamic_bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>1.2e-3</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>5.0e-4</bias_stddev>\n          <dynamic_bias_correlation_time>300</dynamic_bias_correlation_time>\n          <dynamic_bias_stddev>1.0e-5</dynamic_bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>1.2e-3</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>5.0e-4</bias_stddev>\n          <dynamic_bias_correlation_time>300</dynamic_bias_correlation_time>\n          <dynamic_bias_stddev>1.0e-5</dynamic_bias_stddev>\n        </noise>\n      </z>\n    </angular_velocity>\n    <linear_acceleration>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>8.3e-4</stddev>  \x3c!-- 830 \u03bcg --\x3e\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>1.7e-3</bias_stddev>\n          <dynamic_bias_correlation_time>300</dynamic_bias_correlation_time>\n          <dynamic_bias_stddev>1.0e-5</dynamic_bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>8.3e-4</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>1.7e-3</bias_stddev>\n          <dynamic_bias_correlation_time>300</dynamic_bias_correlation_time>\n          <dynamic_bias_stddev>1.0e-5</dynamic_bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>8.3e-4</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>1.7e-3</bias_stddev>\n          <dynamic_bias_correlation_time>300</dynamic_bias_correlation_time>\n          <dynamic_bias_stddev>1.0e-5</dynamic_bias_stddev>\n        </noise>\n      </z>\n    </linear_acceleration>\n  </imu>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"IMU bias drift simulation:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import numpy as np\n\nclass IMUBiasDrift:\n    def __init__(self):\n        self.accel_bias = np.random.normal(0, 1.7e-3, 3)  # Initial bias\n        self.gyro_bias = np.random.normal(0, 5.0e-4, 3)\n        self.time_constant = 300  # Correlation time in seconds\n\n    def update_bias(self, dt):\n        """Update bias with random walk"""\n        # Random walk for bias\n        self.accel_bias += np.random.normal(0, 1.0e-5, 3) * dt\n        self.gyro_bias += np.random.normal(0, 1.0e-6, 3) * dt\n        return self.accel_bias, self.gyro_bias\n'})}),"\n",(0,s.jsx)(e.h2,{id:"solution-35-sensor-fusion-algorithm-implementation",children:"Solution 3.5: Sensor Fusion Algorithm Implementation"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Extended Kalman Filter for position fusion:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.linalg import inv\n\nclass PositionEKF:\n    def __init__(self):\n        # State: [x, y, z, vx, vy, vz]\n        self.x = np.zeros(6)\n        self.P = np.eye(6) * 0.1  # Initial covariance\n        self.Q = np.diag([0.1, 0.1, 0.1, 0.01, 0.01, 0.01])  # Process noise\n        self.R_lidar = 0.02**2   # LiDAR measurement noise (2cm)\n        self.R_camera = 0.01**2  # Camera measurement noise (1cm)\n\n    def predict(self, dt):\n        """Motion model prediction"""\n        # State transition matrix for constant velocity model\n        F = np.array([\n            [1, 0, 0, dt, 0, 0],\n            [0, 1, 0, 0, dt, 0],\n            [0, 0, 1, 0, 0, dt],\n            [0, 0, 0, 1, 0, 0],\n            [0, 0, 0, 0, 1, 0],\n            [0, 0, 0, 0, 0, 1]\n        ])\n\n        # Process noise matrix\n        G = np.array([\n            [0.5*dt**2, 0, 0],\n            [0, 0.5*dt**2, 0],\n            [0, 0, 0.5*dt**2],\n            [dt, 0, 0],\n            [0, dt, 0],\n            [0, 0, dt]\n        ])\n\n        # Predict state and covariance\n        self.x = F @ self.x\n        self.P = F @ self.P @ F.T + G @ np.diag([0.1, 0.1, 0.1]) @ G.T\n\n    def update_lidar(self, z):\n        """Update with LiDAR position measurement [x, y, z]"""\n        # Observation matrix for position\n        H = np.array([\n            [1, 0, 0, 0, 0, 0],\n            [0, 1, 0, 0, 0, 0],\n            [0, 0, 1, 0, 0, 0]\n        ])\n\n        # Innovation\n        y = z - H @ self.x\n        S = H @ self.P @ H.T + np.eye(3) * self.R_lidar\n        K = self.P @ H.T @ inv(S)\n\n        # Update state and covariance\n        self.x = self.x + K @ y\n        I_KH = np.eye(len(self.x)) - K @ H\n        self.P = I_KH @ self.P\n\n    def update_camera(self, z):\n        """Update with camera position measurement [x, y, z]"""\n        H = np.array([\n            [1, 0, 0, 0, 0, 0],\n            [0, 1, 0, 0, 0, 0],\n            [0, 0, 1, 0, 0, 0]\n        ])\n\n        y = z - H @ self.x\n        S = H @ self.P @ H.T + np.eye(3) * self.R_camera\n        K = self.P @ H.T @ inv(S)\n\n        self.x = self.x + K @ y\n        I_KH = np.eye(len(self.x)) - K @ H\n        self.P = I_KH @ self.P\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Complementary filter for IMU-accelerometer fusion:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"class IMUComplementaryFilter:\n    def __init__(self, alpha=0.98):\n        self.alpha = alpha\n        self.pitch = 0.0\n        self.roll = 0.0\n        self.yaw = 0.0\n        self.dt = 0.01\n\n    def update(self, gyro_x, gyro_y, gyro_z, acc_x, acc_y, acc_z):\n        # Integrate gyroscope\n        self.pitch += gyro_x * self.dt\n        self.roll += gyro_y * self.dt\n        self.yaw += gyro_z * self.dt\n\n        # Calculate angles from accelerometer\n        pitch_acc = np.arctan2(acc_y, np.sqrt(acc_x**2 + acc_z**2))\n        roll_acc = np.arctan2(-acc_x, np.sqrt(acc_y**2 + acc_z**2))\n\n        # Complementary filter\n        self.pitch = self.alpha * self.pitch + (1 - self.alpha) * pitch_acc\n        self.roll = self.alpha * self.roll + (1 - self.alpha) * roll_acc\n\n        return self.pitch, self.roll, self.yaw\n"})}),"\n",(0,s.jsx)(e.h2,{id:"solution-36-sensor-validation-and-testing",children:"Solution 3.6: Sensor Validation and Testing"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Ground truth comparison:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def validate_lidar_accuracy(true_positions, measured_ranges, angles):\n    """Validate LiDAR accuracy against known positions"""\n    errors = []\n\n    for i, (true_pos, measured_range, angle) in enumerate(zip(true_positions, measured_ranges, angles)):\n        # Calculate expected range to ground truth\n        expected_range = np.linalg.norm(true_pos)\n\n        # Calculate error\n        error = abs(measured_range - expected_range)\n        errors.append(error)\n\n    # Calculate statistics\n    rmse = np.sqrt(np.mean(np.square(errors)))\n    mae = np.mean(np.abs(errors))\n    std_err = np.std(errors)\n\n    print(f"LIDAR Validation Results:")\n    print(f"  RMSE: {rmse:.4f} m")\n    print(f"  MAE: {mae:.4f} m")\n    print(f"  Std Dev: {std_err:.4f} m")\n    print(f"  Bias: {np.mean(errors):.4f} m")\n\n    return rmse, mae, std_err\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Statistical analysis of sensor noise:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def analyze_sensor_noise(data, sample_rate=100):\n    """Analyze noise characteristics of sensor data"""\n    from scipy import signal\n    from scipy.stats import kurtosis, skew\n\n    # Time domain analysis\n    mean_val = np.mean(data)\n    std_val = np.std(data)\n    variance = np.var(data)\n\n    # Frequency domain analysis (Power Spectral Density)\n    freqs, psd = signal.welch(data, fs=sample_rate, nperseg=len(data)//10)\n\n    # Statistical tests\n    kurt = kurtosis(data)\n    skewness = skew(data)\n\n    print(f"Statistical Analysis:")\n    print(f"  Mean: {mean_val:.6f}")\n    print(f"  Std Dev: {std_val:.6f}")\n    print(f"  Variance: {variance:.6f}")\n    print(f"  Kurtosis: {kurt:.4f} (Gaussian = 0)")\n    print(f"  Skewness: {skewness:.4f} (Symmetric = 0)")\n\n    return mean_val, std_val, variance, freqs, psd\n'})}),"\n",(0,s.jsx)(e.h2,{id:"solution-37-performance-optimization",children:"Solution 3.7: Performance Optimization"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Point cloud downsampling:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def voxel_grid_filter(points, voxel_size=0.01):\n    """Downsample point cloud using voxel grid filter"""\n    if len(points) == 0:\n        return points\n\n    # Convert to voxel coordinates\n    voxel_coords = np.floor(points / voxel_size).astype(int)\n\n    # Group points by voxel\n    voxel_dict = {}\n    for i, coord in enumerate(voxel_coords):\n        coord_tuple = tuple(coord)\n        if coord_tuple not in voxel_dict:\n            voxel_dict[coord_tuple] = []\n        voxel_dict[coord_tuple].append(i)\n\n    # Take centroid of each voxel\n    downsampled_indices = [indices[0] for indices in voxel_dict.values()]\n    return points[downsampled_indices]\n\ndef adaptive_downsampling(points, target_count=1000):\n    """Adaptively downsample to target point count"""\n    if len(points) <= target_count:\n        return points\n\n    step = len(points) // target_count\n    return points[::step]\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Multi-threaded sensor processing:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import threading\nimport queue\nimport time\n\nclass MultiThreadedSensorFusion:\n    def __init__(self):\n        self.lidar_queue = queue.Queue(maxsize=10)\n        self.camera_queue = queue.Queue(maxsize=10)\n        self.imu_queue = queue.Queue(maxsize=10)\n        self.fused_output = queue.Queue(maxsize=10)\n        self.running = True\n\n    def lidar_processor(self):\n        """Process LiDAR data in separate thread"""\n        while self.running:\n            try:\n                lidar_data = self.lidar_queue.get(timeout=0.1)\n                # Process LiDAR data\n                processed = self._process_lidar(lidar_data)\n                # Put on fusion queue\n                self.fused_output.put((\'lidar\', processed))\n            except queue.Empty:\n                continue\n\n    def camera_processor(self):\n        """Process camera data in separate thread"""\n        while self.running:\n            try:\n                camera_data = self.camera_queue.get(timeout=0.1)\n                processed = self._process_camera(camera_data)\n                self.fused_output.put((\'camera\', processed))\n            except queue.Empty:\n                continue\n\n    def start_processing(self):\n        """Start all processing threads"""\n        threading.Thread(target=self.lidar_processor, daemon=True).start()\n        threading.Thread(target=self.camera_processor, daemon=True).start()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"solution-38-environmental-effects-on-sensors",children:"Solution 3.8: Environmental Effects on Sensors"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Lighting effects on camera:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<sensor name="adaptive_camera" type="camera">\n  <camera>\n    <horizontal_fov>1.047</horizontal_fov>\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <clip>\n      <near>0.1</near>\n      <far>10.0</far>\n    </clip>\n    \x3c!-- Add exposure compensation for lighting --\x3e\n    <noise>\n      <type>gaussian</type>\n      <mean>0.0</mean>\n      <stddev>0.01</stddev>\n    </noise>\n  </camera>\n  <always_on>true</always_on>\n  <update_rate>30</update_rate>\n</sensor>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Weather effects on LiDAR:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def simulate_weather_effects(base_range, weather_condition="clear"):\n    """Simulate weather effects on LiDAR range measurements"""\n    if weather_condition == "clear":\n        return base_range\n    elif weather_condition == "fog":\n        # Fog reduces effective range\n        attenuation = 0.1  # 10% loss per meter\n        return base_range * np.exp(-attenuation * base_range)\n    elif weather_condition == "rain":\n        # Rain causes additional noise\n        noise_multiplier = 1.5\n        return base_range + np.random.normal(0, 0.02 * noise_multiplier)\n    elif weather_condition == "snow":\n        # Snow can cause false returns\n        false_return_prob = 0.05\n        if np.random.random() < false_return_prob:\n            return base_range * 0.5  # Early return\n        return base_range\n    else:\n        return base_range\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Electromagnetic interference on IMU:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def add_em_interference(raw_imu_data, interference_level=0.0):\n    """Add electromagnetic interference to IMU readings"""\n    if interference_level > 0:\n        # Add correlated noise that mimics EM interference\n        interference_signal = np.random.normal(0, interference_level, size=raw_imu_data.shape)\n        # Add some frequency components typical of EM interference\n        t = np.arange(len(interference_signal))\n        em_noise = 0.1 * interference_level * np.sin(2 * np.pi * 60 * t * 0.01)  # 60Hz line noise\n        return raw_imu_data + interference_signal + em_noise\n    return raw_imu_data\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"back-to-chapter-contents",children:"Back to Chapter Contents"}),"\n",(0,s.jsxs)(e.p,{children:["Return to ",(0,s.jsx)(e.a,{href:"/Physicial_Ai_Book_Hackathon_1/docs/module-3-digital-twin/chapter-3-sensor-simulation/content",children:"Chapter 3 Content"})," | Continue to ",(0,s.jsx)(e.a,{href:"/Physicial_Ai_Book_Hackathon_1/docs/module-3-digital-twin/chapter-4-unity-integration/content",children:"Chapter 4"})]})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}},8453(n,e,a){a.d(e,{R:()=>r,x:()=>o});var i=a(6540);const s={},t=i.createContext(s);function r(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);