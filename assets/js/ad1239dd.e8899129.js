"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[5673],{5369(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-2-robotic-nervous-system/chapter-4/solutions","title":"Solutions: Implementing Robotic Nervous System Patterns","description":"Solution for Exercise 1: Basic Reflex System Implementation","source":"@site/docs/module-2-robotic-nervous-system/chapter-4/solutions.md","sourceDirName":"module-2-robotic-nervous-system/chapter-4","slug":"/module-2-robotic-nervous-system/chapter-4/solutions","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-4/solutions","draft":false,"unlisted":false,"editUrl":"https://github.com/shirazkk/Physicial_Ai_Book_Hackathon_1/edit/main/my-website/docs/module-2-robotic-nervous-system/chapter-4/solutions.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Exercises: Implementing Robotic Nervous System Patterns","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-2-robotic-nervous-system/chapter-4/exercises"},"next":{"title":"Gazebo Simulation Environment Setup","permalink":"/Physicial_Ai_Book_Hackathon_1/docs/module-3-digital-twin/chapter-1-gazebo-basics/content"}}');var a=t(4848),o=t(8453);const r={},i="Solutions: Implementing Robotic Nervous System Patterns",l={},c=[{value:"Solution for Exercise 1: Basic Reflex System Implementation",id:"solution-for-exercise-1-basic-reflex-system-implementation",level:2},{value:"Complete Reflex System Code",id:"complete-reflex-system-code",level:3},{value:"How to Run",id:"how-to-run",level:3},{value:"Solution for Exercise 2: Hierarchical Control Architecture",id:"solution-for-exercise-2-hierarchical-control-architecture",level:2},{value:"Complete Hierarchical Control System",id:"complete-hierarchical-control-system",level:3},{value:"Solution for Exercise 3: Sensorimotor Integration",id:"solution-for-exercise-3-sensorimotor-integration",level:2},{value:"Complete Sensorimotor Integration System",id:"complete-sensorimotor-integration-system",level:3},{value:"Solution for Exercise 4: Adaptive Control System",id:"solution-for-exercise-4-adaptive-control-system",level:2},{value:"Complete Adaptive Control System",id:"complete-adaptive-control-system",level:3},{value:"Solution for Exercise 5: Coordination Manager",id:"solution-for-exercise-5-coordination-manager",level:2},{value:"Complete Coordination Manager",id:"complete-coordination-manager",level:3},{value:"Solution for Exercise 6: Bio-Inspired Neural Network (Advanced)",id:"solution-for-exercise-6-bio-inspired-neural-network-advanced",level:2},{value:"Complete Bio-Inspired Neural Network System",id:"complete-bio-inspired-neural-network-system",level:3},{value:"Implementation Guide",id:"implementation-guide",level:2},{value:"For Exercise 1 (Basic Reflex System):",id:"for-exercise-1-basic-reflex-system",level:3},{value:"For Exercise 2 (Hierarchical Control):",id:"for-exercise-2-hierarchical-control",level:3},{value:"For Exercise 3 (Sensorimotor Integration):",id:"for-exercise-3-sensorimotor-integration",level:3},{value:"For Exercise 4 (Adaptive Control):",id:"for-exercise-4-adaptive-control",level:3},{value:"For Exercise 5 (Coordination Manager):",id:"for-exercise-5-coordination-manager",level:3},{value:"For Exercise 6 (Bio-Inspired Neural Network):",id:"for-exercise-6-bio-inspired-neural-network",level:3},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"solutions-implementing-robotic-nervous-system-patterns",children:"Solutions: Implementing Robotic Nervous System Patterns"})}),"\n",(0,a.jsx)(n.h2,{id:"solution-for-exercise-1-basic-reflex-system-implementation",children:"Solution for Exercise 1: Basic Reflex System Implementation"}),"\n",(0,a.jsx)(n.h3,{id:"complete-reflex-system-code",children:"Complete Reflex System Code"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Bool\nimport numpy as np\n\nclass BasicReflexSystem(Node):\n    \"\"\"\n    Basic reflex system that immediately responds to obstacles.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('basic_reflex_system')\n\n        # Subscribe to laser scan data\n        self.laser_sub = self.create_subscription(\n            LaserScan, '/scan', self.laser_callback, 10)\n\n        # Publish emergency stop commands\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Emergency status publisher\n        self.emergency_pub = self.create_publisher(Bool, '/emergency_status', 10)\n\n        # High-frequency reflex timer (200 Hz for immediate response)\n        self.reflex_timer = self.create_timer(0.005, self.reflex_control)\n\n        # Internal state\n        self.laser_data = None\n        self.safety_threshold = 0.3  # meters\n        self.emergency_active = False\n\n        self.get_logger().info('Basic Reflex System initialized')\n\n    def laser_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        self.laser_data = np.array(msg.ranges)\n        # Filter invalid readings\n        self.laser_data[self.laser_data == float('inf')] = 3.5\n        self.laser_data[np.isnan(self.laser_data)] = 3.5\n\n    def reflex_control(self):\n        \"\"\"Main reflex control loop with immediate response\"\"\"\n        if self.laser_data is None:\n            return\n\n        # Find minimum distance to any obstacle\n        min_distance = np.min(self.laser_data) if self.laser_data.size > 0 else float('inf')\n\n        # Check for immediate danger\n        if min_distance < self.safety_threshold:\n            if not self.emergency_active:\n                self.emergency_active = True\n                self.get_logger().warn(f'EMERGENCY REFLEX: Obstacle detected at {min_distance:.2f}m! STOPPING!')\n\n                # Publish emergency status\n                emergency_msg = Bool()\n                emergency_msg.data = True\n                self.emergency_pub.publish(emergency_msg)\n\n            # Immediate stop command\n            stop_cmd = Twist()\n            self.cmd_vel_pub.publish(stop_cmd)\n        else:\n            # No immediate danger, but may need to slow down for approach\n            if self.emergency_active:\n                self.emergency_active = False\n                self.get_logger().info('REFLEX: Emergency cleared')\n\n                # Publish normal status\n                normal_msg = Bool()\n                normal_msg.data = False\n                self.emergency_pub.publish(normal_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    reflex_system = BasicReflexSystem()\n\n    try:\n        rclpy.spin(reflex_system)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        reflex_system.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"how-to-run",children:"How to Run"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Save the code as ",(0,a.jsx)(n.code,{children:"basic_reflex_system.py"})]}),"\n",(0,a.jsx)(n.li,{children:"Make sure your ROS 2 environment is sourced"}),"\n",(0,a.jsxs)(n.li,{children:["Run the node: ",(0,a.jsx)(n.code,{children:"python3 basic_reflex_system.py"})]}),"\n",(0,a.jsx)(n.li,{children:"Test with obstacles placed closer than 0.3 meters"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"solution-for-exercise-2-hierarchical-control-architecture",children:"Solution for Exercise 2: Hierarchical Control Architecture"}),"\n",(0,a.jsx)(n.h3,{id:"complete-hierarchical-control-system",children:"Complete Hierarchical Control System"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom std_msgs.msg import String, Bool\nfrom action_msgs.msg import GoalStatus\nimport json\nimport math\n\nclass HighLevelPlanner(Node):\n    """\n    High-level planning node - cortical level.\n    """\n    def __init__(self):\n        super().__init__(\'high_level_planner\')\n\n        # Publishers and subscribers\n        self.task_pub = self.create_publisher(String, \'/mid_level_tasks\', 10)\n        self.status_pub = self.create_publisher(String, \'/high_level_status\', 10)\n        self.goal_sub = self.create_subscription(PoseStamped, \'/navigation_goal\', self.goal_callback, 10)\n\n        # Timer for high-level planning\n        self.planning_timer = self.create_timer(0.5, self.planning_loop)  # 2 Hz\n\n        # Internal state\n        self.current_goal = None\n        self.plan = []\n        self.execution_status = "IDLE"\n\n        self.get_logger().info(\'High Level Planner initialized\')\n\n    def goal_callback(self, msg):\n        """Receive navigation goals"""\n        self.current_goal = msg\n        self.execution_status = "PLANNING"\n        self.get_logger().info(f\'Received goal: ({msg.pose.position.x:.2f}, {msg.pose.position.y:.2f})\')\n\n    def planning_loop(self):\n        """High-level planning and goal management"""\n        if self.execution_status == "PLANNING" and self.current_goal:\n            # Generate a simple plan (in real implementation, this would be actual path planning)\n            plan = [\n                {"type": "navigate", "target": [self.current_goal.pose.position.x, self.current_goal.pose.position.y]},\n                {"type": "wait", "duration": 2.0},\n                {"type": "return", "target": [0.0, 0.0]}\n            ]\n\n            self.plan = plan\n            self.execution_status = "EXECUTING"\n\n            # Send first task to mid-level\n            if self.plan:\n                task_msg = String()\n                task_msg.data = json.dumps(self.plan[0])\n                self.task_pub.publish(task_msg)\n                self.get_logger().info(f\'Sent task to mid-level: {self.plan[0]}\')\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = json.dumps({\n            "status": self.execution_status,\n            "current_goal": [self.current_goal.pose.position.x, self.current_goal.pose.position.y] if self.current_goal else None,\n            "plan_length": len(self.plan),\n            "tasks_completed": 0\n        })\n        self.status_pub.publish(status_msg)\n\nclass MidLevelTaskManager(Node):\n    """\n    Mid-level task execution - midbrain level.\n    """\n    def __init__(self):\n        super().__init__(\'mid_level_task_manager\')\n\n        # Publishers and subscribers\n        self.action_pub = self.create_publisher(String, \'/low_level_actions\', 10)\n        self.task_sub = self.create_subscription(String, \'/mid_level_tasks\', self.task_callback, 10)\n        self.status_pub = self.create_publisher(String, \'/mid_level_status\', 10)\n\n        # Timer for task management\n        self.task_timer = self.create_timer(0.1, self.task_execution_loop)  # 10 Hz\n\n        # Internal state\n        self.current_task = None\n        self.task_queue = []\n        self.execution_status = "IDLE"\n\n        self.get_logger().info(\'Mid Level Task Manager initialized\')\n\n    def task_callback(self, msg):\n        """Receive tasks from high-level planner"""\n        try:\n            task_data = json.loads(msg.data)\n            self.task_queue.append(task_data)\n            self.get_logger().info(f\'Received task: {task_data}\')\n        except Exception as e:\n            self.get_logger().error(f\'Error parsing task: {e}\')\n\n    def task_execution_loop(self):\n        """Execute tasks and break them into low-level actions"""\n        if not self.task_queue and not self.current_task:\n            return\n\n        if not self.current_task and self.task_queue:\n            self.current_task = self.task_queue.pop(0)\n            self.execution_status = "EXECUTING"\n\n        if self.current_task:\n            # Break down complex tasks into simple actions\n            action = self.task_to_action(self.current_task)\n\n            if action:\n                action_msg = String()\n                action_msg.data = json.dumps(action)\n                self.action_pub.publish(action_msg)\n\n                self.get_logger().info(f\'Sent action to low-level: {action}\')\n\n                # Check if task is completed\n                if self.is_task_completed(self.current_task):\n                    self.current_task = None\n                    self.execution_status = "IDLE"\n                    self.get_logger().info(\'Task completed\')\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = json.dumps({\n            "status": self.execution_status,\n            "current_task": self.current_task,\n            "queue_length": len(self.task_queue)\n        })\n        self.status_pub.publish(status_msg)\n\n    def task_to_action(self, task):\n        """Convert task to low-level action"""\n        task_type = task.get("type", "")\n\n        if task_type == "navigate":\n            target = task.get("target", [0, 0])\n            return {\n                "type": "move_to",\n                "x": target[0],\n                "y": target[1],\n                "speed": 0.5\n            }\n        elif task_type == "wait":\n            duration = task.get("duration", 1.0)\n            return {\n                "type": "wait",\n                "duration": duration\n            }\n        elif task_type == "return":\n            target = task.get("target", [0, 0])\n            return {\n                "type": "move_to",\n                "x": target[0],\n                "y": target[1],\n                "speed": 0.3\n            }\n\n        return None\n\n    def is_task_completed(self, task):\n        """Check if task is completed (simplified)"""\n        # In a real implementation, this would check actual robot position vs target\n        return True  # For this example, assume immediate completion\n\nclass LowLevelController(Node):\n    """\n    Low-level motor control - spinal level.\n    """\n    def __init__(self):\n        super().__init__(\'low_level_controller\')\n\n        # Publishers and subscribers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.action_sub = self.create_subscription(String, \'/low_level_actions\', self.action_callback, 10)\n        self.status_pub = self.create_publisher(String, \'/low_level_status\', 10)\n\n        # Timer for low-level control\n        self.control_timer = self.create_timer(0.02, self.control_loop)  # 50 Hz\n\n        # Internal state\n        self.current_action = None\n        self.action_start_time = None\n        self.execution_status = "IDLE"\n\n        self.get_logger().info(\'Low Level Controller initialized\')\n\n    def action_callback(self, msg):\n        """Receive low-level actions from mid-level"""\n        try:\n            action_data = json.loads(msg.data)\n            self.current_action = action_data\n            self.action_start_time = self.get_clock().now()\n            self.execution_status = "EXECUTING"\n            self.get_logger().info(f\'Received action: {action_data}\')\n        except Exception as e:\n            self.get_logger().error(f\'Error parsing action: {e}\')\n\n    def control_loop(self):\n        """Execute low-level motor commands"""\n        if not self.current_action:\n            # Send stop command if no action\n            stop_cmd = Twist()\n            self.cmd_vel_pub.publish(stop_cmd)\n            return\n\n        action_type = self.current_action.get("type", "")\n        cmd = Twist()\n\n        if action_type == "move_to":\n            # Simplified navigation - in reality, this would involve PID control, path following, etc.\n            cmd.linear.x = self.current_action.get("speed", 0.5)\n            cmd.angular.z = 0.0  # For simplicity, assume direct movement\n        elif action_type == "wait":\n            # During wait, send zero velocity\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n        elif action_type == "rotate":\n            cmd.angular.z = self.current_action.get("angular_speed", 0.5)\n\n        # Publish command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Check if action is completed\n        if self.is_action_completed():\n            self.current_action = None\n            self.execution_status = "IDLE"\n            self.get_logger().info(\'Action completed\')\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = json.dumps({\n            "status": self.execution_status,\n            "current_action": self.current_action\n        })\n        self.status_pub.publish(status_msg)\n\n    def is_action_completed(self):\n        """Check if current action is completed"""\n        if not self.current_action or not self.action_start_time:\n            return True\n\n        action_type = self.current_action.get("type", "")\n        if action_type == "wait":\n            duration = self.current_action.get("duration", 1.0)\n            elapsed = (self.get_clock().now() - self.action_start_time).nanoseconds / 1e9\n            return elapsed >= duration\n\n        # For movement actions, this would check actual position vs target\n        # For this example, assume a fixed duration\n        return False\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    # Create all nodes\n    high_level = HighLevelPlanner()\n    mid_level = MidLevelTaskManager()\n    low_level = LowLevelController()\n\n    # Create executor to handle multiple nodes\n    executor = rclpy.executors.MultiThreadedExecutor()\n    executor.add_node(high_level)\n    executor.add_node(mid_level)\n    executor.add_node(low_level)\n\n    try:\n        executor.spin()\n    except KeyboardInterrupt:\n        pass\n    finally:\n        high_level.destroy_node()\n        mid_level.destroy_node()\n        low_level.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"solution-for-exercise-3-sensorimotor-integration",children:"Solution for Exercise 3: Sensorimotor Integration"}),"\n",(0,a.jsx)(n.h3,{id:"complete-sensorimotor-integration-system",children:"Complete Sensorimotor Integration System"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Imu, Odometry\nfrom geometry_msgs.msg import Twist, Vector3\nfrom std_msgs.msg import Float64\nimport numpy as np\nimport math\nfrom collections import deque\n\nclass SensorimotorIntegration(Node):\n    \"\"\"\n    System that integrates multiple sensors to generate coordinated motor outputs.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('sensorimotor_integration')\n\n        # Multiple sensor subscriptions\n        self.laser_sub = self.create_subscription(LaserScan, '/scan', self.laser_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, '/imu', self.imu_callback, 10)\n        self.odom_sub = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)\n\n        # Motor command publisher\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Integration timer\n        self.integration_timer = self.create_timer(0.02, self.integration_loop)  # 50 Hz\n\n        # Internal sensor buffers\n        self.laser_buffer = deque(maxlen=5)\n        self.imu_buffer = deque(maxlen=5)\n        self.odom_buffer = deque(maxlen=5)\n\n        # Sensor data storage\n        self.sensors = {\n            'laser': None,\n            'imu': None,\n            'odom': None\n        }\n\n        # Integration parameters\n        self.integration_weights = {\n            'obstacle_avoidance': 0.4,\n            'balance_control': 0.3,\n            'navigation': 0.3\n        }\n\n        # Sensor validation thresholds\n        self.validation_thresholds = {\n            'laser_min_range': 0.1,\n            'laser_max_range': 3.5,\n            'imu_timeout': 1.0  # seconds\n        }\n\n        self.get_logger().info('Sensorimotor Integration System initialized')\n\n    def laser_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        # Validate laser data\n        ranges = np.array(msg.ranges)\n\n        # Filter invalid readings\n        ranges[ranges < self.validation_thresholds['laser_min_range']] = self.validation_thresholds['laser_max_range']\n        ranges[ranges > self.validation_thresholds['laser_max_range']] = self.validation_thresholds['laser_max_range']\n        ranges[np.isnan(ranges)] = self.validation_thresholds['laser_max_range']\n\n        self.sensors['laser'] = {\n            'ranges': ranges,\n            'angle_min': msg.angle_min,\n            'angle_max': msg.angle_max,\n            'angle_increment': msg.angle_increment,\n            'timestamp': self.get_clock().now().nanoseconds\n        }\n\n        # Add to buffer\n        self.laser_buffer.append(self.sensors['laser'])\n\n    def imu_callback(self, msg):\n        \"\"\"Process IMU data for balance control\"\"\"\n        # Extract orientation from quaternion\n        q = msg.orientation\n        siny_cosp = 2 * (q.w * q.z + q.x * q.y)\n        cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z)\n        yaw = math.atan2(siny_cosp, cosy_cosp)\n\n        self.sensors['imu'] = {\n            'orientation': {'roll': 0, 'pitch': 0, 'yaw': yaw},  # Simplified\n            'angular_velocity': {\n                'x': msg.angular_velocity.x,\n                'y': msg.angular_velocity.y,\n                'z': msg.angular_velocity.z\n            },\n            'linear_acceleration': {\n                'x': msg.linear_acceleration.x,\n                'y': msg.linear_acceleration.y,\n                'z': msg.linear_acceleration.z\n            },\n            'timestamp': self.get_clock().now().nanoseconds\n        }\n\n        # Add to buffer\n        self.imu_buffer.append(self.sensors['imu'])\n\n    def odom_callback(self, msg):\n        \"\"\"Process odometry data for navigation\"\"\"\n        self.sensors['odom'] = {\n            'position': {\n                'x': msg.pose.pose.position.x,\n                'y': msg.pose.pose.position.y,\n                'z': msg.pose.pose.position.z\n            },\n            'velocity': {\n                'linear': {\n                    'x': msg.twist.twist.linear.x,\n                    'y': msg.twist.twist.linear.y,\n                    'z': msg.twist.twist.linear.z\n                },\n                'angular': {\n                    'x': msg.twist.twist.angular.x,\n                    'y': msg.twist.twist.angular.y,\n                    'z': msg.twist.twist.angular.z\n                }\n            },\n            'timestamp': self.get_clock().now().nanoseconds\n        }\n\n        # Add to buffer\n        self.odom_buffer.append(self.sensors['odom'])\n\n    def integration_loop(self):\n        \"\"\"Main sensorimotor integration loop\"\"\"\n        if not all(self.sensors.values()):\n            return\n\n        # Process each sensor modality\n        obstacle_cmd = self.process_obstacle_avoidance()\n        balance_cmd = self.process_balance_control()\n        navigation_cmd = self.process_navigation()\n\n        # Weighted integration of commands\n        final_cmd = Twist()\n\n        # Combine linear components\n        final_cmd.linear.x = (\n            self.integration_weights['obstacle_avoidance'] * obstacle_cmd['linear_x'] +\n            self.integration_weights['balance_control'] * balance_cmd['linear_x'] +\n            self.integration_weights['navigation'] * navigation_cmd['linear_x']\n        )\n\n        # Combine angular components\n        final_cmd.angular.z = (\n            self.integration_weights['obstacle_avoidance'] * obstacle_cmd['angular_z'] +\n            self.integration_weights['balance_control'] * balance_cmd['angular_z'] +\n            self.integration_weights['navigation'] * navigation_cmd['angular_z']\n        )\n\n        # Apply safety limits\n        final_cmd.linear.x = max(-1.0, min(1.0, final_cmd.linear.x))\n        final_cmd.angular.z = max(-1.0, min(1.0, final_cmd.angular.z))\n\n        # Publish integrated command\n        self.cmd_vel_pub.publish(final_cmd)\n\n        self.get_logger().debug(f'Integrated command: linear={final_cmd.linear.x:.2f}, angular={final_cmd.angular.z:.2f}')\n\n    def process_obstacle_avoidance(self):\n        \"\"\"Process laser data for obstacle avoidance\"\"\"\n        if not self.sensors['laser']:\n            return {'linear_x': 0.0, 'angular_z': 0.0}\n\n        laser_data = self.sensors['laser']['ranges']\n        min_distance = np.min(laser_data) if laser_data.size > 0 else float('inf')\n\n        cmd = {'linear_x': 0.0, 'angular_z': 0.0}\n\n        if min_distance < 0.3:  # Emergency avoidance\n            cmd['linear_x'] = -0.3  # Back up\n            # Turn away from closest obstacle\n            closest_idx = np.argmin(laser_data)\n            cmd['angular_z'] = 0.8 if closest_idx < len(laser_data) / 2 else -0.8\n        elif min_distance < 0.8:  # Normal avoidance\n            cmd['linear_x'] = max(0.1, min_distance * 0.4)  # Slow down proportionally\n            # Gentle turn away from closest obstacle\n            closest_idx = np.argmin(laser_data)\n            cmd['angular_z'] = 0.4 if closest_idx < len(laser_data) / 2 else -0.4\n        else:  # Clear path\n            cmd['linear_x'] = 0.6  # Normal forward speed\n            cmd['angular_z'] = 0.0  # No turn\n\n        return cmd\n\n    def process_balance_control(self):\n        \"\"\"Process IMU data for balance control\"\"\"\n        if not self.sensors['imu']:\n            return {'linear_x': 0.0, 'angular_z': 0.0}\n\n        # Extract orientation data\n        yaw = self.sensors['imu']['orientation']['yaw']\n\n        cmd = {'linear_x': 0.0, 'angular_z': 0.0}\n\n        # Simple balance correction based on orientation\n        # In a real system, this would be more sophisticated\n        if abs(yaw) > 0.2:  # Significant orientation error\n            cmd['angular_z'] = -yaw * 1.5  # Correct by turning opposite to error\n        else:\n            cmd['angular_z'] = -yaw * 0.8  # Gentle correction\n\n        return cmd\n\n    def process_navigation(self):\n        \"\"\"Process odometry for navigation\"\"\"\n        if not self.sensors['odom']:\n            return {'linear_x': 0.0, 'angular_z': 0.0}\n\n        # Extract velocity data\n        linear_vel = self.sensors['odom']['velocity']['linear']['x']\n        angular_vel = self.sensors['odom']['velocity']['angular']['z']\n\n        cmd = {'linear_x': 0.0, 'angular_z': 0.0}\n\n        # For this example, maintain current velocity as baseline\n        # In a real system, this would involve goal-seeking behavior\n        cmd['linear_x'] = 0.3  # Default forward motion\n        cmd['angular_z'] = 0.0  # Default no turn\n\n        return cmd\n\ndef main(args=None):\n    rclpy.init(args=args)\n    sensorimotor_system = SensorimotorIntegration()\n\n    try:\n        rclpy.spin(sensorimotor_system)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        sensorimotor_system.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"solution-for-exercise-4-adaptive-control-system",children:"Solution for Exercise 4: Adaptive Control System"}),"\n",(0,a.jsx)(n.h3,{id:"complete-adaptive-control-system",children:"Complete Adaptive Control System"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Odometry\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Float64\nimport numpy as np\nimport math\nfrom collections import deque\nimport json\nimport os\nimport pickle\n\nclass AdaptiveControlSystem(Node):\n    \"\"\"\n    Adaptive control system that learns and improves behavior over time.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('adaptive_control_system')\n\n        # Sensor subscriptions\n        self.laser_sub = self.create_subscription(LaserScan, '/scan', self.laser_callback, 10)\n        self.odom_sub = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)\n\n        # Motor command publisher\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Learning and adaptation timer\n        self.adaptation_timer = self.create_timer(0.1, self.adaptation_loop)  # 10 Hz\n\n        # Internal state\n        self.sensors = {\n            'laser': None,\n            'odom': None\n        }\n\n        # Learning components\n        self.experience_buffer = deque(maxlen=500)  # Store experiences\n        self.performance_history = deque(maxlen=100)  # Track performance\n        self.learning_params = {\n            'learning_rate': 0.01,\n            'exploration_rate': 0.1,\n            'discount_factor': 0.9,\n            'performance_threshold': 0.7\n        }\n\n        # Adaptive parameters\n        self.adaptive_params = {\n            'obstacle_threshold': 0.8,\n            'approach_speed_factor': 0.5,\n            'turn_sensitivity': 0.8,\n            'safety_margin': 0.3\n        }\n\n        # Learned behaviors (state-action mappings)\n        self.learnt_behaviors = {}\n\n        # Performance tracking\n        self.total_distance_traveled = 0.0\n        self.collision_count = 0\n        self.safety_violation_count = 0\n\n        # Load saved learning if available\n        self.load_learning()\n\n        self.get_logger().info('Adaptive Control System initialized')\n\n    def laser_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        ranges = np.array(msg.ranges)\n        # Filter invalid readings\n        ranges[ranges == float('inf')] = 3.5\n        ranges[np.isnan(ranges)] = 3.5\n        ranges[ranges < 0.1] = 3.5  # Remove very close invalid readings\n\n        self.sensors['laser'] = {\n            'ranges': ranges,\n            'min_distance': float(np.min(ranges)) if ranges.size > 0 else float('inf'),\n            'front_clear': float(np.min(ranges[len(ranges)//2-10:len(ranges)//2+10])) if ranges.size > 20 else float('inf'),\n            'left_clear': float(np.min(ranges[:len(ranges)//4])) if ranges.size > 0 else float('inf'),\n            'right_clear': float(np.min(ranges[3*len(ranges)//4:])) if ranges.size > 0 else float('inf'),\n            'timestamp': self.get_clock().now().nanoseconds\n        }\n\n    def odom_callback(self, msg):\n        \"\"\"Process odometry data\"\"\"\n        self.sensors['odom'] = {\n            'position': {\n                'x': msg.pose.pose.position.x,\n                'y': msg.pose.pose.position.y\n            },\n            'velocity': {\n                'linear': msg.twist.twist.linear.x,\n                'angular': msg.twist.twist.angular.z\n            },\n            'timestamp': self.get_clock().now().nanoseconds\n        }\n\n    def adaptation_loop(self):\n        \"\"\"Main adaptation loop\"\"\"\n        if not all(self.sensors.values()):\n            return\n\n        # Get current state representation\n        current_state = self.get_state_representation()\n\n        # Select action based on current state and learning\n        action = self.select_adaptive_action(current_state)\n\n        # Execute action\n        self.execute_action(action)\n\n        # Evaluate performance\n        performance = self.evaluate_performance()\n\n        # Store experience for learning\n        experience = {\n            'state': current_state,\n            'action': action,\n            'performance': performance,\n            'timestamp': self.get_clock().now().nanoseconds\n        }\n        self.experience_buffer.append(experience)\n        self.performance_history.append(performance)\n\n        # Update learning periodically\n        if len(self.experience_buffer) % 10 == 0:\n            self.update_learning()\n\n        # Log performance metrics periodically\n        if len(self.performance_history) % 50 == 0:\n            avg_performance = np.mean(list(self.performance_history))\n            self.get_logger().info(f'Performance: avg={avg_performance:.3f}, collisions={self.collision_count}')\n\n    def get_state_representation(self):\n        \"\"\"Create a discrete state representation from sensor data\"\"\"\n        if not self.sensors['laser']:\n            return \"unknown\"\n\n        laser = self.sensors['laser']\n\n        # Discretize sensor readings\n        min_dist_category = self.categorize_distance(laser['min_distance'])\n        front_clear_category = self.categorize_distance(laser['front_clear'])\n        approach_state = \"approaching\" if laser['min_distance'] < self.adaptive_params['obstacle_threshold'] else \"clear\"\n\n        # Create state key\n        state_key = f\"{min_dist_category}_{front_clear_category}_{approach_state}\"\n        return state_key\n\n    def categorize_distance(self, distance):\n        \"\"\"Categorize distance into discrete bins\"\"\"\n        if distance < 0.3:\n            return \"very_close\"\n        elif distance < 0.6:\n            return \"close\"\n        elif distance < 1.0:\n            return \"medium\"\n        else:\n            return \"far\"\n\n    def select_adaptive_action(self, state):\n        \"\"\"Select action based on state and learned knowledge\"\"\"\n        # Check if we have learned behavior for this state\n        if state in self.learnt_behaviors:\n            # Use learned behavior with some exploration\n            if np.random.random() < self.learning_params['exploration_rate']:\n                # Explore: random action\n                return self.generate_exploratory_action()\n            else:\n                # Exploit: use learned behavior\n                return self.learnt_behaviors[state]\n        else:\n            # No learned behavior, use default adaptive controller\n            return self.adaptive_behavior()\n\n    def generate_exploratory_action(self):\n        \"\"\"Generate a random exploratory action\"\"\"\n        cmd = Twist()\n        cmd.linear.x = np.random.uniform(0.1, 0.8)  # Forward speed between 0.1 and 0.8\n        cmd.angular.z = np.random.uniform(-0.8, 0.8)  # Turn rate between -0.8 and 0.8\n        return cmd\n\n    def adaptive_behavior(self):\n        \"\"\"Default adaptive behavior based on current sensor readings\"\"\"\n        if not self.sensors['laser']:\n            cmd = Twist()\n            cmd.linear.x = 0.3\n            cmd.angular.z = 0.0\n            return cmd\n\n        laser = self.sensors['laser']\n        cmd = Twist()\n\n        # Adaptive obstacle avoidance\n        if laser['min_distance'] < self.adaptive_params['safety_margin']:\n            # Emergency stop - too close to obstacle\n            cmd.linear.x = -0.3  # Back up slowly\n            # Turn away from closest obstacle\n            ranges = laser['ranges']\n            closest_idx = np.argmin(ranges)\n            cmd.angular.z = 0.6 if closest_idx < len(ranges) / 2 else -0.6\n        elif laser['min_distance'] < self.adaptive_params['obstacle_threshold']:\n            # Normal obstacle avoidance\n            cmd.linear.x = max(0.1, laser['min_distance'] * self.adaptive_params['approach_speed_factor'])\n\n            # Turn away from closest obstacle with adaptive sensitivity\n            ranges = laser['ranges']\n            closest_idx = np.argmin(ranges)\n            turn_direction = 0.6 if closest_idx < len(ranges) / 2 else -0.6\n            cmd.angular.z = turn_direction * self.adaptive_params['turn_sensitivity']\n        else:\n            # Clear path, move forward\n            cmd.linear.x = 0.6\n            cmd.angular.z = 0.0\n\n        return cmd\n\n    def execute_action(self, action):\n        \"\"\"Execute the selected action\"\"\"\n        self.cmd_vel_pub.publish(action)\n\n    def evaluate_performance(self):\n        \"\"\"Evaluate the performance of the current behavior\"\"\"\n        if not all(self.sensors.values()):\n            return 0.0\n\n        laser = self.sensors['laser']\n        velocity = self.sensors['odom']['velocity']['linear']\n\n        # Performance metric combining safety and progress\n        safety_score = 1.0 if laser['min_distance'] > 0.5 else laser['min_distance'] / 0.5\n        progress_score = max(0.0, velocity) if velocity > 0 else 0.0  # Only reward forward movement\n\n        # Combine scores with weights\n        performance = 0.6 * progress_score + 0.4 * safety_score\n        return min(1.0, performance)  # Normalize to [0, 1]\n\n    def update_learning(self):\n        \"\"\"Update learned behaviors based on experiences\"\"\"\n        if len(self.experience_buffer) < 20:\n            return\n\n        # Get recent experiences\n        recent_experiences = list(self.experience_buffer)[-20:]\n\n        for exp in recent_experiences:\n            state = exp['state']\n            action = exp['action']\n            performance = exp['performance']\n\n            if performance > self.learning_params['performance_threshold']:\n                # Good performance - reinforce this behavior\n                if state not in self.learnt_behaviors:\n                    self.learnt_behaviors[state] = action\n                else:\n                    # Update towards successful action\n                    current_action = self.learnt_behaviors[state]\n                    # Gradually adjust towards successful action\n                    new_linear = (1 - self.learning_params['learning_rate']) * current_action.linear.x + \\\n                                self.learning_params['learning_rate'] * action.linear.x\n                    new_angular = (1 - self.learning_params['learning_rate']) * current_action.angular.z + \\\n                                 self.learning_params['learning_rate'] * action.angular.z\n\n                    new_action = Twist()\n                    new_action.linear.x = new_linear\n                    new_action.angular.z = new_angular\n                    self.learnt_behaviors[state] = new_action\n\n        # Adjust exploration rate based on performance\n        if self.performance_history:\n            recent_avg = np.mean(list(self.performance_history)[-20:])\n            if recent_avg > 0.8:\n                # High performance, reduce exploration\n                self.learning_params['exploration_rate'] = max(0.05,\n                    self.learning_params['exploration_rate'] * 0.95)\n            elif recent_avg < 0.5:\n                # Low performance, increase exploration\n                self.learning_params['exploration_rate'] = min(0.3,\n                    self.learning_params['exploration_rate'] * 1.05)\n\n        # Adapt parameters based on experience\n        self.adapt_parameters()\n\n    def adapt_parameters(self):\n        \"\"\"Adapt control parameters based on performance\"\"\"\n        if not self.performance_history:\n            return\n\n        recent_performance = np.mean(list(self.performance_history)[-20:]) if len(self.performance_history) >= 20 else 0.0\n\n        # Adapt obstacle threshold based on collision frequency\n        if self.collision_count > 0 and len(self.performance_history) > 50:\n            collision_rate = self.collision_count / len(self.performance_history)\n            if collision_rate > 0.05:  # Too many collisions\n                # Increase safety margin\n                self.adaptive_params['obstacle_threshold'] = min(1.5,\n                    self.adaptive_params['obstacle_threshold'] * 1.05)\n                self.adaptive_params['safety_margin'] = min(0.5,\n                    self.adaptive_params['safety_margin'] * 1.1)\n            elif recent_performance > 0.8 and collision_rate < 0.01:  # Good performance, few collisions\n                # Can be more aggressive\n                self.adaptive_params['obstacle_threshold'] = max(0.5,\n                    self.adaptive_params['obstacle_threshold'] * 0.98)\n                self.adaptive_params['safety_margin'] = max(0.15,\n                    self.adaptive_params['safety_margin'] * 0.98)\n\n        # Adapt turn sensitivity based on navigation success\n        if recent_performance > 0.7:\n            self.adaptive_params['turn_sensitivity'] = min(1.0,\n                self.adaptive_params['turn_sensitivity'] * 1.01)\n        else:\n            self.adaptive_params['turn_sensitivity'] = max(0.3,\n                self.adaptive_params['turn_sensitivity'] * 0.99)\n\n    def save_learning(self):\n        \"\"\"Save learned behaviors and parameters to file\"\"\"\n        learning_data = {\n            'learnt_behaviors': self.learnt_behaviors,\n            'adaptive_params': self.adaptive_params,\n            'learning_params': self.learning_params,\n            'experience_count': len(self.experience_buffer),\n            'performance_stats': {\n                'total_distance': self.total_distance_traveled,\n                'collision_count': self.collision_count,\n                'safety_violations': self.safety_violation_count\n            }\n        }\n\n        try:\n            with open('adaptive_control_learning.pkl', 'wb') as f:\n                pickle.dump(learning_data, f)\n            self.get_logger().info('Learning data saved successfully')\n        except Exception as e:\n            self.get_logger().error(f'Failed to save learning data: {e}')\n\n    def load_learning(self):\n        \"\"\"Load learned behaviors and parameters from file\"\"\"\n        if os.path.exists('adaptive_control_learning.pkl'):\n            try:\n                with open('adaptive_control_learning.pkl', 'rb') as f:\n                    learning_data = pickle.load(f)\n\n                self.learnt_behaviors = learning_data.get('learnt_behaviors', {})\n                self.adaptive_params = learning_data.get('adaptive_params', self.adaptive_params)\n                self.learning_params = learning_data.get('learning_params', self.learning_params)\n\n                stats = learning_data.get('performance_stats', {})\n                self.total_distance_traveled = stats.get('total_distance', 0.0)\n                self.collision_count = stats.get('collision_count', 0)\n                self.safety_violation_count = stats.get('safety_violations', 0)\n\n                self.get_logger().info(f'Learning data loaded: {learning_data.get(\"experience_count\", 0)} experiences')\n            except Exception as e:\n                self.get_logger().error(f'Failed to load learning data: {e}')\n\n    def destroy_node(self):\n        \"\"\"Save learning before shutdown\"\"\"\n        self.save_learning()\n        super().destroy_node()\n\ndef main(args=None):\n    rclpy.init(args=args)\n    adaptive_system = AdaptiveControlSystem()\n\n    try:\n        rclpy.spin(adaptive_system)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        adaptive_system.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"solution-for-exercise-5-coordination-manager",children:"Solution for Exercise 5: Coordination Manager"}),"\n",(0,a.jsx)(n.h3,{id:"complete-coordination-manager",children:"Complete Coordination Manager"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Bool\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nimport json\nfrom enum import Enum\nfrom collections import deque\n\nclass ControlLevel(Enum):\n    REFLEX = 1\n    SPINAL = 2\n    MIDBRAIN = 3\n    CORTICAL = 4\n\nclass CoordinationManager(Node):\n    \"\"\"\n    Manages coordination between different control levels and resolves conflicts.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('coordination_manager')\n\n        # Subscriptions for status from all levels\n        self.high_status_sub = self.create_subscription(String, '/high_level_status', self.high_status_callback, 10)\n        self.mid_status_sub = self.create_subscription(String, '/mid_level_status', self.mid_status_callback, 10)\n        self.low_status_sub = self.create_subscription(String, '/low_level_status', self.low_status_callback, 10)\n        self.reflex_status_sub = self.create_subscription(String, '/reflex_status', self.reflex_status_callback, 10)\n\n        # Subscriptions for commands from all levels\n        self.high_cmd_sub = self.create_subscription(String, '/high_level_commands', self.high_cmd_callback, 10)\n        self.mid_cmd_sub = self.create_subscription(String, '/mid_level_commands', self.mid_cmd_callback, 10)\n        self.low_cmd_sub = self.create_subscription(String, '/low_level_commands', self.low_cmd_callback, 10)\n        self.reflex_cmd_sub = self.create_subscription(String, '/reflex_commands', self.reflex_cmd_callback, 10)\n\n        # Emergency override subscription\n        self.emergency_sub = self.create_subscription(Bool, '/emergency_override', self.emergency_callback, 10)\n\n        # Motor command publisher\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n\n        # Coordination timer\n        self.coordination_timer = self.create_timer(0.01, self.coordination_loop)  # 100 Hz\n\n        # Status tracking\n        self.level_status = {\n            ControlLevel.REFLEX: None,\n            ControlLevel.SPINAL: None,\n            ControlLevel.MIDBRAIN: None,\n            ControlLevel.CORTICAL: None\n        }\n\n        # Command queues for each level\n        self.command_queues = {\n            ControlLevel.REFLEX: deque(maxlen=10),\n            ControlLevel.SPINAL: deque(maxlen=10),\n            ControlLevel.MIDBRAIN: deque(maxlen=10),\n            ControlLevel.CORTICAL: deque(maxlen=10)\n        }\n\n        # Priority mapping\n        self.level_priority = {\n            ControlLevel.REFLEX: 100,      # Highest priority\n            ControlLevel.SPINAL: 80,\n            ControlLevel.MIDBRAIN: 60,\n            ControlLevel.CORTICAL: 40      # Lowest priority\n        }\n\n        # Active commands\n        self.active_commands = {}\n        self.command_timestamps = {}\n\n        # Emergency state\n        self.emergency_override = False\n        self.emergency_reason = \"\"\n        self.emergency_start_time = None\n\n        # Conflict tracking\n        self.conflict_history = deque(maxlen=50)\n\n        self.get_logger().info('Coordination Manager initialized')\n\n    def high_status_callback(self, msg):\n        try:\n            self.level_status[ControlLevel.CORTICAL] = json.loads(msg.data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid high-level status format: {e}')\n\n    def mid_status_callback(self, msg):\n        try:\n            self.level_status[ControlLevel.MIDBRAIN] = json.loads(msg.data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid mid-level status format: {e}')\n\n    def low_status_callback(self, msg):\n        try:\n            self.level_status[ControlLevel.SPINAL] = json.loads(msg.data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid low-level status format: {e}')\n\n    def reflex_status_callback(self, msg):\n        try:\n            self.level_status[ControlLevel.REFLEX] = json.loads(msg.data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid reflex status format: {e}')\n\n    def high_cmd_callback(self, msg):\n        try:\n            cmd_data = json.loads(msg.data)\n            cmd_data['level'] = ControlLevel.CORTICAL\n            cmd_data['timestamp'] = self.get_clock().now().nanoseconds\n            self.command_queues[ControlLevel.CORTICAL].append(cmd_data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid high-level command format: {e}')\n\n    def mid_cmd_callback(self, msg):\n        try:\n            cmd_data = json.loads(msg.data)\n            cmd_data['level'] = ControlLevel.MIDBRAIN\n            cmd_data['timestamp'] = self.get_clock().now().nanoseconds\n            self.command_queues[ControlLevel.MIDBRAIN].append(cmd_data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid mid-level command format: {e}')\n\n    def low_cmd_callback(self, msg):\n        try:\n            cmd_data = json.loads(msg.data)\n            cmd_data['level'] = ControlLevel.SPINAL\n            cmd_data['timestamp'] = self.get_clock().now().nanoseconds\n            self.command_queues[ControlLevel.SPINAL].append(cmd_data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid low-level command format: {e}')\n\n    def reflex_cmd_callback(self, msg):\n        try:\n            cmd_data = json.loads(msg.data)\n            cmd_data['level'] = ControlLevel.REFLEX\n            cmd_data['timestamp'] = self.get_clock().now().nanoseconds\n            self.command_queues[ControlLevel.REFLEX].append(cmd_data)\n        except Exception as e:\n            self.get_logger().warn(f'Invalid reflex command format: {e}')\n\n    def emergency_callback(self, msg):\n        \"\"\"Handle emergency override\"\"\"\n        self.emergency_override = msg.data\n        if self.emergency_override:\n            self.emergency_reason = \"External Emergency Override\"\n            self.emergency_start_time = self.get_clock().now()\n            self.get_logger().fatal('EMERGENCY OVERRIDE ACTIVATED')\n\n            # Send emergency stop\n            self.send_emergency_stop()\n        else:\n            self.emergency_reason = \"\"\n            self.get_logger().info('EMERGENCY OVERRIDE CLEARED')\n\n    def coordination_loop(self):\n        \"\"\"Main coordination loop\"\"\"\n        if self.emergency_override:\n            # Emergency has highest priority, no coordination needed\n            return\n\n        # Check for conflicts between levels\n        conflicts = self.detect_conflicts()\n\n        if conflicts:\n            # Log conflicts\n            for conflict in conflicts:\n                self.conflict_history.append(conflict)\n                self.get_logger().warn(f'Conflict detected: {conflict}')\n\n            # Resolve conflicts based on priority\n            self.resolve_conflicts(conflicts)\n\n        # Select and execute the highest priority command\n        self.execute_highest_priority_command()\n\n        # Monitor system health\n        self.monitor_system_health()\n\n    def detect_conflicts(self):\n        \"\"\"Detect conflicts between different control levels\"\"\"\n        conflicts = []\n\n        # Check for command conflicts (different levels issuing conflicting commands)\n        active_levels = []\n        for level, queue in self.command_queues.items():\n            if queue:\n                active_levels.append(level)\n\n        # If multiple levels have commands, check for conflicts\n        if len(active_levels) > 1:\n            # For this example, we'll consider any simultaneous commands as potential conflicts\n            for level in active_levels:\n                conflicts.append({\n                    'type': 'simultaneous_commands',\n                    'levels': [l.name for l in active_levels],\n                    'active_level': level.name,\n                    'timestamp': self.get_clock().now().nanoseconds\n                })\n\n        # Check for status inconsistencies\n        active_statuses = [level for level, status in self.level_status.items() if status]\n        if len(active_statuses) > 1:\n            # Check if statuses indicate conflicting states\n            for level in active_statuses:\n                status = self.level_status[level]\n                # Example: if one level indicates \"STOP\" while another indicates \"MOVE\"\n                if status and isinstance(status, dict):\n                    command_status = status.get('command_status', '')\n                    if command_status == 'STOP' and any(\n                        self.level_status[other_level] and\n                        self.level_status[other_level].get('command_status', '') == 'MOVE'\n                        for other_level in active_statuses if other_level != level\n                    ):\n                        conflicts.append({\n                            'type': 'command_conflict',\n                            'levels': [level.name, next(l.name for l in active_statuses\n                                                      if l != level and self.level_status[l].get('command_status', '') == 'MOVE')],\n                            'description': f'{level.name} wants STOP but others want MOVE',\n                            'timestamp': self.get_clock().now().nanoseconds\n                        })\n\n        return conflicts\n\n    def resolve_conflicts(self, conflicts):\n        \"\"\"Resolve detected conflicts based on priority\"\"\"\n        for conflict in conflicts:\n            if conflict['type'] == 'simultaneous_commands':\n                # Resolve by priority - only execute highest priority command\n                active_levels = [ControlLevel[name] for name in conflict['levels']]\n                highest_priority_level = max(active_levels, key=lambda l: self.level_priority[l])\n\n                # Clear commands from lower priority levels\n                for level in active_levels:\n                    if level != highest_priority_level and self.command_queues[level]:\n                        self.command_queues[level].clear()\n                        self.get_logger().info(f'Cleared commands from {level.name} due to priority conflict')\n\n            elif conflict['type'] == 'command_conflict':\n                # Specific resolution for command conflicts\n                self.get_logger().info(f'Resolving command conflict: {conflict[\"description\"]}')\n\n    def execute_highest_priority_command(self):\n        \"\"\"Execute the command from the highest priority level that has a command\"\"\"\n        # Find the highest priority level with a command in its queue\n        available_levels = [level for level, queue in self.command_queues.items() if queue]\n\n        if not available_levels:\n            # No commands available, send stop\n            stop_cmd = Twist()\n            self.cmd_vel_pub.publish(stop_cmd)\n            return\n\n        # Find the highest priority level\n        highest_priority_level = max(available_levels, key=lambda l: self.level_priority[l])\n\n        # Get the command from the highest priority level\n        if self.command_queues[highest_priority_level]:\n            cmd_data = self.command_queues[highest_priority_level][0]  # Peek at first command\n            self.command_queues[highest_priority_level].popleft()  # Remove it\n\n            # Convert command data to Twist message\n            cmd = Twist()\n            cmd.linear.x = cmd_data.get('linear_x', 0.0)\n            cmd.linear.y = cmd_data.get('linear_y', 0.0)\n            cmd.linear.z = cmd_data.get('linear_z', 0.0)\n            cmd.angular.x = cmd_data.get('angular_x', 0.0)\n            cmd.angular.y = cmd_data.get('angular_y', 0.0)\n            cmd.angular.z = cmd_data.get('angular_z', 0.0)\n\n            # Apply safety limits\n            cmd.linear.x = max(-1.0, min(1.0, cmd.linear.x))\n            cmd.angular.z = max(-1.0, min(1.0, cmd.angular.z))\n\n            # Publish the command\n            self.cmd_vel_pub.publish(cmd)\n\n            # Log execution\n            self.get_logger().debug(f'Executing command from {highest_priority_level.name}: '\n                                  f'linear={cmd.linear.x:.2f}, angular={cmd.angular.z:.2f}')\n\n    def send_emergency_stop(self):\n        \"\"\"Send emergency stop command\"\"\"\n        stop_cmd = Twist()\n        self.cmd_vel_pub.publish(stop_cmd)\n        self.get_logger().info('Emergency stop command published')\n\n    def monitor_system_health(self):\n        \"\"\"Monitor the health of the coordination system\"\"\"\n        # Check for stale commands\n        current_time = self.get_clock().now().nanoseconds\n        timeout_ns = 1e9  # 1 second timeout\n\n        for level, queue in self.command_queues.items():\n            if queue:\n                oldest_cmd_time = queue[0].get('timestamp', current_time)\n                if (current_time - oldest_cmd_time) > timeout_ns:\n                    # Clear stale commands\n                    queue.clear()\n                    self.get_logger().warn(f'Cleared stale commands from {level.name}')\n\n        # Check for status staleness\n        for level, status in self.level_status.items():\n            if status and isinstance(status, dict):\n                status_time = status.get('timestamp', current_time)\n                if (current_time - status_time) > timeout_ns:\n                    self.level_status[level] = None\n                    self.get_logger().warn(f'Cleared stale status from {level.name}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    coordination_manager = CoordinationManager()\n\n    try:\n        rclpy.spin(coordination_manager)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        coordination_manager.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"solution-for-exercise-6-bio-inspired-neural-network-advanced",children:"Solution for Exercise 6: Bio-Inspired Neural Network (Advanced)"}),"\n",(0,a.jsx)(n.h3,{id:"complete-bio-inspired-neural-network-system",children:"Complete Bio-Inspired Neural Network System"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Imu\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Float64MultiArray\nimport numpy as np\nimport math\nfrom collections import defaultdict\nimport random\n\nclass NeuralNode:\n    """\n    A single neural node in the bio-inspired network.\n    """\n    def __init__(self, node_id, node_type="interneuron", activation_threshold=0.5):\n        self.node_id = node_id\n        self.node_type = node_type  # sensory, interneuron, motor\n        self.activation_threshold = activation_threshold\n        self.current_activation = 0.0\n        self.connections = {}  # {target_node_id: weight}\n        self.input_sum = 0.0\n        self.last_update_time = 0\n        self.activation_history = []\n        self.max_history = 100\n\n    def add_connection(self, target_node_id, weight):\n        """Add a weighted connection to another node"""\n        self.connections[target_node_id] = weight\n\n    def process_input(self, input_value, time_step):\n        """Process input and update activation"""\n        self.input_sum += input_value\n\n        # Apply activation function (sigmoid)\n        self.current_activation = 1 / (1 + math.exp(-self.input_sum))\n\n        # Store in history\n        self.activation_history.append((time_step, self.current_activation))\n        if len(self.activation_history) > self.max_history:\n            self.activation_history.pop(0)\n\n        # Decay input sum over time\n        self.input_sum *= 0.9  # 10% decay per time step\n\n        return self.current_activation\n\n    def get_output(self):\n        """Get output if activation exceeds threshold"""\n        return self.current_activation if self.current_activation > self.activation_threshold else 0.0\n\nclass NeuralNetworkController(Node):\n    """\n    Bio-inspired neural network controller for robotic control.\n    """\n\n    def __init__(self):\n        super().__init__(\'neural_network_controller\')\n\n        # Sensor subscriptions\n        self.laser_sub = self.create_subscription(LaserScan, \'/scan\', self.laser_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, \'/imu\', self.imu_callback, 10)\n\n        # Motor command publisher\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n\n        # Neural network timer\n        self.network_timer = self.create_timer(0.02, self.neural_processing_loop)  # 50 Hz\n\n        # Initialize neural network\n        self.initialize_neural_network()\n\n        # Sensor data storage\n        self.sensors = {\n            \'laser\': None,\n            \'imu\': None\n        }\n\n        # Learning parameters\n        self.learning_rate = 0.01\n        self.plasticity_enabled = True\n\n        self.get_logger().info(\'Neural Network Controller initialized\')\n\n    def initialize_neural_network(self):\n        """Initialize the neural network with a bio-inspired structure"""\n        self.neural_nodes = {}\n\n        # Create sensory neurons for laser inputs (one per laser sector)\n        laser_sectors = 8  # Divide laser scan into 8 sectors\n        for i in range(laser_sectors):\n            node_id = f"sensory_laser_{i}"\n            self.neural_nodes[node_id] = NeuralNode(node_id, "sensory", activation_threshold=0.3)\n\n        # Create sensory neurons for IMU\n        self.neural_nodes[\'sensory_imu_balance\'] = NeuralNode(\'sensory_imu_balance\', "sensory", activation_threshold=0.2)\n\n        # Create interneurons for processing\n        interneuron_count = 12\n        for i in range(interneuron_count):\n            node_id = f"interneuron_{i}"\n            self.neural_nodes[node_id] = NeuralNode(node_id, "interneuron", activation_threshold=0.4)\n\n        # Create motor neurons\n        self.neural_nodes[\'motor_linear\'] = NeuralNode(\'motor_linear\', "motor", activation_threshold=0.3)\n        self.neural_nodes[\'motor_angular\'] = NeuralNode(\'motor_angular\', "motor", activation_threshold=0.3)\n\n        # Create initial connections (random weights)\n        self.create_initial_connections()\n\n        self.get_logger().info(f\'Neural network initialized with {len(self.neural_nodes)} nodes\')\n\n    def create_initial_connections(self):\n        """Create initial connections between neurons"""\n        # Connect sensory neurons to interneurons\n        for i in range(8):  # Laser sensory neurons\n            sensory_id = f"sensory_laser_{i}"\n            for j in range(6):  # Connect to first 6 interneurons\n                interneuron_id = f"interneuron_{j}"\n                weight = random.uniform(-0.5, 0.5)  # Random initial weight\n                self.neural_nodes[sensory_id].add_connection(interneuron_id, weight)\n\n        # Connect IMU sensory to interneurons\n        for j in range(6, 12):  # Connect to last 6 interneurons\n            interneuron_id = f"interneuron_{j}"\n            weight = random.uniform(-0.3, 0.3)\n            self.neural_nodes[\'sensory_imu_balance\'].add_connection(interneuron_id, weight)\n\n        # Connect interneurons to each other (recurrent connections)\n        for i in range(12):\n            interneuron_id = f"interneuron_{i}"\n            # Connect to other interneurons\n            for j in range(12):\n                if i != j:  # No self-connections\n                    target_id = f"interneuron_{j}"\n                    weight = random.uniform(-0.2, 0.2)\n                    # Only create some connections to avoid full connectivity\n                    if random.random() < 0.3:  # 30% connectivity\n                        self.neural_nodes[interneuron_id].add_connection(target_id, weight)\n\n        # Connect interneurons to motor neurons\n        for i in range(6):  # First 6 interneurons to linear motor\n            interneuron_id = f"interneuron_{i}"\n            self.neural_nodes[interneuron_id].add_connection(\'motor_linear\', random.uniform(-0.5, 0.5))\n\n        for i in range(6, 12):  # Last 6 interneurons to angular motor\n            interneuron_id = f"interneuron_{i}"\n            self.neural_nodes[interneuron_id].add_connection(\'motor_angular\', random.uniform(-0.5, 0.5))\n\n    def laser_callback(self, msg):\n        """Process laser scan data and activate sensory neurons"""\n        ranges = np.array(msg.ranges)\n        # Filter invalid readings\n        ranges[ranges == float(\'inf\')] = 3.5\n        ranges[np.isnan(ranges)] = 3.5\n\n        # Divide laser scan into 8 sectors\n        sector_size = len(ranges) // 8\n        for i in range(8):\n            start_idx = i * sector_size\n            end_idx = start_idx + sector_size if i < 7 else len(ranges)  # Handle remainder\n            sector_ranges = ranges[start_idx:end_idx]\n\n            # Calculate average distance in this sector (inverse for obstacle proximity)\n            avg_distance = np.mean(sector_ranges) if len(sector_ranges) > 0 else 3.5\n            # Closer obstacles result in higher activation\n            activation = max(0.0, (3.5 - avg_distance) / 3.5)  # Normalize to [0, 1]\n\n            node_id = f"sensory_laser_{i}"\n            if node_id in self.neural_nodes:\n                self.neural_nodes[node_id].process_input(activation, self.get_clock().now().nanoseconds)\n\n    def imu_callback(self, msg):\n        """Process IMU data and activate balance sensory neuron"""\n        # Extract orientation for balance information\n        q = msg.orientation\n        # Simple roll/pitch extraction (simplified)\n        sinr_cosp = 2 * (q.w * q.x + q.y * q.z)\n        cosr_cosp = 1 - 2 * (q.x * q.x + q.y * q.y)\n        roll = math.atan2(sinr_cosp, cosr_cosp)\n\n        siny_cosp = 2 * (q.w * q.z + q.x * q.y)\n        cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z)\n        pitch = math.atan2(siny_cosp, cosy_cosp)\n\n        # Activation based on tilt magnitude\n        tilt_magnitude = abs(roll) + abs(pitch)\n        activation = min(1.0, tilt_magnitude)  # Cap at 1.0\n\n        node_id = \'sensory_imu_balance\'\n        if node_id in self.neural_nodes:\n            self.neural_nodes[node_id].process_input(activation, self.get_clock().now().nanoseconds)\n\n    def neural_processing_loop(self):\n        """Main neural network processing loop"""\n        if not all(self.sensors.values()):\n            return\n\n        current_time = self.get_clock().now().nanoseconds\n\n        # Propagate activations through the network\n        self.propagate_activations(current_time)\n\n        # Get motor outputs\n        linear_output = self.neural_nodes[\'motor_linear\'].get_output()\n        angular_output = self.neural_nodes[\'motor_angular\'].get_output()\n\n        # Convert to motor command\n        cmd = Twist()\n        cmd.linear.x = linear_output * 0.8  # Scale to reasonable speed\n        cmd.angular.z = angular_output * 1.0  # Scale to reasonable turning rate\n\n        # Apply safety limits\n        cmd.linear.x = max(-0.8, min(0.8, cmd.linear.x))\n        cmd.angular.z = max(-1.0, min(1.0, cmd.angular.z))\n\n        # Publish command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Apply learning if enabled\n        if self.plasticity_enabled:\n            self.apply_hebbian_learning()\n\n        self.get_logger().debug(f\'Neural output - linear: {cmd.linear.x:.3f}, angular: {cmd.angular.z:.3f}\')\n\n    def propagate_activations(self, time_step):\n        """Propagate activations through the network"""\n        # This is a simplified propagation - in a real implementation,\n        # you might want to use a more sophisticated method\n\n        # Process in layers: sensory -> interneurons -> motor\n        # First, collect outputs from sensory neurons\n        sensory_outputs = {}\n        for node_id, node in self.neural_nodes.items():\n            if node.node_type == "sensory":\n                sensory_outputs[node_id] = node.get_output()\n\n        # Then update interneurons based on sensory input and connections\n        interneuron_updates = {}\n        for node_id, node in self.neural_nodes.items():\n            if node.node_type == "interneuron":\n                total_input = 0.0\n\n                # Sum inputs from sensory neurons\n                for src_id, output in sensory_outputs.items():\n                    if src_id in node.connections:\n                        total_input += output * node.connections[src_id]\n\n                # Sum inputs from other interneurons\n                for other_id, other_node in self.neural_nodes.items():\n                    if (other_node.node_type == "interneuron" and\n                        other_id in node.connections and\n                        other_id in interneuron_updates):\n                        total_input += interneuron_updates[other_id] * node.connections[other_id]\n\n                # Update this interneuron\n                node.process_input(total_input, time_step)\n                interneuron_updates[node_id] = node.get_output()\n\n        # Finally, update motor neurons\n        for node_id, node in self.neural_nodes.items():\n            if node.node_type == "motor":\n                total_input = 0.0\n\n                # Sum inputs from interneurons\n                for src_id, output in interneuron_updates.items():\n                    if src_id in node.connections:\n                        total_input += output * node.connections[src_id]\n\n                node.process_input(total_input, time_step)\n\n    def apply_hebbian_learning(self):\n        """Apply Hebbian learning rule: "neurons that fire together, wire together" """\n        # Simplified Hebbian learning\n        for node_id, node in self.neural_nodes.items():\n            for target_id in node.connections:\n                if target_id in self.neural_nodes:\n                    target_node = self.neural_nodes[target_id]\n\n                    # Get current activations\n                    pre_activation = node.get_output()\n                    post_activation = target_node.get_output()\n\n                    # Apply Hebbian rule: weight change proportional to product of activations\n                    weight_change = self.learning_rate * pre_activation * post_activation\n                    node.connections[target_id] += weight_change\n\n                    # Constrain weights to reasonable range\n                    node.connections[target_id] = max(-1.0, min(1.0, node.connections[target_id]))\n\n    def get_network_state(self):\n        """Get the current state of the neural network"""\n        state = {\n            \'node_count\': len(self.neural_nodes),\n            \'sensory_nodes\': [],\n            \'interneurons\': [],\n            \'motor_nodes\': [],\n            \'total_connections\': 0\n        }\n\n        for node_id, node in self.neural_nodes.items():\n            state[f\'{node.node_type}_nodes\'].append({\n                \'id\': node_id,\n                \'activation\': node.current_activation,\n                \'connections\': len(node.connections)\n            })\n            state[\'total_connections\'] += len(node.connections)\n\n        return state\n\ndef main(args=None):\n    rclpy.init(args=args)\n    neural_controller = NeuralNetworkController()\n\n    try:\n        rclpy.spin(neural_controller)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        neural_controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"implementation-guide",children:"Implementation Guide"}),"\n",(0,a.jsx)(n.h3,{id:"for-exercise-1-basic-reflex-system",children:"For Exercise 1 (Basic Reflex System):"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Create a high-frequency timer for immediate response"}),"\n",(0,a.jsx)(n.li,{children:"Implement obstacle detection with safety threshold"}),"\n",(0,a.jsx)(n.li,{children:"Create command override mechanism"}),"\n",(0,a.jsx)(n.li,{children:"Test with various obstacle scenarios"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"for-exercise-2-hierarchical-control",children:"For Exercise 2 (Hierarchical Control):"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Design three-level architecture with clear interfaces"}),"\n",(0,a.jsx)(n.li,{children:"Implement different timer frequencies for each level"}),"\n",(0,a.jsx)(n.li,{children:"Create communication protocols between levels"}),"\n",(0,a.jsx)(n.li,{children:"Implement conflict resolution mechanisms"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"for-exercise-3-sensorimotor-integration",children:"For Exercise 3 (Sensorimotor Integration):"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Set up multiple sensor subscriptions"}),"\n",(0,a.jsx)(n.li,{children:"Implement data synchronization mechanisms"}),"\n",(0,a.jsx)(n.li,{children:"Create state estimation from fused data"}),"\n",(0,a.jsx)(n.li,{children:"Generate appropriate motor commands"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"for-exercise-4-adaptive-control",children:"For Exercise 4 (Adaptive Control):"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Implement basic behavior with adjustable parameters"}),"\n",(0,a.jsx)(n.li,{children:"Create performance evaluation function"}),"\n",(0,a.jsx)(n.li,{children:"Store and analyze experience data"}),"\n",(0,a.jsx)(n.li,{children:"Implement learning algorithm"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"for-exercise-5-coordination-manager",children:"For Exercise 5 (Coordination Manager):"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Design conflict detection mechanisms"}),"\n",(0,a.jsx)(n.li,{children:"Implement priority resolution"}),"\n",(0,a.jsx)(n.li,{children:"Create status monitoring system"}),"\n",(0,a.jsx)(n.li,{children:"Test with various conflict scenarios"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"for-exercise-6-bio-inspired-neural-network",children:"For Exercise 6 (Bio-Inspired Neural Network):"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Design network architecture with appropriate neuron types"}),"\n",(0,a.jsx)(n.li,{children:"Implement activation propagation"}),"\n",(0,a.jsx)(n.li,{children:"Create learning mechanisms"}),"\n",(0,a.jsx)(n.li,{children:"Test with complex behavioral tasks"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Modularity"}),": Keep each control level modular and independently testable"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Safety"}),": Always implement safety checks and emergency overrides"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance"}),": Use appropriate timer frequencies for each control level"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Communication"}),": Implement clear and efficient communication between levels"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Monitoring"}),": Include status reporting and health monitoring"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Adaptation"}),": Implement learning with appropriate exploration vs exploitation balance"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Scalability"}),": Design systems that can scale to more complex networks"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Documentation"}),": Document all parameters and design decisions"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"These solutions provide complete implementations for each exercise, demonstrating how to create bio-inspired robotic nervous system patterns using ROS 2. Each solution builds on the previous ones, showing progressive complexity from basic reflexes to sophisticated neural network control."})]})}function m(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>r,x:()=>i});var s=t(6540);const a={},o=s.createContext(a);function r(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);